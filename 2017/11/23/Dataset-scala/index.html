<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="spark,源码," />










<meta name="description" content="前言Dataset 是一种强类型的领域特定对象集合，可以在使用功能或关系操作的同时进行转换。每个 Dataset 也有一个名为 “DataFrame” 的无类型视图，它是 [[Row]] 的 Dataset。Dataset 上可用的操作分为转换和动作:

转换：产生新的 Dataset ；包括 map, filter, select, and aggregate (groupBy).动作：触发计算">
<meta property="og:type" content="article">
<meta property="og:title" content="Dataset.scala">
<meta property="og:url" content="https://stanxia.github.io/2017/11/23/Dataset-scala/index.html">
<meta property="og:site_name" content="东篱下">
<meta property="og:description" content="前言Dataset 是一种强类型的领域特定对象集合，可以在使用功能或关系操作的同时进行转换。每个 Dataset 也有一个名为 “DataFrame” 的无类型视图，它是 [[Row]] 的 Dataset。Dataset 上可用的操作分为转换和动作:

转换：产生新的 Dataset ；包括 map, filter, select, and aggregate (groupBy).动作：触发计算">
<meta property="og:updated_time" content="2017-12-05T03:33:42.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Dataset.scala">
<meta name="twitter:description" content="前言Dataset 是一种强类型的领域特定对象集合，可以在使用功能或关系操作的同时进行转换。每个 Dataset 也有一个名为 “DataFrame” 的无类型视图，它是 [[Row]] 的 Dataset。Dataset 上可用的操作分为转换和动作:

转换：产生新的 Dataset ；包括 map, filter, select, and aggregate (groupBy).动作：触发计算">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://stanxia.github.io/2017/11/23/Dataset-scala/"/>





  <title>Dataset.scala | 东篱下</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">东篱下</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">斯坦@森</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/aboutme/" rel="section">
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-spark">
          <a href="/tags/spark/" rel="section">
            
            SPARK
          </a>
        </li>
      
        
        <li class="menu-item menu-item-hive">
          <a href="/tags/hive/" rel="section">
            
            HIVE
          </a>
        </li>
      
        
        <li class="menu-item menu-item-gem">
          <a href="/gem/" rel="section">
            
            GEM
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/books" rel="section">
            
            BOOKS
          </a>
        </li>
      
        
        <li class="menu-item menu-item-movies">
          <a href="/movies" rel="section">
            
            MOVIES
          </a>
        </li>
      
        
        <li class="menu-item menu-item-photos">
          <a href="https://www.instagram.com/xooglexls/" rel="section">
            
            PHOTOS
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>
    
    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://stanxia.github.io/2017/11/23/Dataset-scala/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="森">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>
    
    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东篱下">
    </span>
    
    
      <header class="post-header">
    
        
        
          <h1 class="post-title" itemprop="name headline">Dataset.scala</h1>
        
    
        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-23T09:34:44+08:00">
                2017-11-23
              </time>
            
    
            
    
            
          </span>
    
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>
    
                
                
              
            </span>
          
    
          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/11/23/Dataset-scala/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/11/23/Dataset-scala/" itemprop="commentCount"></span>
                </a>
              </span>
            
          
    
          
          
             <span id="/2017/11/23/Dataset-scala/" class="leancloud_visitors" data-flag-title="Dataset.scala">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          
    
          
    
          
    
          
    
        </div>
      </header>
    
    
    
    
    
    <div class="post-body" itemprop="articleBody">
    
      
      
    
      
        <script src="/assets/js/DPlayer.min.js"> </script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Dataset 是一种强类型的领域特定对象集合，可以在使用功能或关系操作的同时进行转换。每个 Dataset 也有一个名为 “DataFrame” 的无类型视图，它是 [[Row]] 的 Dataset。<br>Dataset 上可用的操作分为转换和动作:</p>
<blockquote>
<p>转换：产生新的 Dataset ；包括 map, filter, select, and aggregate (<code>groupBy</code>).<br>动作：触发计算并返回结果 ；包括 count, show, or 写数据到文件系统。</p>
</blockquote>
<p>Dataset是懒加载的，例如：只有提交动作的时候才会触发计算。在内部，Datasets表示一个逻辑计划，它描述生成数据所需的计算。当提交动作时，Spark的查询优化器会优化逻辑计划，并以并行和分布式的方式生成有效执行的物理计划。请使用<code>explain</code> 功能，探索逻辑计划和优化的物理计划。</p>
<p>为了有效地支持特定于领域的对象，需要[[Encoder]]。编码器将特定类型的“T”映射到Spark的内部类型系统。例如：给一个 <code>Person</code> 类，并带有两个属性：<code>name</code> (string) and <code>age</code> (int),编码器告诉Spark在运行时生成代码，序列化 <code>Person</code> 对象为二进制结构。</p>
<p>通常有两种创建Dataset的方法:</p>
<blockquote>
<p>使用 <code>SparkSession</code> 上可用的 <code>read</code> 方法读取 Spark 指向的存储系统上的文件。<br>用现存的 Datasets 转换而来。</p>
</blockquote>
<p>Dataset操作也可以是无类型的，通过多种领域专用语言（DSL）方法定义：这些操作非常类似于 R或Python语言中的 数据框架抽象中可用的操作。<br><a id="more"></a></p>
<!--请开始装逼-->
<h2 id="basic-基础方法"><a href="#basic-基础方法" class="headerlink" title="basic-基础方法"></a>basic-基础方法</h2><h3 id="toDF"><a href="#toDF" class="headerlink" title="toDF"></a>toDF</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Converts this strongly typed collection of data to generic Dataframe. In contrast to the</div><div class="line">  * strongly typed objects that Dataset operations work on, a Dataframe returns generic [[Row]]</div><div class="line">  * objects that allow fields to be accessed by ordinal or name.</div><div class="line">  * 将这种强类型的数据集合转换为一般的Dataframe。</div><div class="line">  * 与Dataset操作所使用的强类型对象相反，</div><div class="line">  * Dataframe返回泛型[[Row]]对象，这些对象允许通过序号或名称访问字段</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="comment">// This is declared with parentheses to prevent the Scala compiler from treating</span></div><div class="line"><span class="comment">// `ds.toDF("1")` as invoking this toDF and then apply on the returned DataFrame.</span></div><div class="line"><span class="comment">// 这是用括号声明的，以防止Scala编译器处理ds.toDF(“1”)调用这个toDF，然后在返回的DataFrame上应用。</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">toDF</span></span>(): <span class="type">DataFrame</span> = <span class="keyword">new</span> <span class="type">Dataset</span>[<span class="type">Row</span>](sparkSession, queryExecution, <span class="type">RowEncoder</span>(schema))</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Converts this strongly typed collection of data to generic `DataFrame` with columns renamed.</div><div class="line">  * This can be quite convenient in conversion from an RDD of tuples into a `DataFrame` with</div><div class="line">  * meaningful names. For example:</div><div class="line">  *</div><div class="line">  * 将这种强类型的数据集合转换为通用的“DataFrame”，并将列重命名。</div><div class="line">  * 在将tuple的RDD转换为富有含义的名称的“DataFrame”时，这是非常方便的，如：</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   val rdd: RDD[(Int, String)] = ...</div><div class="line">  *   rdd.toDF()  // 隐式转换创建了 DataFrame ，列名为： `_1` and `_2`</div><div class="line">  *   rdd.toDF("id", "name")  // 创建了 DataFrame ，列名为： "id" and "name"</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">toDF</span></span>(colNames: <span class="type">String</span>*): <span class="type">DataFrame</span> = &#123;</div><div class="line">  require(schema.size == colNames.size,</div><div class="line">    <span class="string">"The number of columns doesn't match.\n"</span> +</div><div class="line">      <span class="string">s"Old column names (<span class="subst">$&#123;schema.size&#125;</span>): "</span> + schema.fields.map(_.name).mkString(<span class="string">", "</span>) + <span class="string">"\n"</span> +</div><div class="line">      <span class="string">s"New column names (<span class="subst">$&#123;colNames.size&#125;</span>): "</span> + colNames.mkString(<span class="string">", "</span>))</div><div class="line"></div><div class="line">  <span class="keyword">val</span> newCols = logicalPlan.output.zip(colNames).map &#123; <span class="keyword">case</span> (oldAttribute, newName) =&gt;</div><div class="line">    <span class="type">Column</span>(oldAttribute).as(newName)</div><div class="line">  &#125;</div><div class="line">  select(newCols: _*)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="as"><a href="#as" class="headerlink" title="as"></a>as</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * Returns a new Dataset where each record has been mapped on to the specified type. The</div><div class="line">    * method used to map columns depend on the type of `U`:</div><div class="line">    * </div><div class="line">    * 返回一个新的Dataset，其中每个记录都被映射到指定的类型。用于映射列的方法取决于“U”的类型:</div><div class="line">    * </div><div class="line">    *  - When `U` is a class, fields for the class will be mapped to columns of the same name</div><div class="line">    * (case sensitivity is determined by `spark.sql.caseSensitive`).</div><div class="line">    * </div><div class="line">    * 当“U”是类时：类的属性将映射到相同名称的列</div><div class="line">    * </div><div class="line">    *  - When `U` is a tuple, the columns will be be mapped by ordinal (i.e. the first column will</div><div class="line">    * be assigned to `_1`).</div><div class="line">    * </div><div class="line">    * 当“U”是元组时：列将由序数映射 （例如，第一列将为 "_1"）</div><div class="line">    * </div><div class="line">    *  - When `U` is a primitive type (i.e. String, Int, etc), then the first column of the</div><div class="line">    * `DataFrame` will be used.</div><div class="line">    * </div><div class="line">    * 当“U”是 基本类型（如 String，Int等）：然后将使用“DataFrame”的第一列。</div><div class="line">    *</div><div class="line">    * If the schema of the Dataset does not match the desired `U` type, you can use `select`</div><div class="line">    * along with `alias` or `as` to rearrange or rename as required.</div><div class="line">    * </div><div class="line">    * 如果数据集的模式与所需的“U”类型不匹配，您可以使用“select”和“alias”或“as”来重新排列或重命名。</div><div class="line">    *</div><div class="line">    * @group basic</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">as</span></span>[<span class="type">U</span>: <span class="type">Encoder</span>]: <span class="type">Dataset</span>[<span class="type">U</span>] = <span class="type">Dataset</span>[<span class="type">U</span>](sparkSession, logicalPlan)</div></pre></td></tr></table></figure>
<h3 id="schema"><a href="#schema" class="headerlink" title="schema"></a>schema</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the schema of this Dataset.</div><div class="line">  * 返回该Dataset的模版</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">schema</span></span>: <span class="type">StructType</span> = queryExecution.analyzed.schema</div></pre></td></tr></table></figure>
<h3 id="printSchema"><a href="#printSchema" class="headerlink" title="printSchema"></a>printSchema</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Prints the schema to the console in a nice tree format.</div><div class="line">  * </div><div class="line">  * 以一种漂亮的树格式将模式打印到控制台。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="comment">// scalastyle:off println</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">printSchema</span></span>(): <span class="type">Unit</span> = println(schema.treeString)</div></pre></td></tr></table></figure>
<h3 id="explain"><a href="#explain" class="headerlink" title="explain"></a>explain</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Prints the plans (logical and physical) to the console for debugging purposes.</div><div class="line">  * </div><div class="line">  * 将计划(逻辑和物理)打印到控制台以进行调试。</div><div class="line">  * 参数：extended = false 为物理计划</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">explain</span></span>(extended: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> explain = <span class="type">ExplainCommand</span>(queryExecution.logical, extended = extended)</div><div class="line">  sparkSession.sessionState.executePlan(explain).executedPlan.executeCollect().foreach &#123;</div><div class="line">    <span class="comment">// scalastyle:off println</span></div><div class="line">    r =&gt; println(r.getString(<span class="number">0</span>))</div><div class="line">    <span class="comment">// scalastyle:on println</span></div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Prints the physical plan to the console for debugging purposes.</div><div class="line">  * 将物理计划打印到控制台以进行调试。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">explain</span></span>(): <span class="type">Unit</span> = explain(extended = <span class="literal">false</span>)</div></pre></td></tr></table></figure>
<h3 id="dtypes"><a href="#dtypes" class="headerlink" title="dtypes"></a>dtypes</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns all column names and their data types as an array.</div><div class="line">  * 以数组的形式返回所有列名称和它们的数据类型</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dtypes</span></span>: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">String</span>)] = schema.fields.map &#123; field =&gt;</div><div class="line">  (field.name, field.dataType.toString)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="columns"><a href="#columns" class="headerlink" title="columns"></a>columns</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns all column names as an array.</div><div class="line">  * 以数组的形式返回 所有列名</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">columns</span></span>: <span class="type">Array</span>[<span class="type">String</span>] = schema.fields.map(_.name)</div></pre></td></tr></table></figure>
<h3 id="isLocal"><a href="#isLocal" class="headerlink" title="isLocal"></a>isLocal</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns true if the `collect` and `take` methods can be run locally</div><div class="line">  * (without any Spark executors).</div><div class="line">  * 如果`collect` and `take` 方法能在本地运行，则返回true</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">isLocal</span></span>: <span class="type">Boolean</span> = logicalPlan.isInstanceOf[<span class="type">LocalRelation</span>]</div></pre></td></tr></table></figure>
<h3 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Eagerly checkpoint a Dataset and return the new Dataset. Checkpointing can be used to truncate</div><div class="line">  * the logical plan of this Dataset, which is especially useful in iterative algorithms where the</div><div class="line">  * plan may grow exponentially. It will be saved to files inside the checkpoint</div><div class="line">  * directory set with `SparkContext#setCheckpointDir`.</div><div class="line">  * </div><div class="line">  * 急切地检查一个数据集并返回新的数据集。</div><div class="line">  * 检查点能用来清除Dataset的逻辑计划，尤其是在可能生成指数级别的迭代算法中尤其有用。</div><div class="line">  * 将会在检查点目录中保存检查文件。可以在`SparkContext#setCheckpointDir`中设置。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 2.1.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkpoint</span></span>(): <span class="type">Dataset</span>[<span class="type">T</span>] = checkpoint(eager = <span class="literal">true</span>)</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Returns a checkpointed version of this Dataset. Checkpointing can be used to truncate the</div><div class="line">  * logical plan of this Dataset, which is especially useful in iterative algorithms where the</div><div class="line">  * plan may grow exponentially. It will be saved to files inside the checkpoint</div><div class="line">  * directory set with `SparkContext#setCheckpointDir`.</div><div class="line">  * 返回Dataset 之前检查过的版本。</div><div class="line">  * 检查点能用来清除Dataset的逻辑计划，尤其是在可能生成指数级别的迭代算法中尤其有用。</div><div class="line">  * 将会在检查点目录中保存检查文件。可以在`SparkContext#setCheckpointDir`中设置。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 2.1.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkpoint</span></span>(eager: <span class="type">Boolean</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> internalRdd = queryExecution.toRdd.map(_.copy())</div><div class="line">  internalRdd.checkpoint()</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (eager) &#123;</div><div class="line">    internalRdd.count()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> physicalPlan = queryExecution.executedPlan</div><div class="line"></div><div class="line">  <span class="comment">// Takes the first leaf partitioning whenever we see a `PartitioningCollection`. Otherwise the</span></div><div class="line">  <span class="comment">// size of `PartitioningCollection` may grow exponentially for queries involving deep inner</span></div><div class="line">  <span class="comment">// joins.</span></div><div class="line">  <span class="comment">// 每当我们看到“PartitioningCollection”时，就采用第一个叶子分区</span></div><div class="line">  <span class="comment">// 否则，用于涉及深度内连接的查询，“PartitioningCollection”的大小可能会以指数形式增长。</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">firstLeafPartitioning</span></span>(partitioning: <span class="type">Partitioning</span>): <span class="type">Partitioning</span> = &#123;</div><div class="line">    partitioning <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> p: <span class="type">PartitioningCollection</span> =&gt; firstLeafPartitioning(p.partitionings.head)</div><div class="line">      <span class="keyword">case</span> p =&gt; p</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> outputPartitioning = firstLeafPartitioning(physicalPlan.outputPartitioning)</div><div class="line"></div><div class="line">  <span class="type">Dataset</span>.ofRows(</div><div class="line">    sparkSession,</div><div class="line">    <span class="type">LogicalRDD</span>(</div><div class="line">      logicalPlan.output,</div><div class="line">      internalRdd,</div><div class="line">      outputPartitioning,</div><div class="line">      physicalPlan.outputOrdering</div><div class="line">    )(sparkSession)).as[<span class="type">T</span>]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="persist"><a href="#persist" class="headerlink" title="persist"></a>persist</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).</div><div class="line">  *</div><div class="line">  * 持久化。</div><div class="line">  * 根据默认的 存储级别 (`MEMORY_AND_DISK`)  持久化Dataset。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = &#123;</div><div class="line">  sparkSession.sharedState.cacheManager.cacheQuery(<span class="keyword">this</span>)</div><div class="line">  <span class="keyword">this</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Persist this Dataset with the given storage level.</div><div class="line">  *</div><div class="line">  * 根据指定的 存储级别 持久化 Dataset。</div><div class="line">  *</div><div class="line">  * @param newLevel One of:</div><div class="line">  *                 `MEMORY_ONLY`,</div><div class="line">  *                 `MEMORY_AND_DISK`,</div><div class="line">  *                 `MEMORY_ONLY_SER`,</div><div class="line">  *                 `MEMORY_AND_DISK_SER`,</div><div class="line">  *                 `DISK_ONLY`,</div><div class="line">  *                 `MEMORY_ONLY_2`, 与MEMORY_ONLY的区别是会备份数据到其他节点上</div><div class="line">  *                 `MEMORY_AND_DISK_2`, 与MEMORY_AND_DISK的区别是会备份数据到其他节点上</div><div class="line">  *                 etc.</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(newLevel: <span class="type">StorageLevel</span>): <span class="keyword">this</span>.<span class="keyword">type</span> = &#123;</div><div class="line">  sparkSession.sharedState.cacheManager.cacheQuery(<span class="keyword">this</span>, <span class="type">None</span>, newLevel)</div><div class="line">  <span class="keyword">this</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Persist this Dataset with the default storage level (`MEMORY_AND_DISK`).</div><div class="line">  *</div><div class="line">  * 持久化。</div><div class="line">  * 根据默认的 存储级别 (`MEMORY_AND_DISK`)  持久化Dataset。</div><div class="line">  * 和 persist 一致。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cache</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = persist()</div></pre></td></tr></table></figure>
<h3 id="storageLevel"><a href="#storageLevel" class="headerlink" title="storageLevel"></a>storageLevel</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Get the Dataset's current storage level, or StorageLevel.NONE if not persisted.</div><div class="line">  *</div><div class="line">  * 获取当前Dataset的当前存储级别。如果没有缓存则 StorageLevel.NONE。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 2.1.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storageLevel</span></span>: <span class="type">StorageLevel</span> = &#123;</div><div class="line">  sparkSession.sharedState.cacheManager.lookupCachedData(<span class="keyword">this</span>).map &#123; cachedData =&gt;</div><div class="line">    cachedData.cachedRepresentation.storageLevel</div><div class="line">  &#125;.getOrElse(<span class="type">StorageLevel</span>.<span class="type">NONE</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="unpersist"><a href="#unpersist" class="headerlink" title="unpersist"></a>unpersist</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div><div class="line">  *</div><div class="line">  * 解除持久化。</div><div class="line">  * 将Dataset标记为非持久化，并从内存和磁盘中移除所有的块。</div><div class="line">  *</div><div class="line">  * @param blocking Whether to block until all blocks are deleted.</div><div class="line">  *                 是否阻塞，直到删除所有的块。</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpersist</span></span>(blocking: <span class="type">Boolean</span>): <span class="keyword">this</span>.<span class="keyword">type</span> = &#123;</div><div class="line">  sparkSession.sharedState.cacheManager.uncacheQuery(<span class="keyword">this</span>, blocking)</div><div class="line">  <span class="keyword">this</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div><div class="line">  *</div><div class="line">  * 解除持久化。</div><div class="line">  * 将Dataset标记为非持久化，并从内存和磁盘中移除所有的块。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpersist</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = unpersist(blocking = <span class="literal">false</span>)</div></pre></td></tr></table></figure>
<h3 id="rdd"><a href="#rdd" class="headerlink" title="rdd"></a>rdd</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Represents the content of the Dataset as an `RDD` of [[T]].</div><div class="line">  *</div><div class="line">  * 转换为[[T]]的“RDD”，表示Dataset的内容</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">T</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> objectType = exprEnc.deserializer.dataType</div><div class="line">  <span class="keyword">val</span> deserialized = <span class="type">CatalystSerde</span>.deserialize[<span class="type">T</span>](logicalPlan)</div><div class="line">  sparkSession.sessionState.executePlan(deserialized).toRdd.mapPartitions &#123; rows =&gt;</div><div class="line">    rows.map(_.get(<span class="number">0</span>, objectType).asInstanceOf[<span class="type">T</span>])</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="toJavaRDD"><a href="#toJavaRDD" class="headerlink" title="toJavaRDD"></a>toJavaRDD</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the content of the Dataset as a `JavaRDD` of [[T]]s.</div><div class="line">  * </div><div class="line">  * 转换为JavaRDD</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">toJavaRDD</span></span>: <span class="type">JavaRDD</span>[<span class="type">T</span>] = rdd.toJavaRDD()</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Returns the content of the Dataset as a `JavaRDD` of [[T]]s.</div><div class="line">  *</div><div class="line">  * 转换为JavaRDD</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">javaRDD</span></span>: <span class="type">JavaRDD</span>[<span class="type">T</span>] = toJavaRDD</div></pre></td></tr></table></figure>
<h3 id="registerTempTable"><a href="#registerTempTable" class="headerlink" title="registerTempTable"></a>registerTempTable</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Registers this Dataset as a temporary table using the given name. The lifetime of this</div><div class="line">  * temporary table is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class="line">  *</div><div class="line">  * 根据指定的表名，注册临时表。</div><div class="line">  * 生命周期为[[SparkSession]]的生命周期。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@deprecated</span>(<span class="string">"Use createOrReplaceTempView(viewName) instead."</span>, <span class="string">"2.0.0"</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">registerTempTable</span></span>(tableName: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  createOrReplaceTempView(tableName)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="createTempView"><a href="#createTempView" class="headerlink" title="createTempView"></a>createTempView</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Creates a local temporary view using the given name. The lifetime of this</div><div class="line">  * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class="line">  *</div><div class="line">  * 用指定的名字创建本地临时表。</div><div class="line">  * 与[[SparkSession]] 同生命周期。</div><div class="line">  *</div><div class="line">  * Local temporary view is session-scoped. Its lifetime is the lifetime of the session that</div><div class="line">  * created it, i.e. it will be automatically dropped when the session terminates. It's not</div><div class="line">  * tied to any databases, i.e. we can't use `db1.view1` to reference a local temporary view.</div><div class="line">  *</div><div class="line">  * 本地临时表是 session范围内的。当创建它的session停止的时候，该表也随之停止。</div><div class="line">  *</div><div class="line">  * @throws AnalysisException if the view name already exists</div><div class="line">  * @group basic</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@throws</span>[<span class="type">AnalysisException</span>]</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTempView</span></span>(viewName: <span class="type">String</span>): <span class="type">Unit</span> = withPlan &#123;</div><div class="line">  createTempViewCommand(viewName, replace = <span class="literal">false</span>, global = <span class="literal">false</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="createOrReplaceTempView"><a href="#createOrReplaceTempView" class="headerlink" title="createOrReplaceTempView"></a>createOrReplaceTempView</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Creates a local temporary view using the given name. The lifetime of this</div><div class="line">  * temporary view is tied to the [[SparkSession]] that was used to create this Dataset.</div><div class="line">  *</div><div class="line">  * 用指定的名字创建本地临时表。如果已经有了则替换。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createOrReplaceTempView</span></span>(viewName: <span class="type">String</span>): <span class="type">Unit</span> = withPlan &#123;</div><div class="line">  createTempViewCommand(viewName, replace = <span class="literal">true</span>, global = <span class="literal">false</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="createGlobalTempView"><a href="#createGlobalTempView" class="headerlink" title="createGlobalTempView"></a>createGlobalTempView</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Creates a global temporary view using the given name. The lifetime of this</div><div class="line">  * temporary view is tied to this Spark application.</div><div class="line">  *</div><div class="line">  * 创建全局临时表。</div><div class="line">  * 生命周期为整个Spark application.</div><div class="line">  *</div><div class="line">  * Global temporary view is cross-session. Its lifetime is the lifetime of the Spark application,</div><div class="line">  * i.e. it will be automatically dropped when the application terminates. It's tied to a system</div><div class="line">  * preserved database `_global_temp`, and we must use the qualified name to refer a global temp</div><div class="line">  * view, e.g. `SELECT * FROM _global_temp.view1`.</div><div class="line">  *</div><div class="line">  * 全局临时表是跨session的。属于 _global_temp 数据库。e.g. `SELECT * FROM _global_temp.view1`.</div><div class="line">  *</div><div class="line">  * @throws AnalysisException if the view name already exists</div><div class="line">  *                           如果表已经存在，则报错。</div><div class="line">  * @group basic</div><div class="line">  * @since 2.1.0</div><div class="line">  */</div><div class="line"><span class="meta">@throws</span>[<span class="type">AnalysisException</span>]</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createGlobalTempView</span></span>(viewName: <span class="type">String</span>): <span class="type">Unit</span> = withPlan &#123;</div><div class="line">  createTempViewCommand(viewName, replace = <span class="literal">false</span>, global = <span class="literal">true</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="write"><a href="#write" class="headerlink" title="write"></a>write</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Interface for saving the content of the non-streaming Dataset out into external storage.</div><div class="line">  * </div><div class="line">  * 将非流Dataset的内容保存到外部存储中的接口。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span></span>: <span class="type">DataFrameWriter</span>[<span class="type">T</span>] = &#123;</div><div class="line">  <span class="keyword">if</span> (isStreaming) &#123;</div><div class="line">    logicalPlan.failAnalysis(</div><div class="line">      <span class="string">"'write' can not be called on streaming Dataset/DataFrame"</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">new</span> <span class="type">DataFrameWriter</span>[<span class="type">T</span>](<span class="keyword">this</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="writeStream"><a href="#writeStream" class="headerlink" title="writeStream"></a>writeStream</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * Interface for saving the content of the streaming Dataset out into external storage.</div><div class="line">  *</div><div class="line">  * 将流Dataset保存在外部存储。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">writeStream</span></span>: <span class="type">DataStreamWriter</span>[<span class="type">T</span>] = &#123;</div><div class="line">  <span class="keyword">if</span> (!isStreaming) &#123;</div><div class="line">    logicalPlan.failAnalysis(</div><div class="line">      <span class="string">"'writeStream' can be called only on streaming Dataset/DataFrame"</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">new</span> <span class="type">DataStreamWriter</span>[<span class="type">T</span>](<span class="keyword">this</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="toJSON"><a href="#toJSON" class="headerlink" title="toJSON"></a>toJSON</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the content of the Dataset as a Dataset of JSON strings.</div><div class="line">  *</div><div class="line">  * 将Dataset转换为JSON。</div><div class="line">  *</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">toJSON</span></span>: <span class="type">Dataset</span>[<span class="type">String</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> rowSchema = <span class="keyword">this</span>.schema</div><div class="line">  <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = queryExecution.toRdd.mapPartitions &#123; iter =&gt;</div><div class="line">    <span class="keyword">val</span> writer = <span class="keyword">new</span> <span class="type">CharArrayWriter</span>()</div><div class="line">    <span class="comment">// create the Generator without separator inserted between 2 records</span></div><div class="line">    <span class="keyword">val</span> gen = <span class="keyword">new</span> <span class="type">JacksonGenerator</span>(rowSchema, writer)</div><div class="line"></div><div class="line">    <span class="keyword">new</span> <span class="type">Iterator</span>[<span class="type">String</span>] &#123;</div><div class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = iter.hasNext</div><div class="line"></div><div class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">String</span> = &#123;</div><div class="line">        gen.write(iter.next())</div><div class="line">        gen.flush()</div><div class="line"></div><div class="line">        <span class="keyword">val</span> json = writer.toString</div><div class="line">        <span class="keyword">if</span> (hasNext) &#123;</div><div class="line">          writer.reset()</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          gen.close()</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        json</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">import</span> sparkSession.implicits.newStringEncoder</div><div class="line">  sparkSession.createDataset(rdd)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="inputFiles"><a href="#inputFiles" class="headerlink" title="inputFiles"></a>inputFiles</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a best-effort snapshot of the files that compose this Dataset. This method simply</div><div class="line">  * asks each constituent BaseRelation for its respective files and takes the union of all results.</div><div class="line">  * Depending on the source relations, this may not find all input files. Duplicates are removed.</div><div class="line">  *</div><div class="line">  * 返回组成这个Dataset的所有文件的最佳快照。</div><div class="line">  * 该方法简单地要求每个组件BaseRelation对其各自的文件进行处理，并联合所有结果。</div><div class="line">  * 基于源关系，应该可以找到所有的输入文件。</div><div class="line">  * 重复的也会被移除。</div><div class="line">  *</div><div class="line">  * @group basic</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">inputFiles</span></span>: <span class="type">Array</span>[<span class="type">String</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> files: <span class="type">Seq</span>[<span class="type">String</span>] = queryExecution.optimizedPlan.collect &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">LogicalRelation</span>(fsBasedRelation: <span class="type">FileRelation</span>, _, _) =&gt;</div><div class="line">      fsBasedRelation.inputFiles</div><div class="line">    <span class="keyword">case</span> fr: <span class="type">FileRelation</span> =&gt;</div><div class="line">      fr.inputFiles</div><div class="line">  &#125;.flatten</div><div class="line">  files.toSet.toArray</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="streaming"><a href="#streaming" class="headerlink" title="streaming"></a>streaming</h2><h3 id="isStreaming"><a href="#isStreaming" class="headerlink" title="isStreaming"></a>isStreaming</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns true if this Dataset contains one or more sources that continuously</div><div class="line">  * return data as it arrives. A Dataset that reads data from a streaming source</div><div class="line">  * must be executed as a `StreamingQuery` using the `start()` method in</div><div class="line">  * `DataStreamWriter`. Methods that return a single answer, e.g. `count()` or</div><div class="line">  * `collect()`, will throw an [[AnalysisException]] when there is a streaming</div><div class="line">  * source present.</div><div class="line">  * </div><div class="line">  * 如果Dataset包含一个或多个持续返回数据的源，则返回true；</div><div class="line">  * 如果Dataset从streaming源读取数据，则必须像 `StreamingQuery` 一样执行：使用 `DataStreamWriter` 中的 `start()`方法。</div><div class="line">  * 返回单个值的方法，例如： `count()` or `collect()`，当存在streaming源时，将会抛出[[AnalysisException]]。</div><div class="line">  *</div><div class="line">  * @group streaming</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">isStreaming</span></span>: <span class="type">Boolean</span> = logicalPlan.isStreaming</div></pre></td></tr></table></figure>
<h3 id="withWatermark"><a href="#withWatermark" class="headerlink" title="withWatermark"></a>withWatermark</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental :: 实验性的</div><div class="line">  * Defines an event time watermark for this [[Dataset]]. A watermark tracks a point in time</div><div class="line">  * before which we assume no more late data is going to arrive.</div><div class="line">  * </div><div class="line">  * 为这个[[Dataset]]定义事件时间水印。</div><div class="line">  * 我们假设没有更多的晚期数据将到达之前，一个水印跟踪一个时间点。</div><div class="line">  *</div><div class="line">  * Spark will use this watermark for several purposes:</div><div class="line">  * Spark用水印有几个目的：</div><div class="line">  *  - To know when a given time window aggregation can be finalized and thus can be emitted when</div><div class="line">  * using output modes that do not allow updates.</div><div class="line">  * </div><div class="line">  * 可以知道何时完成给定的时间窗口聚合能够完成，因此当使用不允许更新的输出模式时能够被放出。</div><div class="line">  *  - To minimize the amount of state that we need to keep for on-going aggregations.</div><div class="line">  * 为了最小化我们需要持续不断的聚合的状态数量。</div><div class="line">  *</div><div class="line">  *</div><div class="line">  * The current watermark is computed by looking at the `MAX(eventTime)` seen across</div><div class="line">  * all of the partitions in the query minus a user specified `delayThreshold`.  Due to the cost</div><div class="line">  * of coordinating this value across partitions, the actual watermark used is only guaranteed</div><div class="line">  * to be at least `delayThreshold` behind the actual event time.  In some cases we may still</div><div class="line">  * process records that arrive more than `delayThreshold` late.</div><div class="line">  * </div><div class="line">  * 当前的水印 = 查看查询中所有分区上看到的`MAX(eventTime)` - 用户指定的`delayThreshold`</div><div class="line">  * 由于在分区之间协调这个值的花销，实际使用的水印只保证在实际事件时间后至少是“delayThreshold”。</div><div class="line">  * 在某些情况下，我们可能还会处理比“delayThreshold”晚些时候到达的记录。</div><div class="line">  *</div><div class="line">  * @param eventTime      the name of the column that contains the event time of the row.</div><div class="line">  *                       包含行的事件时间的列名</div><div class="line">  * @param delayThreshold the minimum delay to wait to data to arrive late, relative to the latest</div><div class="line">  *                       record that has been processed in the form of an interval</div><div class="line">  *                       (e.g. "1 minute" or "5 hours").</div><div class="line">  *                       等待晚到数据的最少延迟，相对于以间隔形式处理的最新记录</div><div class="line">  * @group streaming</div><div class="line">  * @since 2.1.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="comment">// We only accept an existing column name, not a derived column here as a watermark that is</span></div><div class="line"><span class="comment">// defined on a derived column cannot referenced elsewhere in the plan.</span></div><div class="line"><span class="comment">// 我们只接受一个现有的列名，而不是作为一个在派生列上定义的水印的派生列，而不能在该计划的其他地方引用。</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">withWatermark</span></span>(eventTime: <span class="type">String</span>, delayThreshold: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">  <span class="keyword">val</span> parsedDelay =</div><div class="line">    <span class="type">Option</span>(<span class="type">CalendarInterval</span>.fromString(<span class="string">"interval "</span> + delayThreshold))</div><div class="line">      .getOrElse(<span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">AnalysisException</span>(<span class="string">s"Unable to parse time delay '<span class="subst">$delayThreshold</span>'"</span>))</div><div class="line">  <span class="type">EventTimeWatermark</span>(<span class="type">UnresolvedAttribute</span>(eventTime), parsedDelay, logicalPlan)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="action"><a href="#action" class="headerlink" title="action"></a>action</h2><h3 id="show"><a href="#show" class="headerlink" title="show"></a>show</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Displays the Dataset in a tabular form. Strings more than 20 characters will be truncated,</div><div class="line">  * and all cells will be aligned right. For example:</div><div class="line">  * </div><div class="line">  * 以表格形式显示数据集。</div><div class="line">  * 字符串超过20个字符将被截断，</div><div class="line">  * 所有单元格将被对齐。</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   year  month AVG('Adj Close) MAX('Adj Close)</div><div class="line">  *   1980  12    0.503218        0.595103</div><div class="line">  *   1981  01    0.523289        0.570307</div><div class="line">  *   1982  02    0.436504        0.475256</div><div class="line">  *   1983  03    0.410516        0.442194</div><div class="line">  *   1984  04    0.450090        0.483521</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @param numRows Number of rows to show 要显示的行数</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span></span>(numRows: <span class="type">Int</span>): <span class="type">Unit</span> = show(numRows, truncate = <span class="literal">true</span>)</div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Displays the top 20 rows of Dataset in a tabular form. Strings more than 20 characters</div><div class="line">  * will be truncated, and all cells will be aligned right.</div><div class="line">  * 显示头20行</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span></span>(): <span class="type">Unit</span> = show(<span class="number">20</span>)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Displays the top 20 rows of Dataset in a tabular form.</div><div class="line">  * 显示头20行</div><div class="line">  *</div><div class="line">  * @param truncate Whether truncate long strings. If true, strings more than 20 characters will</div><div class="line">  *                 be truncated and all cells will be aligned right</div><div class="line">  *                 是否截断长字符串。如果 true：超过20个字符就会被截断</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span></span>(truncate: <span class="type">Boolean</span>): <span class="type">Unit</span> = show(<span class="number">20</span>, truncate)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Displays the Dataset in a tabular form. For example:</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   year  month AVG('Adj Close) MAX('Adj Close)</div><div class="line">  *   1980  12    0.503218        0.595103</div><div class="line">  *   1981  01    0.523289        0.570307</div><div class="line">  *   1982  02    0.436504        0.475256</div><div class="line">  *   1983  03    0.410516        0.442194</div><div class="line">  *   1984  04    0.450090        0.483521</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @param numRows  Number of rows to show 显示的行数</div><div class="line">  * @param truncate Whether truncate long strings. If true, strings more than 20 characters will</div><div class="line">  *                 be truncated and all cells will be aligned right</div><div class="line">  *                 是否截断长字符串</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="comment">// scalastyle:off println</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span></span>(numRows: <span class="type">Int</span>, truncate: <span class="type">Boolean</span>): <span class="type">Unit</span> = <span class="keyword">if</span> (truncate) &#123;</div><div class="line">  println(showString(numRows, truncate = <span class="number">20</span>))</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">  println(showString(numRows, truncate = <span class="number">0</span>))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// scalastyle:on println</span></div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Displays the Dataset in a tabular form. For example:</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   year  month AVG('Adj Close) MAX('Adj Close)</div><div class="line">  *   1980  12    0.503218        0.595103</div><div class="line">  *   1981  01    0.523289        0.570307</div><div class="line">  *   1982  02    0.436504        0.475256</div><div class="line">  *   1983  03    0.410516        0.442194</div><div class="line">  *   1984  04    0.450090        0.483521</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @param numRows  Number of rows to show</div><div class="line">  * @param truncate If set to more than 0, truncates strings to `truncate` characters and</div><div class="line">  *                 all cells will be aligned right.</div><div class="line">  *                 设置 触发截断字符串的阈值</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="comment">// scalastyle:off println</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span></span>(numRows: <span class="type">Int</span>, truncate: <span class="type">Int</span>): <span class="type">Unit</span> = println(showString(numRows, truncate))</div></pre></td></tr></table></figure>
<h3 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Scala-specific)</div><div class="line">  * Reduces the elements of this Dataset using the specified binary function. The given `func`</div><div class="line">  * must be commutative and associative or the result may be non-deterministic.</div><div class="line">  *</div><div class="line">  * 使用指定的二进制函数减少这个数据集的元素。给定的“func”必须是可交换的和关联的，否则结果可能是不确定性的。</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(func: (<span class="type">T</span>, <span class="type">T</span>) =&gt; <span class="type">T</span>): <span class="type">T</span> = rdd.reduce(func)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Java-specific)</div><div class="line">  * Reduces the elements of this Dataset using the specified binary function. The given `func`</div><div class="line">  * must be commutative and associative or the result may be non-deterministic.</div><div class="line">  * </div><div class="line">  * 使用指定的二进制函数减少这个数据集的元素。给定的“func”必须是可交换的和关联的，否则结果可能是不确定性的。</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(func: <span class="type">ReduceFunction</span>[<span class="type">T</span>]): <span class="type">T</span> = reduce(func.call(_, _))</div></pre></td></tr></table></figure>
<h3 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Computes statistics for numeric and string columns, including count, mean, stddev, min, and</div><div class="line">   * max. If no columns are given, this function computes statistics for all numerical or string</div><div class="line">   * columns.</div><div class="line">   *</div><div class="line">   * 计算数字和字符串列的统计数据，包括count、mean、stddev、min和max。</div><div class="line">   * 如果没有给出任何列，该函数计算所有数值或字符串列的统计信息。</div><div class="line">   *</div><div class="line">   * This function is meant for exploratory data analysis, as we make no guarantee about the</div><div class="line">   * backward compatibility of the schema of the resulting Dataset. If you want to</div><div class="line">   * programmatically compute summary statistics, use the `agg` function instead.</div><div class="line">   *</div><div class="line">   * 这个函数用于探索性的数据分析，因为我们不能保证生成数据集的模式的向后兼容性。</div><div class="line">   * 如果您想通过编程计算汇总统计信息，可以使用“agg”函数。</div><div class="line">   *</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   ds.describe("age", "height").show()</div><div class="line">   *</div><div class="line">   *   // output:</div><div class="line">   *   // summary age   height</div><div class="line">   *   // count   10.0  10.0</div><div class="line">   *   // mean    53.3  178.05</div><div class="line">   *   // stddev  11.6  15.7</div><div class="line">   *   // min     18.0  163.0</div><div class="line">   *   // max     92.0  192.0</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   *</div><div class="line">   * @group action</div><div class="line">   * @since 1.6.0</div><div class="line">   */</div><div class="line"> <span class="meta">@scala</span>.annotation.varargs</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">describe</span></span>(cols: <span class="type">String</span>*): <span class="type">DataFrame</span> = withPlan &#123;</div><div class="line"></div><div class="line">   <span class="comment">// The list of summary statistics to compute, in the form of expressions.</span></div><div class="line">   <span class="keyword">val</span> statistics = <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Expression</span> =&gt; <span class="type">Expression</span>)](</div><div class="line">     <span class="string">"count"</span> -&gt; ((child: <span class="type">Expression</span>) =&gt; <span class="type">Count</span>(child).toAggregateExpression()),</div><div class="line">     <span class="string">"mean"</span> -&gt; ((child: <span class="type">Expression</span>) =&gt; <span class="type">Average</span>(child).toAggregateExpression()),</div><div class="line">     <span class="string">"stddev"</span> -&gt; ((child: <span class="type">Expression</span>) =&gt; <span class="type">StddevSamp</span>(child).toAggregateExpression()),</div><div class="line">     <span class="string">"min"</span> -&gt; ((child: <span class="type">Expression</span>) =&gt; <span class="type">Min</span>(child).toAggregateExpression()),</div><div class="line">     <span class="string">"max"</span> -&gt; ((child: <span class="type">Expression</span>) =&gt; <span class="type">Max</span>(child).toAggregateExpression()))</div><div class="line"></div><div class="line">   <span class="keyword">val</span> outputCols =</div><div class="line">     (<span class="keyword">if</span> (cols.isEmpty) aggregatableColumns.map(usePrettyExpression(_).sql) <span class="keyword">else</span> cols).toList</div><div class="line"></div><div class="line">   <span class="keyword">val</span> ret: <span class="type">Seq</span>[<span class="type">Row</span>] = <span class="keyword">if</span> (outputCols.nonEmpty) &#123;</div><div class="line">     <span class="keyword">val</span> aggExprs = statistics.flatMap &#123; <span class="keyword">case</span> (_, colToAgg) =&gt;</div><div class="line">       outputCols.map(c =&gt; <span class="type">Column</span>(<span class="type">Cast</span>(colToAgg(<span class="type">Column</span>(c).expr), <span class="type">StringType</span>)).as(c))</div><div class="line">     &#125;</div><div class="line"></div><div class="line">     <span class="keyword">val</span> row = groupBy().agg(aggExprs.head, aggExprs.tail: _*).head().toSeq</div><div class="line"></div><div class="line">     <span class="comment">// Pivot the data so each summary is one row</span></div><div class="line">     row.grouped(outputCols.size).toSeq.zip(statistics).map &#123; <span class="keyword">case</span> (aggregation, (statistic, _)) =&gt;</div><div class="line">       <span class="type">Row</span>(statistic :: aggregation.toList: _*)</div><div class="line">     &#125;</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">     <span class="comment">// If there are no output columns, just output a single column that contains the stats.</span></div><div class="line">     statistics.map &#123; <span class="keyword">case</span> (name, _) =&gt; <span class="type">Row</span>(name) &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="comment">// All columns are string type</span></div><div class="line">   <span class="keyword">val</span> schema = <span class="type">StructType</span>(</div><div class="line">     <span class="type">StructField</span>(<span class="string">"summary"</span>, <span class="type">StringType</span>) :: outputCols.map(<span class="type">StructField</span>(_, <span class="type">StringType</span>))).toAttributes</div><div class="line">   <span class="comment">// `toArray` forces materialization to make the seq serializable</span></div><div class="line">   <span class="type">LocalRelation</span>.fromExternalRows(schema, ret.toArray.toSeq)</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<h3 id="head"><a href="#head" class="headerlink" title="head"></a>head</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the first `n` rows.</div><div class="line">  *</div><div class="line">  * 返回前n行</div><div class="line">  *</div><div class="line">  * @note this method should only be used if the resulting array is expected to be small, as</div><div class="line">  *       all the data is loaded into the driver's memory.</div><div class="line">  *       仅适用于结果很少的时候使用，因为会将结果加载进内存中</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">head</span></span>(n: <span class="type">Int</span>): <span class="type">Array</span>[<span class="type">T</span>] = withTypedCallback(<span class="string">"head"</span>, limit(n)) &#123; df =&gt;</div><div class="line">  df.collect(needCallback = <span class="literal">false</span>)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the first row.</div><div class="line">  *</div><div class="line">  * 返回第一行（默认1）</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">head</span></span>(): <span class="type">T</span> = head(<span class="number">1</span>).head</div></pre></td></tr></table></figure>
<h3 id="first"><a href="#first" class="headerlink" title="first"></a>first</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the first row. Alias for head().</div><div class="line">  *</div><div class="line">  * 返回第一行 ，与head()一样</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">first</span></span>(): <span class="type">T</span> = head()</div></pre></td></tr></table></figure>
<h3 id="foreach"><a href="#foreach" class="headerlink" title="foreach"></a>foreach</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Applies a function `f` to all rows.</div><div class="line">  *</div><div class="line">  * 对所有行应用函数f。</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreach</span></span>(f: <span class="type">T</span> =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = withNewExecutionId &#123;</div><div class="line">  rdd.foreach(f)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * (Java-specific)</div><div class="line">  * Runs `func` on each element of this Dataset.</div><div class="line">  *</div><div class="line">  * 在这个数据集的每个元素上运行“func”。</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreach</span></span>(func: <span class="type">ForeachFunction</span>[<span class="type">T</span>]): <span class="type">Unit</span> = foreach(func.call(_))</div></pre></td></tr></table></figure>
<h3 id="foreachPartition"><a href="#foreachPartition" class="headerlink" title="foreachPartition"></a>foreachPartition</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Applies a function `f` to each partition of this Dataset.</div><div class="line">  *</div><div class="line">  * 对这个数据集的每个分区应用一个函数f。</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreachPartition</span></span>(f: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = withNewExecutionId &#123;</div><div class="line">  rdd.foreachPartition(f)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * (Java-specific)</div><div class="line">  * Runs `func` on each partition of this Dataset.</div><div class="line">  *</div><div class="line">  * 对这个数据集的每个分区应用一个函数f。</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreachPartition</span></span>(func: <span class="type">ForeachPartitionFunction</span>[<span class="type">T</span>]): <span class="type">Unit</span> =</div><div class="line">  foreachPartition(it =&gt; func.call(it.asJava))</div></pre></td></tr></table></figure>
<h3 id="take"><a href="#take" class="headerlink" title="take"></a>take</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the first `n` rows in the Dataset.</div><div class="line">  *</div><div class="line">  * 返回数据集中的前“n”行。</div><div class="line">  * 同head(n)</div><div class="line">  *</div><div class="line">  * Running take requires moving data into the application's driver process, and doing so with</div><div class="line">  * a very large `n` can crash the driver process with OutOfMemoryError.</div><div class="line">  *</div><div class="line">  * take在driver端执行，n太大会造成oom</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">take</span></span>(n: <span class="type">Int</span>): <span class="type">Array</span>[<span class="type">T</span>] = head(n)</div></pre></td></tr></table></figure>
<h3 id="takeAsList"><a href="#takeAsList" class="headerlink" title="takeAsList"></a>takeAsList</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the first `n` rows in the Dataset as a list.</div><div class="line">  *</div><div class="line">  * 以List形式返回 前n行</div><div class="line">  *</div><div class="line">  * Running take requires moving data into the application's driver process, and doing so with</div><div class="line">  * a very large `n` can crash the driver process with OutOfMemoryError.</div><div class="line">  *</div><div class="line">  * take在driver端执行，n太大会造成oom</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeAsList</span></span>(n: <span class="type">Int</span>): java.util.<span class="type">List</span>[<span class="type">T</span>] = java.util.<span class="type">Arrays</span>.asList(take(n): _*)</div></pre></td></tr></table></figure>
<h3 id="collect"><a href="#collect" class="headerlink" title="collect"></a>collect</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns an array that contains all of [[Row]]s in this Dataset.</div><div class="line">  *</div><div class="line">  * 返回包含所有Row的 一个数组</div><div class="line">  *</div><div class="line">  * Running collect requires moving all the data into the application's driver process, and</div><div class="line">  * doing so on a very large dataset can crash the driver process with OutOfMemoryError.</div><div class="line">  *</div><div class="line">  * 会将所有数据移动到driver，所以可能会造成oom</div><div class="line">  *</div><div class="line">  * For Java API, use [[collectAsList]].</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>] = collect(needCallback = <span class="literal">true</span>)</div></pre></td></tr></table></figure>
<h3 id="collectAsList"><a href="#collectAsList" class="headerlink" title="collectAsList"></a>collectAsList</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a Java list that contains all of [[Row]]s in this Dataset.</div><div class="line">  *</div><div class="line">  * 返回包含所有Row的一个Java List</div><div class="line">  *</div><div class="line">  * Running collect requires moving all the data into the application's driver process, and</div><div class="line">  * doing so on a very large dataset can crash the driver process with OutOfMemoryError.</div><div class="line">  *</div><div class="line">  * 会将所有数据移动到driver，所以可能会造成oom</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">collectAsList</span></span>(): java.util.<span class="type">List</span>[<span class="type">T</span>] = withCallback(<span class="string">"collectAsList"</span>, toDF()) &#123; _ =&gt;</div><div class="line">  withNewExecutionId &#123;</div><div class="line">    <span class="keyword">val</span> values = queryExecution.executedPlan.executeCollect().map(boundEnc.fromRow)</div><div class="line">    java.util.<span class="type">Arrays</span>.asList(values: _*)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="toLocalIterator"><a href="#toLocalIterator" class="headerlink" title="toLocalIterator"></a>toLocalIterator</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Return an iterator that contains all of [[Row]]s in this Dataset.</div><div class="line">  *</div><div class="line">  * 返回包含所有Row的一个迭代器</div><div class="line">  *</div><div class="line">  * The iterator will consume as much memory as the largest partition in this Dataset.</div><div class="line">  *</div><div class="line">  * 迭代器将消耗与此数据集中最大的分区一样多的内存。</div><div class="line">  *</div><div class="line">  * @note this results in multiple Spark jobs, and if the input Dataset is the result</div><div class="line">  *       of a wide transformation (e.g. join with different partitioners), to avoid</div><div class="line">  *       recomputing the input Dataset should be cached first.</div><div class="line">  *       这将导致多个Spark作业，如果输入数据集是宽依赖转换的结果(例如，与不同的分区连接)，</div><div class="line">  *       那么为了避免重新计算输入数据，应该首先缓存输入数据集。</div><div class="line">  * @group action</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">toLocalIterator</span></span>(): java.util.<span class="type">Iterator</span>[<span class="type">T</span>] = withCallback(<span class="string">"toLocalIterator"</span>, toDF()) &#123; _ =&gt;</div><div class="line">  withNewExecutionId &#123;</div><div class="line">    queryExecution.executedPlan.executeToIterator().map(boundEnc.fromRow).asJava</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="count"><a href="#count" class="headerlink" title="count"></a>count</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns the number of rows in the Dataset.</div><div class="line">  *</div><div class="line">  * 返回总行数</div><div class="line">  *</div><div class="line">  * @group action</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span></span>(): <span class="type">Long</span> = withCallback(<span class="string">"count"</span>, groupBy().count()) &#123; df =&gt;</div><div class="line">  df.collect(needCallback = <span class="literal">false</span>).head.getLong(<span class="number">0</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="untypedrel-无类型转换"><a href="#untypedrel-无类型转换" class="headerlink" title="untypedrel-无类型转换"></a>untypedrel-无类型转换</h2><h3 id="na"><a href="#na" class="headerlink" title="na"></a>na</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a [[DataFrameNaFunctions]] for working with missing data.</div><div class="line">  * 返回一个用于处理丢失数据的[[DataFrameNaFunctions]]。</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   // Dropping rows containing any null values. 删除包含任何null 值的行</div><div class="line">  *   ds.na.drop()</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">na</span></span>: <span class="type">DataFrameNaFunctions</span> = <span class="keyword">new</span> <span class="type">DataFrameNaFunctions</span>(toDF())</div></pre></td></tr></table></figure>
<h3 id="stat"><a href="#stat" class="headerlink" title="stat"></a>stat</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a [[DataFrameStatFunctions]] for working statistic functions support.</div><div class="line">  * 返回用于支持统计功能的[[DataFrameStatFunctions]]。</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   // Finding frequent items in column with name 'a'. 查询列名为"a"中的频繁数据。</div><div class="line">  *   ds.stat.freqItems(Seq("a"))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stat</span></span>: <span class="type">DataFrameStatFunctions</span> = <span class="keyword">new</span> <span class="type">DataFrameStatFunctions</span>(toDF())</div></pre></td></tr></table></figure>
<h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Join with another `DataFrame`.</div><div class="line">    * 和 另一个 `DataFrame`  jion</div><div class="line">    *</div><div class="line">    * Behaves as an INNER JOIN and requires a subsequent join predicate.</div><div class="line">    * 作为一个内部连接，并需要一个后续的连接谓词。</div><div class="line">    *</div><div class="line">    * @param right Right side of the join operation. join操作的右侧</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">join</span></span>(right: <span class="type">Dataset</span>[_]): <span class="type">DataFrame</span> = withPlan &#123;</div><div class="line">    <span class="type">Join</span>(logicalPlan, right.logicalPlan, joinType = <span class="type">Inner</span>, <span class="type">None</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Inner equi-join with another `DataFrame` using the given column.</div><div class="line">    * 给定列名的内部等值连接</div><div class="line">    *</div><div class="line">    * Different from other join functions, the join column will only appear once in the output,</div><div class="line">    * i.e. similar to SQL's `JOIN USING` syntax.</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // Joining df1 and df2 using the column "user_id" 用"user_id"  连接 df1 和df2</div><div class="line">    *   df1.join(df2, "user_id")</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @param right       Right side of the join operation. join连接右侧</div><div class="line">    * @param usingColumn Name of the column to join on. This column must exist on both sides.</div><div class="line">    *                    列名。必须在两边都存在</div><div class="line">    * @note If you perform a self-join using this function without aliasing the input</div><div class="line">    *       `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class="line">    *       there is no way to disambiguate which side of the join you would like to reference.</div><div class="line">    *       自连接的时候，请指定 表别名。不然干不了事</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">join</span></span>(right: <span class="type">Dataset</span>[_], usingColumn: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">    join(right, <span class="type">Seq</span>(usingColumn))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Inner equi-join with another `DataFrame` using the given columns.</div><div class="line">    * 根据指定多个列进行join</div><div class="line">    *</div><div class="line">    * Different from other join functions, the join columns will only appear once in the output,</div><div class="line">    * i.e. similar to SQL's `JOIN USING` syntax.</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // Joining df1 and df2 using the columns "user_id" and "user_name"</div><div class="line">    *   df1.join(df2, Seq("user_id", "user_name"))</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @param right        Right side of the join operation.</div><div class="line">    * @param usingColumns Names of the columns to join on. This columns must exist on both sides.</div><div class="line">    * @note If you perform a self-join using this function without aliasing the input</div><div class="line">    *       `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class="line">    *       there is no way to disambiguate which side of the join you would like to reference.</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">join</span></span>(right: <span class="type">Dataset</span>[_], usingColumns: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">DataFrame</span> = &#123;</div><div class="line">    join(right, usingColumns, <span class="string">"inner"</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Equi-join with another `DataFrame` using the given columns.</div><div class="line">    *</div><div class="line">    * Different from other join functions, the join columns will only appear once in the output,</div><div class="line">    * i.e. similar to SQL's `JOIN USING` syntax.</div><div class="line">    *</div><div class="line">    * @param right        Right side of the join operation.</div><div class="line">    * @param usingColumns Names of the columns to join on. This columns must exist on both sides.</div><div class="line">    * @param joinType     One of: `inner`, `outer`, `left_outer`, `right_outer`, `leftsemi`.</div><div class="line">    *                     连接类型：内连接，外连接，左外连接，右外连接，左内连接</div><div class="line">    * @note If you perform a self-join using this function without aliasing the input</div><div class="line">    *       `DataFrame`s, you will NOT be able to reference any columns after the join, since</div><div class="line">    *       there is no way to disambiguate which side of the join you would like to reference.</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">join</span></span>(right: <span class="type">Dataset</span>[_], usingColumns: <span class="type">Seq</span>[<span class="type">String</span>], joinType: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">    <span class="comment">// Analyze the self join. The assumption is that the analyzer will disambiguate left vs right</span></div><div class="line">    <span class="comment">// by creating a new instance for one of the branch.</span></div><div class="line">    <span class="comment">// 自连接的时候，为其中一个分支创建一个新实例来消除左vs右的歧义。</span></div><div class="line">    <span class="keyword">val</span> joined = sparkSession.sessionState.executePlan(</div><div class="line">      <span class="type">Join</span>(logicalPlan, right.logicalPlan, joinType = <span class="type">JoinType</span>(joinType), <span class="type">None</span>))</div><div class="line">      .analyzed.asInstanceOf[<span class="type">Join</span>]</div><div class="line"></div><div class="line">    withPlan &#123;</div><div class="line">      <span class="type">Join</span>(</div><div class="line">        joined.left,</div><div class="line">        joined.right,</div><div class="line">        <span class="type">UsingJoin</span>(<span class="type">JoinType</span>(joinType), usingColumns),</div><div class="line">        <span class="type">None</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Inner join with another `DataFrame`, using the given join expression.</div><div class="line">    * 用给定的表达式进行join</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // The following two are equivalent:</div><div class="line">    *   df1.join(df2, $"df1Key" === $"df2Key")</div><div class="line">    *   df1.join(df2).where($"df1Key" === $"df2Key")</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">join</span></span>(right: <span class="type">Dataset</span>[_], joinExprs: <span class="type">Column</span>): <span class="type">DataFrame</span> = join(right, joinExprs, <span class="string">"inner"</span>)</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Join with another `DataFrame`, using the given join expression. The following performs</div><div class="line">    * a full outer join between `df1` and `df2`.</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // Scala:</div><div class="line">    *   import org.apache.spark.sql.functions._</div><div class="line">    *   df1.join(df2, $"df1Key" === $"df2Key", "outer")</div><div class="line">    *</div><div class="line">    *   // Java:</div><div class="line">    *   import static org.apache.spark.sql.functions.*;</div><div class="line">    *   df1.join(df2, col("df1Key").equalTo(col("df2Key")), "outer");</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @param right     Right side of the join.</div><div class="line">    * @param joinExprs Join expression.</div><div class="line">    * @param joinType  One of: `inner`, `outer`, `left_outer`, `right_outer`, `leftsemi`.</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">join</span></span>(right: <span class="type">Dataset</span>[_], joinExprs: <span class="type">Column</span>, joinType: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">    <span class="comment">// Note that in this function, we introduce a hack in the case of self-join to automatically</span></div><div class="line">    <span class="comment">// resolve ambiguous join conditions into ones that might make sense [SPARK-6231].</span></div><div class="line">    <span class="comment">// Consider this case: df.join(df, df("key") === df("key"))</span></div><div class="line">    <span class="comment">// Since df("key") === df("key") is a trivially true condition, this actually becomes a</span></div><div class="line">    <span class="comment">// cartesian join. However, most likely users expect to perform a self join using "key".</span></div><div class="line">    <span class="comment">// With that assumption, this hack turns the trivially true condition into equality on join</span></div><div class="line">    <span class="comment">// keys that are resolved to both sides.</span></div><div class="line"></div><div class="line">    <span class="comment">// Trigger analysis so in the case of self-join, the analyzer will clone the plan.</span></div><div class="line">    <span class="comment">// After the cloning, left and right side will have distinct expression ids.</span></div><div class="line">    <span class="comment">// 针对自连接的优化：正常情况下，自连接如果使用  df.join(df, df("key") === df("key"))</span></div><div class="line">    <span class="comment">// 会造成 笛卡尔积</span></div><div class="line">    <span class="comment">// 这种情况下，分析器会 克隆计划，克隆完成后，左右两边则有不同的 id</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> plan = withPlan(</div><div class="line">      <span class="type">Join</span>(logicalPlan, right.logicalPlan, <span class="type">JoinType</span>(joinType), <span class="type">Some</span>(joinExprs.expr)))</div><div class="line">      .queryExecution.analyzed.asInstanceOf[<span class="type">Join</span>]</div><div class="line"></div><div class="line">    <span class="comment">// If auto self join alias is disabled, return the plan.</span></div><div class="line">    <span class="keyword">if</span> (!sparkSession.sessionState.conf.dataFrameSelfJoinAutoResolveAmbiguity) &#123;</div><div class="line">      <span class="keyword">return</span> withPlan(plan)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// If left/right have no output set intersection, return the plan.</span></div><div class="line">    <span class="keyword">val</span> lanalyzed = withPlan(<span class="keyword">this</span>.logicalPlan).queryExecution.analyzed</div><div class="line">    <span class="keyword">val</span> ranalyzed = withPlan(right.logicalPlan).queryExecution.analyzed</div><div class="line">    <span class="keyword">if</span> (lanalyzed.outputSet.intersect(ranalyzed.outputSet).isEmpty) &#123;</div><div class="line">      <span class="keyword">return</span> withPlan(plan)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Otherwise, find the trivially true predicates and automatically resolves them to both sides.</span></div><div class="line">    <span class="comment">// By the time we get here, since we have already run analysis, all attributes should've been</span></div><div class="line">    <span class="comment">// resolved and become AttributeReference.</span></div><div class="line">    <span class="keyword">val</span> cond = plan.condition.map &#123;</div><div class="line">      _.transform &#123;</div><div class="line">        <span class="keyword">case</span> catalyst.expressions.<span class="type">EqualTo</span>(a: <span class="type">AttributeReference</span>, b: <span class="type">AttributeReference</span>)</div><div class="line">          <span class="keyword">if</span> a.sameRef(b) =&gt;</div><div class="line">          catalyst.expressions.<span class="type">EqualTo</span>(</div><div class="line">            withPlan(plan.left).resolve(a.name),</div><div class="line">            withPlan(plan.right).resolve(b.name))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    withPlan &#123;</div><div class="line">      plan.copy(condition = cond)</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="crossJoin"><a href="#crossJoin" class="headerlink" title="crossJoin"></a>crossJoin</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Explicit cartesian join with another `DataFrame`.</div><div class="line">  * 显式笛卡尔积join</div><div class="line">  *</div><div class="line">  * @param right Right side of the join operation.</div><div class="line">  * @note Cartesian joins are very expensive without an extra filter that can be pushed down.</div><div class="line">  *       如果没有额外的过滤器，笛卡尔连接非常昂贵。</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.1.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">crossJoin</span></span>(right: <span class="type">Dataset</span>[_]): <span class="type">DataFrame</span> = withPlan &#123;</div><div class="line">  <span class="type">Join</span>(logicalPlan, right.logicalPlan, joinType = <span class="type">Cross</span>, <span class="type">None</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="apply"><a href="#apply" class="headerlink" title="apply"></a>apply</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Selects column based on the column name and return it as a [[Column]].</div><div class="line">  *</div><div class="line">  * 选择基于列名的列，并将其作为[[Column]]返回。</div><div class="line">  *</div><div class="line">  * @note The column name can also reference to a nested column like `a.b`.</div><div class="line">  *</div><div class="line">  *       列名也可以引用像“a.b”这样的嵌套列。</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(colName: <span class="type">String</span>): <span class="type">Column</span> = col(colName)</div></pre></td></tr></table></figure>
<h3 id="col"><a href="#col" class="headerlink" title="col"></a>col</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Selects column based on the column name and return it as a [[Column]].</div><div class="line">  *</div><div class="line">  * 选择基于列名的列，并将其作为[[Column]]返回。</div><div class="line">  *</div><div class="line">  * @note The column name can also reference to a nested column like `a.b`.</div><div class="line">  *</div><div class="line">  *       列名也可以引用像“a.b”这样的嵌套列。</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">col</span></span>(colName: <span class="type">String</span>): <span class="type">Column</span> = colName <span class="keyword">match</span> &#123;</div><div class="line">  <span class="keyword">case</span> <span class="string">"*"</span> =&gt;</div><div class="line">    <span class="type">Column</span>(<span class="type">ResolvedStar</span>(queryExecution.analyzed.output))</div><div class="line">  <span class="keyword">case</span> _ =&gt;</div><div class="line">    <span class="keyword">val</span> expr = resolve(colName)</div><div class="line">    <span class="type">Column</span>(expr)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Selects a set of column based expressions.</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   ds.select($"colA", $"colB" + 1)</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">select</span></span>(cols: <span class="type">Column</span>*): <span class="type">DataFrame</span> = withPlan &#123;</div><div class="line">  <span class="type">Project</span>(cols.map(_.named), logicalPlan)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Selects a set of columns. This is a variant of `select` that can only select</div><div class="line">  * existing columns using column names (i.e. cannot construct expressions).</div><div class="line">  *</div><div class="line">  * 只能是已经存在的列名</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   // The following two are equivalent:</div><div class="line">  *   ds.select("colA", "colB")</div><div class="line">  *   ds.select($"colA", $"colB")</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">select</span></span>(col: <span class="type">String</span>, cols: <span class="type">String</span>*): <span class="type">DataFrame</span> = select((col +: cols).map(<span class="type">Column</span>(_)): _*)</div></pre></td></tr></table></figure>
<h3 id="selectExpr"><a href="#selectExpr" class="headerlink" title="selectExpr"></a>selectExpr</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Selects a set of SQL expressions. This is a variant of `select` that accepts</div><div class="line">  * SQL expressions.</div><div class="line">  *</div><div class="line">  * 接受SQL表达式</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   // The following are equivalent:</div><div class="line">  *   以下是等价的:</div><div class="line">  *   ds.selectExpr("colA", "colB as newName", "abs(colC)")</div><div class="line">  *   ds.select(expr("colA"), expr("colB as newName"), expr("abs(colC)"))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectExpr</span></span>(exprs: <span class="type">String</span>*): <span class="type">DataFrame</span> = &#123;</div><div class="line">  select(exprs.map &#123; expr =&gt;</div><div class="line">    <span class="type">Column</span>(sparkSession.sessionState.sqlParser.parseExpression(expr))</div><div class="line">  &#125;: _*)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="groupBy"><a href="#groupBy" class="headerlink" title="groupBy"></a>groupBy</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Groups the Dataset using the specified columns, so we can run aggregation on them. See</div><div class="line">  * [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class="line">  *</div><div class="line">  * 使用指定的列对数据集进行分组，这样我们就可以对它们进行聚合。</div><div class="line">  * 查看[[RelationalGroupedDataset]]为所有可用的聚合函数。</div><div class="line">  *</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   // Compute the average for all numeric columns grouped by department.</div><div class="line">  *</div><div class="line">  *   计算按部门分组的所有数字列的平均值。</div><div class="line">  *</div><div class="line">  *   ds.groupBy($"department").avg()</div><div class="line">  *</div><div class="line">  *   // Compute the max age and average salary, grouped by department and gender.</div><div class="line">  *   ds.groupBy($"department", $"gender").agg(Map(</div><div class="line">  *     "salary" -&gt; "avg",</div><div class="line">  *     "age" -&gt; "max"</div><div class="line">  *   ))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupBy</span></span>(cols: <span class="type">Column</span>*): <span class="type">RelationalGroupedDataset</span> = &#123;</div><div class="line">  <span class="type">RelationalGroupedDataset</span>(toDF(), cols.map(_.expr), <span class="type">RelationalGroupedDataset</span>.<span class="type">GroupByType</span>)</div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">  * Groups the Dataset using the specified columns, so that we can run aggregation on them.</div><div class="line">  * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class="line">  *</div><div class="line">  * This is a variant of groupBy that can only group by existing columns using column names</div><div class="line">  * (i.e. cannot construct expressions).</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   // Compute the average for all numeric columns grouped by department.</div><div class="line">  *   ds.groupBy("department").avg()</div><div class="line">  *</div><div class="line">  *   // Compute the max age and average salary, grouped by department and gender.</div><div class="line">  *   ds.groupBy($"department", $"gender").agg(Map(</div><div class="line">  *     "salary" -&gt; "avg",</div><div class="line">  *     "age" -&gt; "max"</div><div class="line">  *   ))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupBy</span></span>(col1: <span class="type">String</span>, cols: <span class="type">String</span>*): <span class="type">RelationalGroupedDataset</span> = &#123;</div><div class="line">  <span class="keyword">val</span> colNames: <span class="type">Seq</span>[<span class="type">String</span>] = col1 +: cols</div><div class="line">  <span class="type">RelationalGroupedDataset</span>(</div><div class="line">    toDF(), colNames.map(colName =&gt; resolve(colName)), <span class="type">RelationalGroupedDataset</span>.<span class="type">GroupByType</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="rollup"><a href="#rollup" class="headerlink" title="rollup"></a>rollup</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Create a multi-dimensional rollup for the current Dataset using the specified columns,</div><div class="line">    * so we can run aggregation on them.</div><div class="line">    * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class="line">    *</div><div class="line">    * 使用指定的列为当前数据集创建多维的汇总，因此我们可以在它们上运行聚合。</div><div class="line">    *</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // Compute the average for all numeric columns rolluped by department and group.</div><div class="line">    *</div><div class="line">    *   汇总后 求平均值</div><div class="line">    *</div><div class="line">    *   ds.rollup($"department", $"group").avg()</div><div class="line">    *</div><div class="line">    *   // Compute the max age and average salary, rolluped by department and gender.</div><div class="line">    *   ds.rollup($"department", $"gender").agg(Map(</div><div class="line">    *     "salary" -&gt; "avg",</div><div class="line">    *     "age" -&gt; "max"</div><div class="line">    *   ))</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rollup</span></span>(cols: <span class="type">Column</span>*): <span class="type">RelationalGroupedDataset</span> = &#123;</div><div class="line">    <span class="type">RelationalGroupedDataset</span>(toDF(), cols.map(_.expr), <span class="type">RelationalGroupedDataset</span>.<span class="type">RollupType</span>)</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">    <span class="comment">/**</span></div><div class="line">    * Create a multi-dimensional rollup for the current Dataset using the specified columns,</div><div class="line">    * so we can run aggregation on them.</div><div class="line">    * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class="line">    *</div><div class="line">    * 使用指定的列为当前数据集创建多维的rollup，因此我们可以在它们上运行聚合。</div><div class="line">    * rollup可以实现 从右到左一次递减的多级统计，显示统计某一层次结构的聚合</div><div class="line">    * 例如 rollup(a,b,c,d) =结果=&gt; (a,b,c,d),(a,b,c),(a,b),a</div><div class="line">    *</div><div class="line">    * This is a variant of rollup that can only group by existing columns using column names</div><div class="line">    * (i.e. cannot construct expressions).</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // Compute the average for all numeric columns rolluped by department and group.</div><div class="line">    *   ds.rollup("department", "group").avg()</div><div class="line">    *</div><div class="line">    *   // Compute the max age and average salary, rolluped by department and gender.</div><div class="line">    *   ds.rollup($"department", $"gender").agg(Map(</div><div class="line">    *     "salary" -&gt; "avg",</div><div class="line">    *     "age" -&gt; "max"</div><div class="line">    *   ))</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rollup</span></span>(col1: <span class="type">String</span>, cols: <span class="type">String</span>*): <span class="type">RelationalGroupedDataset</span> = &#123;</div><div class="line">    <span class="keyword">val</span> colNames: <span class="type">Seq</span>[<span class="type">String</span>] = col1 +: cols</div><div class="line">    <span class="type">RelationalGroupedDataset</span>(</div><div class="line">      toDF(), colNames.map(colName =&gt; resolve(colName)), <span class="type">RelationalGroupedDataset</span>.<span class="type">RollupType</span>)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="cube"><a href="#cube" class="headerlink" title="cube"></a>cube</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Create a multi-dimensional cube for the current Dataset using the specified columns,</div><div class="line">    * so we can run aggregation on them.</div><div class="line">    * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class="line">    *</div><div class="line">    * 使用指定的列为当前数据集创建多维数据集，因此我们可以在它们上运行聚合。</div><div class="line">    *</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // Compute the average for all numeric columns cubed by department and group.</div><div class="line">    *   ds.cube($"department", $"group").avg()</div><div class="line">    *</div><div class="line">    *   // Compute the max age and average salary, cubed by department and gender.</div><div class="line">    *   ds.cube($"department", $"gender").agg(Map(</div><div class="line">    *     "salary" -&gt; "avg",</div><div class="line">    *     "age" -&gt; "max"</div><div class="line">    *   ))</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">cube</span></span>(cols: <span class="type">Column</span>*): <span class="type">RelationalGroupedDataset</span> = &#123;</div><div class="line">    <span class="type">RelationalGroupedDataset</span>(toDF(), cols.map(_.expr), <span class="type">RelationalGroupedDataset</span>.<span class="type">CubeType</span>)</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">   <span class="comment">/**</span></div><div class="line">    * Create a multi-dimensional cube for the current Dataset using the specified columns,</div><div class="line">    * so we can run aggregation on them.</div><div class="line">    * See [[RelationalGroupedDataset]] for all the available aggregate functions.</div><div class="line">    *</div><div class="line">    * 魔方 例如：cube(a,b,c) =结果=&gt; (a,b),(a,c),a,(b,c),b,c 结果为所有的维度</div><div class="line">    * 使用指定的列为当前数据集创建多维多维数据集，因此我们可以在它们上运行聚合。</div><div class="line">    *</div><div class="line">    * This is a variant of cube that can only group by existing columns using column names</div><div class="line">    * (i.e. cannot construct expressions).</div><div class="line">    *</div><div class="line">    * 这是一个多维数据集的变体，它只能通过使用列名的现有列来分组</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // Compute the average for all numeric columns cubed by department and group.</div><div class="line">    *   ds.cube("department", "group").avg()</div><div class="line">    *</div><div class="line">    *   // Compute the max age and average salary, cubed by department and gender.</div><div class="line">    *   ds.cube($"department", $"gender").agg(Map(</div><div class="line">    *     "salary" -&gt; "avg",</div><div class="line">    *     "age" -&gt; "max"</div><div class="line">    *   ))</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group untypedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">cube</span></span>(col1: <span class="type">String</span>, cols: <span class="type">String</span>*): <span class="type">RelationalGroupedDataset</span> = &#123;</div><div class="line">    <span class="keyword">val</span> colNames: <span class="type">Seq</span>[<span class="type">String</span>] = col1 +: cols</div><div class="line">    <span class="type">RelationalGroupedDataset</span>(</div><div class="line">      toDF(), colNames.map(colName =&gt; resolve(colName)), <span class="type">RelationalGroupedDataset</span>.<span class="type">CubeType</span>)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="agg"><a href="#agg" class="headerlink" title="agg"></a>agg</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * (Scala-specific) Aggregates on the entire Dataset without groups.</div><div class="line">   * 对整个数据集进行聚合，无需分组。</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class="line">   *   ds.agg("age" -&gt; "max", "salary" -&gt; "avg")</div><div class="line">   *   ds.groupBy().agg("age" -&gt; "max", "salary" -&gt; "avg")</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   *</div><div class="line">   * @group untypedrel</div><div class="line">   * @since 2.0.0</div><div class="line">   */</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">agg</span></span>(aggExpr: (<span class="type">String</span>, <span class="type">String</span>), aggExprs: (<span class="type">String</span>, <span class="type">String</span>)*): <span class="type">DataFrame</span> = &#123;</div><div class="line">   groupBy().agg(aggExpr, aggExprs: _*)</div><div class="line"> &#125;</div><div class="line"></div><div class="line"> <span class="comment">/**</span></div><div class="line">   * (Scala-specific) Aggregates on the entire Dataset without groups.</div><div class="line">   * 对整个数据集进行聚合，无需分组。</div><div class="line">   *</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class="line">   *   ds.agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))</div><div class="line">   *   ds.groupBy().agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   *</div><div class="line">   * @group untypedrel</div><div class="line">   * @since 2.0.0</div><div class="line">   */</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">agg</span></span>(exprs: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span> = groupBy().agg(exprs)</div><div class="line"></div><div class="line"> <span class="comment">/**</span></div><div class="line">   * (Java-specific) Aggregates on the entire Dataset without groups.</div><div class="line">   *</div><div class="line">   * 对整个数据集进行聚合，无需分组。</div><div class="line">   *</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class="line">   *   ds.agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))</div><div class="line">   *   ds.groupBy().agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   *</div><div class="line">   * @group untypedrel</div><div class="line">   * @since 2.0.0</div><div class="line">   */</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">agg</span></span>(exprs: java.util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span> = groupBy().agg(exprs)</div><div class="line"></div><div class="line"> <span class="comment">/**</span></div><div class="line">   * Aggregates on the entire Dataset without groups.</div><div class="line">   *</div><div class="line">   * 对整个数据集进行聚合，无需分组。</div><div class="line">   *</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)</div><div class="line">   *   ds.agg(max($"age"), avg($"salary"))</div><div class="line">   *   ds.groupBy().agg(max($"age"), avg($"salary"))</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   *</div><div class="line">   * @group untypedrel</div><div class="line">   * @since 2.0.0</div><div class="line">   */</div><div class="line"> <span class="meta">@scala</span>.annotation.varargs</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">agg</span></span>(expr: <span class="type">Column</span>, exprs: <span class="type">Column</span>*): <span class="type">DataFrame</span> = groupBy().agg(expr, exprs: _*)</div></pre></td></tr></table></figure>
<h3 id="explode"><a href="#explode" class="headerlink" title="explode"></a>explode</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * (Scala-specific) Returns a new Dataset where each row has been expanded to zero or more</div><div class="line">  * rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. The columns of</div><div class="line">  * the input row are implicitly joined with each row that is output by the function.</div><div class="line">  *</div><div class="line">  * 根据提供的方法，该数据集的每一行都被扩展为零个或更多的行，返回一个新的数据集。</div><div class="line">  * 这类似于HiveQL的“LATERAL VIEW”。</div><div class="line">  * 输入行的列 隐式地加入了由函数输出的每一行。</div><div class="line">  *</div><div class="line">  * Given that this is deprecated, as an alternative, you can explode columns either using</div><div class="line">  * `functions.explode()` or `flatMap()`. The following example uses these alternatives to count</div><div class="line">  * the number of books that contain a given word:</div><div class="line">  *</div><div class="line">  * 考虑到这已经被弃用，作为替代，您可以使用“functions.explode()”或“flatMap()”来引爆列。</div><div class="line">  * 下面的示例使用这些替代方法来计算包含给定单词的图书的数量:</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   case class Book(title: String, words: String)</div><div class="line">  *   val ds: Dataset[Book]</div><div class="line">  *</div><div class="line">  *   val allWords = ds.select('title, explode(split('words, " ")).as("word"))</div><div class="line">  *</div><div class="line">  *   val bookCountPerWord = allWords.groupBy("word").agg(countDistinct("title"))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * Using `flatMap()` this can similarly be exploded as:</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   ds.flatMap(_.words.split(" "))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0 已经过时，用 flatMap() 或 functions.explode() 代替</div><div class="line">  */</div><div class="line"><span class="meta">@deprecated</span>(<span class="string">"use flatMap() or select() with functions.explode() instead"</span>, <span class="string">"2.0.0"</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">explode</span></span>[<span class="type">A</span> &lt;: <span class="type">Product</span> : <span class="type">TypeTag</span>](input: <span class="type">Column</span>*)(f: <span class="type">Row</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">A</span>]): <span class="type">DataFrame</span> = &#123;</div><div class="line">  <span class="keyword">val</span> elementSchema = <span class="type">ScalaReflection</span>.schemaFor[<span class="type">A</span>].dataType.asInstanceOf[<span class="type">StructType</span>]</div><div class="line"></div><div class="line">  <span class="keyword">val</span> convert = <span class="type">CatalystTypeConverters</span>.createToCatalystConverter(elementSchema)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> rowFunction =</div><div class="line">    f.andThen(_.map(convert(_).asInstanceOf[<span class="type">InternalRow</span>]))</div><div class="line">  <span class="keyword">val</span> generator = <span class="type">UserDefinedGenerator</span>(elementSchema, rowFunction, input.map(_.expr))</div><div class="line"></div><div class="line">  withPlan &#123;</div><div class="line">    <span class="type">Generate</span>(generator, join = <span class="literal">true</span>, outer = <span class="literal">false</span>,</div><div class="line">      qualifier = <span class="type">None</span>, generatorOutput = <span class="type">Nil</span>, logicalPlan)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * (Scala-specific) Returns a new Dataset where a single column has been expanded to zero</div><div class="line">  * or more rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. All</div><div class="line">  * columns of the input row are implicitly joined with each value that is output by the function.</div><div class="line">  *</div><div class="line">  * Given that this is deprecated, as an alternative, you can explode columns either using</div><div class="line">  * `functions.explode()`:</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   ds.select(explode(split('words, " ")).as("word"))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * or `flatMap()`:</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   ds.flatMap(_.words.split(" "))</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@deprecated</span>(<span class="string">"use flatMap() or select() with functions.explode() instead"</span>, <span class="string">"2.0.0"</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">explode</span></span>[<span class="type">A</span>, <span class="type">B</span>: <span class="type">TypeTag</span>](inputColumn: <span class="type">String</span>, outputColumn: <span class="type">String</span>)(f: <span class="type">A</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">B</span>])</div><div class="line">: <span class="type">DataFrame</span> = &#123;</div><div class="line">  <span class="keyword">val</span> dataType = <span class="type">ScalaReflection</span>.schemaFor[<span class="type">B</span>].dataType</div><div class="line">  <span class="keyword">val</span> attributes = <span class="type">AttributeReference</span>(outputColumn, dataType)() :: <span class="type">Nil</span></div><div class="line">  <span class="comment">// TODO handle the metadata?</span></div><div class="line">  <span class="keyword">val</span> elementSchema = attributes.toStructType</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rowFunction</span></span>(row: <span class="type">Row</span>): <span class="type">TraversableOnce</span>[<span class="type">InternalRow</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> convert = <span class="type">CatalystTypeConverters</span>.createToCatalystConverter(dataType)</div><div class="line">    f(row(<span class="number">0</span>).asInstanceOf[<span class="type">A</span>]).map(o =&gt; <span class="type">InternalRow</span>(convert(o)))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> generator = <span class="type">UserDefinedGenerator</span>(elementSchema, rowFunction, apply(inputColumn).expr :: <span class="type">Nil</span>)</div><div class="line"></div><div class="line">  withPlan &#123;</div><div class="line">    <span class="type">Generate</span>(generator, join = <span class="literal">true</span>, outer = <span class="literal">false</span>,</div><div class="line">      qualifier = <span class="type">None</span>, generatorOutput = <span class="type">Nil</span>, logicalPlan)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="withColumn"><a href="#withColumn" class="headerlink" title="withColumn"></a>withColumn</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset by adding a column or replacing the existing column that has</div><div class="line">  * the same name.</div><div class="line">  * 通过添加一个列或替换具有相同名称的现有列返回新的数据集。</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">withColumn</span></span>(colName: <span class="type">String</span>, col: <span class="type">Column</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">  <span class="keyword">val</span> resolver = sparkSession.sessionState.analyzer.resolver</div><div class="line">  <span class="keyword">val</span> output = queryExecution.analyzed.output</div><div class="line">  <span class="keyword">val</span> shouldReplace = output.exists(f =&gt; resolver(f.name, colName))</div><div class="line">  <span class="keyword">if</span> (shouldReplace) &#123;</div><div class="line">    <span class="keyword">val</span> columns = output.map &#123; field =&gt;</div><div class="line">      <span class="keyword">if</span> (resolver(field.name, colName)) &#123;</div><div class="line">        col.as(colName)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Column</span>(field)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    select(columns: _*)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    select(<span class="type">Column</span>(<span class="string">"*"</span>), col.as(colName))</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset by adding a column with metadata.</div><div class="line">  * 通过添加带有元数据的列返回一个新的数据集。</div><div class="line">  */</div><div class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">withColumn</span></span>(colName: <span class="type">String</span>, col: <span class="type">Column</span>, metadata: <span class="type">Metadata</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">  <span class="keyword">val</span> resolver = sparkSession.sessionState.analyzer.resolver</div><div class="line">  <span class="keyword">val</span> output = queryExecution.analyzed.output</div><div class="line">  <span class="keyword">val</span> shouldReplace = output.exists(f =&gt; resolver(f.name, colName))</div><div class="line">  <span class="keyword">if</span> (shouldReplace) &#123;</div><div class="line">    <span class="keyword">val</span> columns = output.map &#123; field =&gt;</div><div class="line">      <span class="keyword">if</span> (resolver(field.name, colName)) &#123;</div><div class="line">        col.as(colName, metadata)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Column</span>(field)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    select(columns: _*)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    select(<span class="type">Column</span>(<span class="string">"*"</span>), col.as(colName, metadata))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="withColumnRenamed"><a href="#withColumnRenamed" class="headerlink" title="withColumnRenamed"></a>withColumnRenamed</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset with a column renamed.</div><div class="line">  * This is a no-op if schema doesn't contain existingName.</div><div class="line">  * 返回一个重命名的列的新数据集。</div><div class="line">  * 如果模式不包含存在名称，那么这是不操作的。</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">withColumnRenamed</span></span>(existingName: <span class="type">String</span>, newName: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">  <span class="keyword">val</span> resolver = sparkSession.sessionState.analyzer.resolver</div><div class="line">  <span class="keyword">val</span> output = queryExecution.analyzed.output</div><div class="line">  <span class="keyword">val</span> shouldRename = output.exists(f =&gt; resolver(f.name, existingName))</div><div class="line">  <span class="keyword">if</span> (shouldRename) &#123;</div><div class="line">    <span class="keyword">val</span> columns = output.map &#123; col =&gt;</div><div class="line">      <span class="keyword">if</span> (resolver(col.name, existingName)) &#123;</div><div class="line">        <span class="type">Column</span>(col).as(newName)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Column</span>(col)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    select(columns: _*)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    toDF()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="drop"><a href="#drop" class="headerlink" title="drop"></a>drop</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset with a column dropped. This is a no-op if schema doesn't contain</div><div class="line">  * column name.</div><div class="line">  *</div><div class="line">  * 返回删除指定列之后的新Dataset</div><div class="line">  *</div><div class="line">  * This method can only be used to drop top level columns. the colName string is treated</div><div class="line">  * literally without further interpretation.</div><div class="line">  *</div><div class="line">  * 仅用于删除顶层的列</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">drop</span></span>(colName: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">  drop(<span class="type">Seq</span>(colName): _*)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset with columns dropped.</div><div class="line">  * This is a no-op if schema doesn't contain column name(s).</div><div class="line">  *</div><div class="line">  * 删除指定的多个列，并返回新的dataset</div><div class="line">  *</div><div class="line">  * This method can only be used to drop top level columns. the colName string is treated literally</div><div class="line">  * without further interpretation.</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">drop</span></span>(colNames: <span class="type">String</span>*): <span class="type">DataFrame</span> = &#123;</div><div class="line">  <span class="keyword">val</span> resolver = sparkSession.sessionState.analyzer.resolver</div><div class="line">  <span class="keyword">val</span> allColumns = queryExecution.analyzed.output</div><div class="line">  <span class="keyword">val</span> remainingCols = allColumns.filter &#123; attribute =&gt;</div><div class="line">    colNames.forall(n =&gt; !resolver(attribute.name, n))</div><div class="line">  &#125;.map(attribute =&gt; <span class="type">Column</span>(attribute))</div><div class="line">  <span class="keyword">if</span> (remainingCols.size == allColumns.size) &#123;</div><div class="line">    toDF()</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="keyword">this</span>.select(remainingCols: _*)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset with a column dropped.</div><div class="line">  * This version of drop accepts a [[Column]] rather than a name.</div><div class="line">  * This is a no-op if the Dataset doesn't have a column</div><div class="line">  * with an equivalent expression.</div><div class="line">  *</div><div class="line">  * 删除指定的 列（根据Column）</div><div class="line">  *</div><div class="line">  * @group untypedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">drop</span></span>(col: <span class="type">Column</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">  <span class="keyword">val</span> expression = col <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Column</span>(u: <span class="type">UnresolvedAttribute</span>) =&gt;</div><div class="line">      queryExecution.analyzed.resolveQuoted(</div><div class="line">        u.name, sparkSession.sessionState.analyzer.resolver).getOrElse(u)</div><div class="line">    <span class="keyword">case</span> <span class="type">Column</span>(expr: <span class="type">Expression</span>) =&gt; expr</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">val</span> attrs = <span class="keyword">this</span>.logicalPlan.output</div><div class="line">  <span class="keyword">val</span> colsAfterDrop = attrs.filter &#123; attr =&gt;</div><div class="line">    attr != expression</div><div class="line">  &#125;.map(attr =&gt; <span class="type">Column</span>(attr))</div><div class="line">  select(colsAfterDrop: _*)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="typedrel-有类型的转换"><a href="#typedrel-有类型的转换" class="headerlink" title="typedrel-有类型的转换"></a>typedrel-有类型的转换</h2><h3 id="joinWith"><a href="#joinWith" class="headerlink" title="joinWith"></a>joinWith</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::  实验的</div><div class="line">  * Joins this Dataset returning a `Tuple2` for each pair where `condition` evaluates to</div><div class="line">  * true.</div><div class="line">  * 连接这个数据集返回一个“Tuple2”对每一对的“条件”计算为true。</div><div class="line">  *</div><div class="line">  * This is similar to the relation `join` function with one important difference in the</div><div class="line">  * result schema. Since `joinWith` preserves objects present on either side of the join, the</div><div class="line">  * result schema is similarly nested into a tuple under the column names `_1` and `_2`.</div><div class="line">  * 这类似于关系“join”函数，在结果模式中有一个重要的区别。</div><div class="line">  * 由于“joinWith”保存了连接的任何一边的对象，因此结果模式类似地嵌套在列名称“_1”和“_2”下面的tuple中。</div><div class="line">  *</div><div class="line">  * This type of join can be useful both for preserving type-safety with the original object</div><div class="line">  * types as well as working with relational data where either side of the join has column</div><div class="line">  * names in common.</div><div class="line">  * 这种类型的联接既可以用于保存与原始对象类型的类型安全性，</div><div class="line">  * 也可以用于处理连接的任何一端都有列名的关系数据。</div><div class="line">  *</div><div class="line">  * @param other     Right side of the join.</div><div class="line">  * @param condition Join expression.</div><div class="line">  * @param joinType  One of: `inner`, `outer`, `left_outer`, `right_outer`, `leftsemi`.</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">joinWith</span></span>[<span class="type">U</span>](other: <span class="type">Dataset</span>[<span class="type">U</span>], condition: <span class="type">Column</span>, joinType: <span class="type">String</span>): <span class="type">Dataset</span>[(<span class="type">T</span>, <span class="type">U</span>)] = &#123;</div><div class="line">  <span class="comment">// Creates a Join node and resolve it first, to get join condition resolved, self-join resolved,</span></div><div class="line">  <span class="comment">// 创建一个联接节点并首先解析它，使Join条件得到解析，self - Join解析，</span></div><div class="line">  <span class="comment">// etc.</span></div><div class="line">  <span class="keyword">val</span> joined = sparkSession.sessionState.executePlan(</div><div class="line">    <span class="type">Join</span>(</div><div class="line">      <span class="keyword">this</span>.logicalPlan,</div><div class="line">      other.logicalPlan,</div><div class="line">      <span class="type">JoinType</span>(joinType),</div><div class="line">      <span class="type">Some</span>(condition.expr))).analyzed.asInstanceOf[<span class="type">Join</span>]</div><div class="line"></div><div class="line">  <span class="comment">// For both join side, combine all outputs into a single column and alias it with "_1" or "_2",</span></div><div class="line">  <span class="comment">// to match the schema for the encoder of the join result.</span></div><div class="line">  <span class="comment">// 对于这两个连接，将所有输出合并为一个列，并将其别名为“_1”或“_2”，以匹配连接结果的编码器的模式。</span></div><div class="line"></div><div class="line">  <span class="comment">// Note that we do this before joining them, to enable the join operator to return null for one</span></div><div class="line">  <span class="comment">// side, in cases like outer-join.</span></div><div class="line">  <span class="comment">// 请注意，在join它们之前，我们这样做，使join操作符在像outer - join这样的情况下返回null。</span></div><div class="line">  <span class="keyword">val</span> left = &#123;</div><div class="line">    <span class="keyword">val</span> combined = <span class="keyword">if</span> (<span class="keyword">this</span>.exprEnc.flat) &#123;</div><div class="line">      assert(joined.left.output.length == <span class="number">1</span>)</div><div class="line">      <span class="type">Alias</span>(joined.left.output.head, <span class="string">"_1"</span>)()</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="type">Alias</span>(<span class="type">CreateStruct</span>(joined.left.output), <span class="string">"_1"</span>)()</div><div class="line">    &#125;</div><div class="line">    <span class="type">Project</span>(combined :: <span class="type">Nil</span>, joined.left)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> right = &#123;</div><div class="line">    <span class="keyword">val</span> combined = <span class="keyword">if</span> (other.exprEnc.flat) &#123;</div><div class="line">      assert(joined.right.output.length == <span class="number">1</span>)</div><div class="line">      <span class="type">Alias</span>(joined.right.output.head, <span class="string">"_2"</span>)()</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="type">Alias</span>(<span class="type">CreateStruct</span>(joined.right.output), <span class="string">"_2"</span>)()</div><div class="line">    &#125;</div><div class="line">    <span class="type">Project</span>(combined :: <span class="type">Nil</span>, joined.right)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Rewrites the join condition to make the attribute point to correct column/field, after we</span></div><div class="line">  <span class="comment">// combine the outputs of each join side.</span></div><div class="line">  <span class="comment">// 在将每个连接的输出组合在一起之后,重写联接条件，使属性指向正确的列/字段。</span></div><div class="line"></div><div class="line">  <span class="keyword">val</span> conditionExpr = joined.condition.get transformUp &#123;</div><div class="line">    <span class="keyword">case</span> a: <span class="type">Attribute</span> <span class="keyword">if</span> joined.left.outputSet.contains(a) =&gt;</div><div class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.exprEnc.flat) &#123;</div><div class="line">        left.output.head</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">val</span> index = joined.left.output.indexWhere(_.exprId == a.exprId)</div><div class="line">        <span class="type">GetStructField</span>(left.output.head, index)</div><div class="line">      &#125;</div><div class="line">    <span class="keyword">case</span> a: <span class="type">Attribute</span> <span class="keyword">if</span> joined.right.outputSet.contains(a) =&gt;</div><div class="line">      <span class="keyword">if</span> (other.exprEnc.flat) &#123;</div><div class="line">        right.output.head</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">val</span> index = joined.right.output.indexWhere(_.exprId == a.exprId)</div><div class="line">        <span class="type">GetStructField</span>(right.output.head, index)</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">implicit</span> <span class="keyword">val</span> tuple2Encoder: <span class="type">Encoder</span>[(<span class="type">T</span>, <span class="type">U</span>)] =</div><div class="line">    <span class="type">ExpressionEncoder</span>.tuple(<span class="keyword">this</span>.exprEnc, other.exprEnc)</div><div class="line"></div><div class="line">  withTypedPlan(<span class="type">Join</span>(left, right, joined.joinType, <span class="type">Some</span>(conditionExpr)))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * Using inner equi-join to join this Dataset returning a `Tuple2` for each pair</div><div class="line">  * where `condition` evaluates to true.</div><div class="line">  *</div><div class="line">  * 使用内部的等连接加入这个数据集，为每一对返回一个“Tuple2”，其中“条件”的计算结果为true。</div><div class="line">  *</div><div class="line">  * @param other     Right side of the join.</div><div class="line">  * @param condition Join expression.</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">joinWith</span></span>[<span class="type">U</span>](other: <span class="type">Dataset</span>[<span class="type">U</span>], condition: <span class="type">Column</span>): <span class="type">Dataset</span>[(<span class="type">T</span>, <span class="type">U</span>)] = &#123;</div><div class="line">  joinWith(other, condition, <span class="string">"inner"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="sortWithinPartitions"><a href="#sortWithinPartitions" class="headerlink" title="sortWithinPartitions"></a>sortWithinPartitions</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset with each partition sorted by the given expressions.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，每个分区按照给定的表达式排序。</div><div class="line">  *</div><div class="line">  * This is the same operation as "SORT BY" in SQL (Hive QL).</div><div class="line">  *</div><div class="line">  * 这与SQL(Hive QL)中“SORT BY”的操作相同。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sortWithinPartitions</span></span>(sortCol: <span class="type">String</span>, sortCols: <span class="type">String</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">  sortWithinPartitions((sortCol +: sortCols).map(<span class="type">Column</span>(_)): _*)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset with each partition sorted by the given expressions.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，每个分区按照给定的表达式排序。</div><div class="line">  *</div><div class="line">  * This is the same operation as "SORT BY" in SQL (Hive QL).</div><div class="line">  *</div><div class="line">  * 这与SQL(Hive QL)中“SORT BY”的操作相同。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sortWithinPartitions</span></span>(sortExprs: <span class="type">Column</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">  sortInternal(global = <span class="literal">false</span>, sortExprs)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Returns a new Dataset sorted by the specified column, all in ascending order.</div><div class="line">    * 排序 升序</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // The following 3 are equivalent</div><div class="line">    *   下面3个是等价的</div><div class="line">    *   ds.sort("sortcol")</div><div class="line">    *   ds.sort($"sortcol")</div><div class="line">    *   ds.sort($"sortcol".asc)</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sort</span></span>(sortCol: <span class="type">String</span>, sortCols: <span class="type">String</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">    sort((sortCol +: sortCols).map(apply): _*)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Returns a new Dataset sorted by the given expressions. For example:</div><div class="line">    *</div><div class="line">    * 返回一个由给定表达式排序的新数据集。例如:</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   ds.sort($"col1", $"col2".desc)</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sort</span></span>(sortExprs: <span class="type">Column</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">    sortInternal(global = <span class="literal">true</span>, sortExprs)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="orderBy"><a href="#orderBy" class="headerlink" title="orderBy"></a>orderBy</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Returns a new Dataset sorted by the given expressions.</div><div class="line">   * This is an alias of the `sort` function.</div><div class="line">   * 这是“sort”函数的别名。</div><div class="line">   *</div><div class="line">   * @group typedrel</div><div class="line">   * @since 2.0.0</div><div class="line">   */</div><div class="line"> <span class="meta">@scala</span>.annotation.varargs</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">orderBy</span></span>(sortCol: <span class="type">String</span>, sortCols: <span class="type">String</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = sort(sortCol, sortCols: _*)</div><div class="line"></div><div class="line"> <span class="comment">/**</span></div><div class="line">   * Returns a new Dataset sorted by the given expressions.</div><div class="line">   * This is an alias of the `sort` function.</div><div class="line">   * 这是“sort”函数的别名。</div><div class="line">   *</div><div class="line">   * @group typedrel</div><div class="line">   * @since 2.0.0</div><div class="line">   */</div><div class="line"> <span class="meta">@scala</span>.annotation.varargs</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">orderBy</span></span>(sortExprs: <span class="type">Column</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = sort(sortExprs: _*)</div></pre></td></tr></table></figure>
<h3 id="as-1"><a href="#as-1" class="headerlink" title="as"></a>as</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Returns a new Dataset with an alias set.</div><div class="line">    *</div><div class="line">    * 返回一个具有别名集的新数据集。</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">as</span></span>(alias: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">    <span class="type">SubqueryAlias</span>(alias, logicalPlan, <span class="type">None</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * (Scala-specific) Returns a new Dataset with an alias set.</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">as</span></span>(alias: <span class="type">Symbol</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = as(alias.name)</div></pre></td></tr></table></figure>
<h3 id="alias"><a href="#alias" class="headerlink" title="alias"></a>alias</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Returns a new Dataset with an alias set. Same as `as`.</div><div class="line">    * 返回一个具有别名集的新数据集。与“as”相同。</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">alias</span></span>(alias: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = as(alias)</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * (Scala-specific) Returns a new Dataset with an alias set. Same as `as`.</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">alias</span></span>(alias: <span class="type">Symbol</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = as(alias)</div></pre></td></tr></table></figure>
<h3 id="select-1"><a href="#select-1" class="headerlink" title="select"></a>select</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * Returns a new Dataset by computing the given [[Column]] expression for each element.</div><div class="line">    *</div><div class="line">    * 通过计算每个元素的给定[[列]]表达式返回一个新的数据集。</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   val ds = Seq(1, 2, 3).toDS()</div><div class="line">    *   val newDS = ds.select(expr("value + 1").as[Int])</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">select</span></span>[<span class="type">U1</span>](c1: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U1</span>]): <span class="type">Dataset</span>[<span class="type">U1</span>] = &#123;</div><div class="line">    <span class="keyword">implicit</span> <span class="keyword">val</span> encoder = c1.encoder</div><div class="line">    <span class="keyword">val</span> project = <span class="type">Project</span>(c1.withInputType(exprEnc, logicalPlan.output).named :: <span class="type">Nil</span>,</div><div class="line">      logicalPlan)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (encoder.flat) &#123;</div><div class="line">      <span class="keyword">new</span> <span class="type">Dataset</span>[<span class="type">U1</span>](sparkSession, project, encoder)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// Flattens inner fields of U1</span></div><div class="line">      <span class="comment">// 使U1的内部区域变平</span></div><div class="line">      <span class="keyword">new</span> <span class="type">Dataset</span>[<span class="type">Tuple1</span>[<span class="type">U1</span>]](sparkSession, project, <span class="type">ExpressionEncoder</span>.tuple(encoder)).map(_._1)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">select</span></span>[<span class="type">U1</span>, <span class="type">U2</span>](c1: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U1</span>], c2: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U2</span>]): <span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>)] =</div><div class="line">    selectUntyped(c1, c2).asInstanceOf[<span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>)]]</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">select</span></span>[<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>](</div><div class="line">                          c1: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U1</span>],</div><div class="line">                          c2: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U2</span>],</div><div class="line">                          c3: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U3</span>]): <span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>)] =</div><div class="line">    selectUntyped(c1, c2, c3).asInstanceOf[<span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>)]]</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">select</span></span>[<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>, <span class="type">U4</span>](</div><div class="line">                              c1: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U1</span>],</div><div class="line">                              c2: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U2</span>],</div><div class="line">                              c3: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U3</span>],</div><div class="line">                              c4: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U4</span>]): <span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>, <span class="type">U4</span>)] =</div><div class="line">    selectUntyped(c1, c2, c3, c4).asInstanceOf[<span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>, <span class="type">U4</span>)]]</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * Returns a new Dataset by computing the given [[Column]] expressions for each element.</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">select</span></span>[<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>, <span class="type">U4</span>, <span class="type">U5</span>](</div><div class="line">                                  c1: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U1</span>],</div><div class="line">                                  c2: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U2</span>],</div><div class="line">                                  c3: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U3</span>],</div><div class="line">                                  c4: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U4</span>],</div><div class="line">                                  c5: <span class="type">TypedColumn</span>[<span class="type">T</span>, <span class="type">U5</span>]): <span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>, <span class="type">U4</span>, <span class="type">U5</span>)] =</div><div class="line">    selectUntyped(c1, c2, c3, c4, c5).asInstanceOf[<span class="type">Dataset</span>[(<span class="type">U1</span>, <span class="type">U2</span>, <span class="type">U3</span>, <span class="type">U4</span>, <span class="type">U5</span>)]]</div></pre></td></tr></table></figure>
<h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Filters rows using the given condition.</div><div class="line">    *</div><div class="line">    * 用给定的条件过滤rows</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   // The following are equivalent:</div><div class="line">    *   以下是等价的：</div><div class="line">    *   peopleDs.filter($"age" &gt; 15)</div><div class="line">    *   peopleDs.where($"age" &gt; 15)</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(condition: <span class="type">Column</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">    <span class="type">Filter</span>(condition.expr, logicalPlan)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Filters rows using the given SQL expression.</div><div class="line">    *</div><div class="line">    * 用给定的 SQL 表达式 过滤rows</div><div class="line">    *</div><div class="line">    * &#123;&#123;&#123;</div><div class="line">    *   peopleDs.filter("age &gt; 15")</div><div class="line">    * &#125;&#125;&#125;</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(conditionExpr: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">    filter(<span class="type">Column</span>(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="where"><a href="#where" class="headerlink" title="where"></a>where</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Filters rows using the given condition. This is an alias for `filter`.</div><div class="line">   *</div><div class="line">   * 使用给定条件过滤行。</div><div class="line">   * 这是“filter”的别名。</div><div class="line">   *</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   // The following are equivalent:</div><div class="line">   *   peopleDs.filter($"age" &gt; 15)</div><div class="line">   *   peopleDs.where($"age" &gt; 15)</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   *</div><div class="line">   * @group typedrel</div><div class="line">   * @since 1.6.0</div><div class="line">   */</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">where</span></span>(condition: <span class="type">Column</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = filter(condition)</div><div class="line"></div><div class="line"> <span class="comment">/**</span></div><div class="line">   * Filters rows using the given SQL expression.</div><div class="line">   *</div><div class="line">   * 使用给定的 SQL 表达式  过滤 rows</div><div class="line">   *</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   peopleDs.where("age &gt; 15")</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   *</div><div class="line">   * @group typedrel</div><div class="line">   * @since 1.6.0</div><div class="line">   */</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">where</span></span>(conditionExpr: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">   filter(<span class="type">Column</span>(sparkSession.sessionState.sqlParser.parseExpression(conditionExpr)))</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<h3 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Scala-specific)</div><div class="line">  * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.</div><div class="line">  * 返回一个[[KeyValueGroupedDataset]]，数据由给定键' func '分组。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>[<span class="type">K</span>: <span class="type">Encoder</span>](func: <span class="type">T</span> =&gt; <span class="type">K</span>): <span class="type">KeyValueGroupedDataset</span>[<span class="type">K</span>, <span class="type">T</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> inputPlan = logicalPlan</div><div class="line">  <span class="keyword">val</span> withGroupingKey = <span class="type">AppendColumns</span>(func, inputPlan)</div><div class="line">  <span class="keyword">val</span> executed = sparkSession.sessionState.executePlan(withGroupingKey)</div><div class="line"></div><div class="line">  <span class="keyword">new</span> <span class="type">KeyValueGroupedDataset</span>(</div><div class="line">    encoderFor[<span class="type">K</span>],</div><div class="line">    encoderFor[<span class="type">T</span>],</div><div class="line">    executed,</div><div class="line">    inputPlan.output,</div><div class="line">    withGroupingKey.newColumns)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Java-specific)</div><div class="line">  * Returns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.</div><div class="line">  * 返回一个[[KeyValueGroupedDataset]]，数据由给定键' func '分组。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>[<span class="type">K</span>](func: <span class="type">MapFunction</span>[<span class="type">T</span>, <span class="type">K</span>], encoder: <span class="type">Encoder</span>[<span class="type">K</span>]): <span class="type">KeyValueGroupedDataset</span>[<span class="type">K</span>, <span class="type">T</span>] =</div><div class="line">  groupByKey(func.call(_))(encoder)</div></pre></td></tr></table></figure>
<h3 id="limit"><a href="#limit" class="headerlink" title="limit"></a>limit</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset by taking the first `n` rows. The difference between this function</div><div class="line">  * and `head` is that `head` is an action and returns an array (by triggering query execution)</div><div class="line">  * while `limit` returns a new Dataset.</div><div class="line">  *</div><div class="line">  * 通过使用第一个“n”行返回一个新的数据集。</div><div class="line">  * 这个函数和“head”的区别在于“head”是一个动作，</div><div class="line">  * 并返回一个数组(通过触发查询执行)，而“limit”则返回一个新的数据集。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">limit</span></span>(n: <span class="type">Int</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">  <span class="type">Limit</span>(<span class="type">Literal</span>(n), logicalPlan)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="unionAll-已过时"><a href="#unionAll-已过时" class="headerlink" title="unionAll-已过时"></a>unionAll-已过时</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div><div class="line">  * This is equivalent to `UNION ALL` in SQL.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，该数据集包含该数据集中的行和另一个数据集。</div><div class="line">  * 这相当于SQL中的“UNION ALL”。</div><div class="line">  *</div><div class="line">  * To do a SQL-style set union (that does deduplication of elements), use this function followed</div><div class="line">  * by a [[distinct]].</div><div class="line">  *</div><div class="line">  * 如果需要去重的话，在该方法后继续直接  [[distinct]]</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0 已经过时</div><div class="line">  */</div><div class="line"><span class="meta">@deprecated</span>(<span class="string">"use union()"</span>, <span class="string">"2.0.0"</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">unionAll</span></span>(other: <span class="type">Dataset</span>[<span class="type">T</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = union(other)</div></pre></td></tr></table></figure>
<h3 id="union"><a href="#union" class="headerlink" title="union"></a>union</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div><div class="line">  * This is equivalent to `UNION ALL` in SQL.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，该数据集包含该数据集中的行和另一个数据集。</div><div class="line">  * 这相当于SQL中的“UNION ALL”。</div><div class="line">  *</div><div class="line">  * To do a SQL-style set union (that does deduplication of elements), use this function followed</div><div class="line">  * by a [[distinct]].</div><div class="line">  *</div><div class="line">  * 如果需要去重的话，在该方法后继续直接  [[distinct]]</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">union</span></span>(other: <span class="type">Dataset</span>[<span class="type">T</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = withSetOperator &#123;</div><div class="line">  <span class="comment">// This breaks caching, but it's usually ok because it addresses a very specific use case:</span></div><div class="line">  <span class="comment">// using union to union many files or partitions.</span></div><div class="line">  <span class="comment">// 这打破了缓存，但通常是可以的，因为它解决了一个非常具体的用例:使用union来联合许多文件或分区。</span></div><div class="line">  <span class="type">CombineUnions</span>(<span class="type">Union</span>(logicalPlan, other.logicalPlan))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="intersect-交集"><a href="#intersect-交集" class="headerlink" title="intersect-交集"></a>intersect-交集</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset containing rows only in both this Dataset and another Dataset.</div><div class="line">  * This is equivalent to `INTERSECT` in SQL.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，只包含该数据集和另一个数据集相同的行.</div><div class="line">  * 这相当于在SQL中“INTERSECT”。</div><div class="line">  * 会去重.</div><div class="line">  *</div><div class="line">  * @note Equality checking is performed directly on the encoded representation of the data</div><div class="line">  *       and thus is not affected by a custom `equals` function defined on `T`.</div><div class="line">  *</div><div class="line">  *       等式检查直接执行数据的编码表示，因此不受定义为“T”的自定义“equals”函数的影响。</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">intersect</span></span>(other: <span class="type">Dataset</span>[<span class="type">T</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = withSetOperator &#123;</div><div class="line">  <span class="type">Intersect</span>(logicalPlan, other.logicalPlan)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="except-只显示另个Dataset中没有的值"><a href="#except-只显示另个Dataset中没有的值" class="headerlink" title="except-只显示另个Dataset中没有的值"></a>except-只显示另个Dataset中没有的值</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset containing rows in this Dataset but not in another Dataset.</div><div class="line">  * This is equivalent to `EXCEPT` in SQL.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，该数据集包含该数据集中的行，而不是在另一个数据集。</div><div class="line">  * 这等价于SQL中的“EXCEPT”。</div><div class="line">  * 会去重.</div><div class="line">  *</div><div class="line">  * @note Equality checking is performed directly on the encoded representation of the data</div><div class="line">  *       and thus is not affected by a custom `equals` function defined on `T`.</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">except</span></span>(other: <span class="type">Dataset</span>[<span class="type">T</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = withSetOperator &#123;</div><div class="line">  <span class="type">Except</span>(logicalPlan, other.logicalPlan)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="sample-随机抽样"><a href="#sample-随机抽样" class="headerlink" title="sample-随机抽样"></a>sample-随机抽样</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new [[Dataset]] by sampling a fraction of rows, using a user-supplied seed.</div><div class="line">  *</div><div class="line">  * 通过使用用户提供的种子，通过抽样的方式返回一个新的[[Dataset]]。</div><div class="line">  *</div><div class="line">  * @param withReplacement Sample with replacement or not.</div><div class="line">  *                        样本已经取过的值是否放回</div><div class="line">  * @param fraction        Fraction of rows to generate.</div><div class="line">  *                        每一行数据被取样的概率</div><div class="line">  * @param seed            Seed for sampling.</div><div class="line">  *                        取样种子（与随机数生成有关）</div><div class="line">  * @note This is NOT guaranteed to provide exactly the fraction of the count</div><div class="line">  *       of the given [[Dataset]].</div><div class="line">  *       不能保证准确的按照给定的分数取样。（一般结果会在概率值*总数左右）</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span></span>(withReplacement: <span class="type">Boolean</span>, fraction: <span class="type">Double</span>, seed: <span class="type">Long</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">  require(fraction &gt;= <span class="number">0</span>,</div><div class="line">    <span class="string">s"Fraction must be nonnegative, but got <span class="subst">$&#123;fraction&#125;</span>"</span>)</div><div class="line"></div><div class="line">  withTypedPlan &#123;</div><div class="line">    <span class="type">Sample</span>(<span class="number">0.0</span>, fraction, withReplacement, seed, logicalPlan)()</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new [[Dataset]] by sampling a fraction of rows, using a random seed.</div><div class="line">  *</div><div class="line">  * 通过程序随机的种子，抽样返回新的DataSet</div><div class="line">  *</div><div class="line">  * @param withReplacement Sample with replacement or not.</div><div class="line">  *                        取样结果是否放回</div><div class="line">  * @param fraction        Fraction of rows to generate.</div><div class="line">  *                        每行数据被取样的概率</div><div class="line">  * @note This is NOT guaranteed to provide exactly the fraction of the total count</div><div class="line">  *       of the given [[Dataset]].</div><div class="line">  *       不能保证准确的按照给定的分数取样。（一般结果会在概率值*总数左右）</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span></span>(withReplacement: <span class="type">Boolean</span>, fraction: <span class="type">Double</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">  sample(withReplacement, fraction, <span class="type">Utils</span>.random.nextLong)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="randomSplit-按照权重分割"><a href="#randomSplit-按照权重分割" class="headerlink" title="randomSplit-按照权重分割"></a>randomSplit-按照权重分割</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Randomly splits this Dataset with the provided weights.</div><div class="line">    *</div><div class="line">    * 随机将此数据集按照所提供的权重进行分割。</div><div class="line">    *</div><div class="line">    * @param weights weights for splits, will be normalized if they don't sum to 1.</div><div class="line">    *                切分的权重。如果和不为1就会被标准化。</div><div class="line">    * @param seed    Seed for sampling.</div><div class="line">    *                取样的种子（影响随机数生成器）</div><div class="line">    *</div><div class="line">    *                For Java API, use [[randomSplitAsList]].</div><div class="line">    *                Java API 使用 [[randomSplitAsList]].</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">randomSplit</span></span>(weights: <span class="type">Array</span>[<span class="type">Double</span>], seed: <span class="type">Long</span>): <span class="type">Array</span>[<span class="type">Dataset</span>[<span class="type">T</span>]] = &#123;</div><div class="line">    require(weights.forall(_ &gt;= <span class="number">0</span>),</div><div class="line">      <span class="string">s"Weights must be nonnegative, but got <span class="subst">$&#123;weights.mkString("[", ",", "]")&#125;</span>"</span>)</div><div class="line">    require(weights.sum &gt; <span class="number">0</span>,</div><div class="line">      <span class="string">s"Sum of weights must be positive, but got <span class="subst">$&#123;weights.mkString("[", ",", "]")&#125;</span>"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// It is possible that the underlying dataframe doesn't guarantee the ordering of rows in its</span></div><div class="line">    <span class="comment">// constituent partitions each time a split is materialized which could result in</span></div><div class="line">    <span class="comment">// overlapping splits. To prevent this, we explicitly sort each input partition to make the</span></div><div class="line">    <span class="comment">// ordering deterministic.</span></div><div class="line">    <span class="comment">// MapType cannot be sorted.</span></div><div class="line">    <span class="keyword">val</span> sorted = <span class="type">Sort</span>(logicalPlan.output.filterNot(_.dataType.isInstanceOf[<span class="type">MapType</span>])</div><div class="line">      .map(<span class="type">SortOrder</span>(_, <span class="type">Ascending</span>)), global = <span class="literal">false</span>, logicalPlan)</div><div class="line">    <span class="keyword">val</span> sum = weights.sum</div><div class="line">    <span class="comment">// scanLeft 从右到右依次累计算 scanLeft(0.0d)(_+_): (0.0,(0.0+0.2),(0.0+0.2+0.8))</span></div><div class="line">    <span class="keyword">val</span> normalizedCumWeights = weights.map(_ / sum).scanLeft(<span class="number">0.0</span>d)(_ + _)</div><div class="line">    <span class="comment">// sliding(n) 每次取n个值，以步长为1向右滑动，如：(0.0,0.2,0.8).sliding(2)=(0.0,0.2),(0.2,0.8)</span></div><div class="line">    normalizedCumWeights.sliding(<span class="number">2</span>).map &#123; x =&gt;</div><div class="line">      <span class="keyword">new</span> <span class="type">Dataset</span>[<span class="type">T</span>](</div><div class="line">        sparkSession, <span class="type">Sample</span>(x(<span class="number">0</span>), x(<span class="number">1</span>), withReplacement = <span class="literal">false</span>, seed, sorted)(), encoder)</div><div class="line">    &#125;.toArray</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">    <span class="comment">/**</span></div><div class="line">    * Randomly splits this Dataset with the provided weights.</div><div class="line">    *</div><div class="line">    * 程序自动生成随机数种子，随机将此数据集按照所提供的权重进行分割。</div><div class="line">    *</div><div class="line">    * @param weights weights for splits, will be normalized if they don't sum to 1.</div><div class="line">    *                切分的权重。如果和不为1就会被标准化。</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">randomSplit</span></span>(weights: <span class="type">Array</span>[<span class="type">Double</span>]): <span class="type">Array</span>[<span class="type">Dataset</span>[<span class="type">T</span>]] = &#123;</div><div class="line">    randomSplit(weights, <span class="type">Utils</span>.random.nextLong)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Randomly splits this Dataset with the provided weights. Provided for the Python Api.</div><div class="line">    * Python 使用该方法</div><div class="line">    *</div><div class="line">    * @param weights weights for splits, will be normalized if they don't sum to 1.</div><div class="line">    * @param seed    Seed for sampling.</div><div class="line">    */</div><div class="line">  <span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">randomSplit</span></span>(weights: <span class="type">List</span>[<span class="type">Double</span>], seed: <span class="type">Long</span>): <span class="type">Array</span>[<span class="type">Dataset</span>[<span class="type">T</span>]] = &#123;</div><div class="line">    randomSplit(weights.toArray, seed)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="randomSplitAsList"><a href="#randomSplitAsList" class="headerlink" title="randomSplitAsList"></a>randomSplitAsList</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a Java list that contains randomly split Dataset with the provided weights.</div><div class="line">  *</div><div class="line">  * 根据提供的权重分割DataFrames，返回Java list</div><div class="line">  *</div><div class="line">  * @param weights weights for splits, will be normalized if they don't sum to 1.</div><div class="line">  *                切分的权重。如果和不为1就会被标准化。</div><div class="line">  * @param seed    Seed for sampling.</div><div class="line">  *                取样的种子（影响随机数生成器）</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomSplitAsList</span></span>(weights: <span class="type">Array</span>[<span class="type">Double</span>], seed: <span class="type">Long</span>): java.util.<span class="type">List</span>[<span class="type">Dataset</span>[<span class="type">T</span>]] = &#123;</div><div class="line">  <span class="keyword">val</span> values = randomSplit(weights, seed)</div><div class="line">  java.util.<span class="type">Arrays</span>.asList(values: _*)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="dropDuplicates-去重"><a href="#dropDuplicates-去重" class="headerlink" title="dropDuplicates-去重"></a>dropDuplicates-去重</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset that contains only the unique rows from this Dataset.</div><div class="line">  * This is an alias for `distinct`.</div><div class="line">  *</div><div class="line">  * 删除重复的row数据，是distinct的别名</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropDuplicates</span></span>(): <span class="type">Dataset</span>[<span class="type">T</span>] = dropDuplicates(<span class="keyword">this</span>.columns)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * (Scala-specific) Returns a new Dataset with duplicate rows removed, considering only</div><div class="line">  * the subset of columns.</div><div class="line">  *</div><div class="line">  * 只删除指定列的重复数据</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropDuplicates</span></span>(colNames: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">  <span class="keyword">val</span> resolver = sparkSession.sessionState.analyzer.resolver</div><div class="line">  <span class="keyword">val</span> allColumns = queryExecution.analyzed.output</div><div class="line">  <span class="keyword">val</span> groupCols = colNames.flatMap &#123; colName =&gt;</div><div class="line">    <span class="comment">// It is possibly there are more than one columns with the same name,</span></div><div class="line">    <span class="comment">// so we call filter instead of find.</span></div><div class="line">    <span class="keyword">val</span> cols = allColumns.filter(col =&gt; resolver(col.name, colName))</div><div class="line">    <span class="keyword">if</span> (cols.isEmpty) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">AnalysisException</span>(</div><div class="line">        <span class="string">s""</span><span class="string">"Cannot resolve column name "</span>$colN<span class="string">ame" among (<span class="subst">$&#123;schema.fieldNames.mkString(", ")&#125;</span>)"</span><span class="string">""</span>)</div><div class="line">    &#125;</div><div class="line">    cols</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">val</span> groupColExprIds = groupCols.map(_.exprId)</div><div class="line">  <span class="keyword">val</span> aggCols = logicalPlan.output.map &#123; attr =&gt;</div><div class="line">    <span class="keyword">if</span> (groupColExprIds.contains(attr.exprId)) &#123;</div><div class="line">      attr</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// Removing duplicate rows should not change output attributes. We should keep</span></div><div class="line">      <span class="comment">// the original exprId of the attribute. Otherwise, to select a column in original</span></div><div class="line">      <span class="comment">// dataset will cause analysis exception due to unresolved attribute.</span></div><div class="line">      <span class="comment">// 删除重复行不应该更改输出属性。</span></div><div class="line">      <span class="comment">// 我们应该保留这个属性的原始属性。</span></div><div class="line">      <span class="comment">// 否则，在原始数据集中选择一个列将导致分析异常，原因是未解析的属性。</span></div><div class="line">      <span class="type">Alias</span>(<span class="keyword">new</span> <span class="type">First</span>(attr).toAggregateExpression(), attr.name)(exprId = attr.exprId)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="type">Aggregate</span>(groupCols, aggCols, logicalPlan)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new Dataset with duplicate rows removed, considering only</div><div class="line">  * the subset of columns.</div><div class="line">  *</div><div class="line">  * 只针对特定列做去重</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropDuplicates</span></span>(colNames: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = dropDuplicates(colNames.toSeq)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Returns a new [[Dataset]] with duplicate rows removed, considering only</div><div class="line">  * the subset of columns.</div><div class="line">  *</div><div class="line">  * 只针对特定多列做去重</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 2.0.0</div><div class="line">  */</div><div class="line"><span class="meta">@scala</span>.annotation.varargs</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropDuplicates</span></span>(col1: <span class="type">String</span>, cols: <span class="type">String</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> colNames: <span class="type">Seq</span>[<span class="type">String</span>] = col1 +: cols</div><div class="line">  dropDuplicates(colNames)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="transform-自定义转换"><a href="#transform-自定义转换" class="headerlink" title="transform-自定义转换"></a>transform-自定义转换</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Concise syntax for chaining custom transformations.</div><div class="line">  *</div><div class="line">  * 用于链接自定义转换的简明语法。</div><div class="line">  *</div><div class="line">  * &#123;&#123;&#123;</div><div class="line">  *   def featurize(ds: Dataset[T]): Dataset[U] = ...</div><div class="line">  *</div><div class="line">  *   ds</div><div class="line">  *     .transform(featurize)</div><div class="line">  *     .transform(...)</div><div class="line">  * &#125;&#125;&#125;</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span></span>[<span class="type">U</span>](t: <span class="type">Dataset</span>[<span class="type">T</span>] =&gt; <span class="type">Dataset</span>[<span class="type">U</span>]): <span class="type">Dataset</span>[<span class="type">U</span>] = t(<span class="keyword">this</span>)</div></pre></td></tr></table></figure>
<h3 id="filter-过滤"><a href="#filter-过滤" class="headerlink" title="filter-过滤"></a>filter-过滤</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * (Scala-specific)</div><div class="line">    * Returns a new Dataset that only contains elements where `func` returns `true`.</div><div class="line">    *</div><div class="line">    * 该数据集只包含“func”返回“true”的元素。</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(func: <span class="type">T</span> =&gt; <span class="type">Boolean</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">    withTypedPlan(<span class="type">TypedFilter</span>(func, logicalPlan))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * :: Experimental ::</div><div class="line">    * (Java-specific)</div><div class="line">    * Returns a new Dataset that only contains elements where `func` returns `true`.</div><div class="line">    *</div><div class="line">    * 返回一个新数据集，该数据集只包含“func”返回“true”的元素。</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(func: <span class="type">FilterFunction</span>[<span class="type">T</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = &#123;</div><div class="line">    withTypedPlan(<span class="type">TypedFilter</span>(func, logicalPlan))</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Scala-specific)</div><div class="line">  * Returns a new Dataset that contains the result of applying `func` to each element.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，该数据集包含对每个元素应用“func”的结果。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">Encoder</span>](func: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">Dataset</span>[<span class="type">U</span>] = withTypedPlan &#123;</div><div class="line">  <span class="type">MapElements</span>[<span class="type">T</span>, <span class="type">U</span>](func, logicalPlan)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Java-specific)</div><div class="line">  * Returns a new Dataset that contains the result of applying `func` to each element.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，该数据集包含对每个元素应用“func”的结果。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>](func: <span class="type">MapFunction</span>[<span class="type">T</span>, <span class="type">U</span>], encoder: <span class="type">Encoder</span>[<span class="type">U</span>]): <span class="type">Dataset</span>[<span class="type">U</span>] = &#123;</div><div class="line">  <span class="keyword">implicit</span> <span class="keyword">val</span> uEnc = encoder</div><div class="line">  withTypedPlan(<span class="type">MapElements</span>[<span class="type">T</span>, <span class="type">U</span>](func, logicalPlan))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Scala-specific)</div><div class="line">  * Returns a new Dataset that contains the result of applying `func` to each partition.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，该数据集包含对每个分区应用“func”的结果。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitions</span></span>[<span class="type">U</span>: <span class="type">Encoder</span>](func: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Iterator</span>[<span class="type">U</span>]): <span class="type">Dataset</span>[<span class="type">U</span>] = &#123;</div><div class="line">  <span class="keyword">new</span> <span class="type">Dataset</span>[<span class="type">U</span>](</div><div class="line">    sparkSession,</div><div class="line">    <span class="type">MapPartitions</span>[<span class="type">T</span>, <span class="type">U</span>](func, logicalPlan),</div><div class="line">    implicitly[<span class="type">Encoder</span>[<span class="type">U</span>]])</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Java-specific)</div><div class="line">  * Returns a new Dataset that contains the result of applying `f` to each partition.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，该数据集包含对每个分区应用“f”的结果。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitions</span></span>[<span class="type">U</span>](f: <span class="type">MapPartitionsFunction</span>[<span class="type">T</span>, <span class="type">U</span>], encoder: <span class="type">Encoder</span>[<span class="type">U</span>]): <span class="type">Dataset</span>[<span class="type">U</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> func: (<span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">Iterator</span>[<span class="type">U</span>] = x =&gt; f.call(x.asJava).asScala</div><div class="line">  mapPartitions(func)(encoder)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="flatMap-将map结果flat扁平化"><a href="#flatMap-将map结果flat扁平化" class="headerlink" title="flatMap-将map结果flat扁平化"></a>flatMap-将map结果flat扁平化</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Scala-specific)</div><div class="line">  * Returns a new Dataset by first applying a function to all elements of this Dataset,</div><div class="line">  * and then flattening the results.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，首先对该数据集的所有元素应用一个函数，然后将结果扁平化。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">Encoder</span>](func: <span class="type">T</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">U</span>]): <span class="type">Dataset</span>[<span class="type">U</span>] =</div><div class="line">  mapPartitions(_.flatMap(func))</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * :: Experimental ::</div><div class="line">  * (Java-specific)</div><div class="line">  * Returns a new Dataset by first applying a function to all elements of this Dataset,</div><div class="line">  * and then flattening the results.</div><div class="line">  *</div><div class="line">  * 返回一个新的数据集，首先对该数据集的所有元素应用一个函数，然后将结果扁平化。</div><div class="line">  *</div><div class="line">  * @group typedrel</div><div class="line">  * @since 1.6.0</div><div class="line">  */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="meta">@InterfaceStability</span>.<span class="type">Evolving</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>](f: <span class="type">FlatMapFunction</span>[<span class="type">T</span>, <span class="type">U</span>], encoder: <span class="type">Encoder</span>[<span class="type">U</span>]): <span class="type">Dataset</span>[<span class="type">U</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> func: (<span class="type">T</span>) =&gt; <span class="type">Iterator</span>[<span class="type">U</span>] = x =&gt; f.call(x).asScala</div><div class="line">  flatMap(func)(encoder)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="repartition-重分区"><a href="#repartition-重分区" class="headerlink" title="repartition-重分区"></a>repartition-重分区</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Returns a new Dataset that has exactly `numPartitions` partitions.</div><div class="line">    *</div><div class="line">    * 返回一个 给定分区数量的新DataSet</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">repartition</span></span>(numPartitions: <span class="type">Int</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">    <span class="type">Repartition</span>(numPartitions, shuffle = <span class="literal">true</span>, logicalPlan)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Returns a new Dataset partitioned by the given partitioning expressions into</div><div class="line">    * `numPartitions`. The resulting Dataset is hash partitioned.</div><div class="line">    *</div><div class="line">    * 返回一个由给定的分区表达式划分为“num分区”的新数据集。</div><div class="line">    * 生成的Dataset是哈希分区的。</div><div class="line">    *</div><div class="line">    * This is the same operation as "DISTRIBUTE BY" in SQL (Hive QL).</div><div class="line">    *</div><div class="line">    * 和 SQL (Hive QL) 中的 "DISTRIBUTE BY" 作用相同</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">repartition</span></span>(numPartitions: <span class="type">Int</span>, partitionExprs: <span class="type">Column</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">    <span class="type">RepartitionByExpression</span>(partitionExprs.map(_.expr), logicalPlan, <span class="type">Some</span>(numPartitions))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * Returns a new Dataset partitioned by the given partitioning expressions, using</div><div class="line">    * `spark.sql.shuffle.partitions` as number of partitions.</div><div class="line">    * The resulting Dataset is hash partitioned.</div><div class="line">    *</div><div class="line">    * 根据指定的分区表达式进行重分区。</div><div class="line">    * 分区数量由`spark.sql.shuffle.partitions` 获得。</div><div class="line">    * 结果Dataset 是哈希分区的。</div><div class="line">    *</div><div class="line">    * This is the same operation as "DISTRIBUTE BY" in SQL (Hive QL).</div><div class="line">    *</div><div class="line">    * 和 SQL (Hive QL) 中的 "DISTRIBUTE BY" 作用相同</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">repartition</span></span>(partitionExprs: <span class="type">Column</span>*): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">    <span class="type">RepartitionByExpression</span>(partitionExprs.map(_.expr), logicalPlan, numPartitions = <span class="type">None</span>)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="coalesce-合并分区"><a href="#coalesce-合并分区" class="headerlink" title="coalesce-合并分区"></a>coalesce-合并分区</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Returns a new Dataset that has exactly `numPartitions` partitions.</div><div class="line">    * Similar to coalesce defined on an `RDD`, this operation results in a narrow dependency, e.g.</div><div class="line">    * if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of</div><div class="line">    * the 100 new partitions will claim 10 of the current partitions.</div><div class="line">    *</div><div class="line">    * 合并。</div><div class="line">    * 返回确定分区数量的Dataset。</div><div class="line">    * 和RDD中的合并方法类似，这个操作导致了一个窄依赖。</div><div class="line">    * 例如：将1000个分区合并为100个分区，这个过程没有shuffle，而是100个新分区中的每个分区将声明当前的10个分区。</div><div class="line">    *</div><div class="line">    * @group typedrel</div><div class="line">    * @since 1.6.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">coalesce</span></span>(numPartitions: <span class="type">Int</span>): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</div><div class="line">    <span class="type">Repartition</span>(numPartitions, shuffle = <span class="literal">false</span>, logicalPlan)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="distinct-去重"><a href="#distinct-去重" class="headerlink" title="distinct-去重"></a>distinct-去重</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">    * Returns a new Dataset that contains only the unique rows from this Dataset.</div><div class="line">    * This is an alias for `dropDuplicates`.</div><div class="line">    *</div><div class="line">    * 去重。</div><div class="line">    * 返回去重后的Dataset。</div><div class="line">    * 和 `dropDuplicates` 方法一致。</div><div class="line">    *</div><div class="line">    * @note Equality checking is performed directly on the encoded representation of the data</div><div class="line">    *       and thus is not affected by a custom `equals` function defined on `T`.</div><div class="line">    * @group typedrel</div><div class="line">    * @since 2.0.0</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">distinct</span></span>(): <span class="type">Dataset</span>[<span class="type">T</span>] = dropDuplicates()</div></pre></td></tr></table></figure>
<!--对不起，到时间了，请停止装逼-->

      
    </div>
    
    
    
    
    
    
    <div>
      
        <div>
<div>



<div style="text-align:center;color: #ccc;font-size:14px;">

-------------THE<i class="fa fa-paw"></i>END-------------</div>



</div>
</div>
      
    </div>
    
    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/pic/wechatpay.jpeg" alt="森 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/pic/alipay.jpeg" alt="森 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    
    
    
    
    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag"><i class="fa fa-tag"></i> spark</a>
          
            <a href="/tags/源码/" rel="tag"><i class="fa fa-tag"></i> 源码</a>
          
        </div>
      
    
      
      
      
    
      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/11/21/JavaRDDLike-scala/" rel="next" title="JavaRDDLike.scala">
                <i class="fa fa-chevron-left"></i> JavaRDDLike.scala
              </a>
            
          </div>
    
          <span class="post-nav-divider"></span>
    
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/11/27/spark分层取样/" rel="prev" title="spark分层取样">
                spark分层取样 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      
    
      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.gif"
                alt="森" />
            
              <p class="site-author-name" itemprop="name">森</p>
              <p class="site-description motion-element" itemprop="description">采菊东篱下，悠然见南山</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/stanxia" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="xooglexls@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://plus.google.com/u/0/+SengleXia" target="_blank" title="Google">
                    
                      <i class="fa fa-fw fa-google"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://twitter.com/stillstan1" target="_blank" title="Twitter">
                    
                      <i class="fa fa-fw fa-twitter"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.facebook.com/xlsstan" target="_blank" title="FB Page">
                    
                      <i class="fa fa-fw fa-facebook"></i></a>
                </span>
              
            
          </div>

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                书签
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://ac.qq.com/Comic/comicInfo/id/505432" title="火影" target="_blank">火影</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.ishuhui.com/cartoon/book/1" title="海贼王" target="_blank">海贼王</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://ac.qq.com/Comic/comicInfo/id/541812" title="西行记" target="_blank">西行记</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.infoq.com/cn/spark1" title="InfoQ" target="_blank">InfoQ</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://portal.qiniu.com/bucket/stanxia/resource" title="七牛云" target="_blank">七牛云</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://github.com/caesar0301/awesome-public-datasets#finance" title="公共数据集" target="_blank">公共数据集</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#basic-基础方法"><span class="nav-number">2.</span> <span class="nav-text">basic-基础方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#toDF"><span class="nav-number">2.1.</span> <span class="nav-text">toDF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#as"><span class="nav-number">2.2.</span> <span class="nav-text">as</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#schema"><span class="nav-number">2.3.</span> <span class="nav-text">schema</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#printSchema"><span class="nav-number">2.4.</span> <span class="nav-text">printSchema</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#explain"><span class="nav-number">2.5.</span> <span class="nav-text">explain</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dtypes"><span class="nav-number">2.6.</span> <span class="nav-text">dtypes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#columns"><span class="nav-number">2.7.</span> <span class="nav-text">columns</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#isLocal"><span class="nav-number">2.8.</span> <span class="nav-text">isLocal</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#checkpoint"><span class="nav-number">2.9.</span> <span class="nav-text">checkpoint</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#persist"><span class="nav-number">2.10.</span> <span class="nav-text">persist</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cache"><span class="nav-number">2.11.</span> <span class="nav-text">cache</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#storageLevel"><span class="nav-number">2.12.</span> <span class="nav-text">storageLevel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#unpersist"><span class="nav-number">2.13.</span> <span class="nav-text">unpersist</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rdd"><span class="nav-number">2.14.</span> <span class="nav-text">rdd</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#toJavaRDD"><span class="nav-number">2.15.</span> <span class="nav-text">toJavaRDD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#registerTempTable"><span class="nav-number">2.16.</span> <span class="nav-text">registerTempTable</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#createTempView"><span class="nav-number">2.17.</span> <span class="nav-text">createTempView</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#createOrReplaceTempView"><span class="nav-number">2.18.</span> <span class="nav-text">createOrReplaceTempView</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#createGlobalTempView"><span class="nav-number">2.19.</span> <span class="nav-text">createGlobalTempView</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#write"><span class="nav-number">2.20.</span> <span class="nav-text">write</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#writeStream"><span class="nav-number">2.21.</span> <span class="nav-text">writeStream</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#toJSON"><span class="nav-number">2.22.</span> <span class="nav-text">toJSON</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inputFiles"><span class="nav-number">2.23.</span> <span class="nav-text">inputFiles</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#streaming"><span class="nav-number">3.</span> <span class="nav-text">streaming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#isStreaming"><span class="nav-number">3.1.</span> <span class="nav-text">isStreaming</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#withWatermark"><span class="nav-number">3.2.</span> <span class="nav-text">withWatermark</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#action"><span class="nav-number">4.</span> <span class="nav-text">action</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#show"><span class="nav-number">4.1.</span> <span class="nav-text">show</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce"><span class="nav-number">4.2.</span> <span class="nav-text">reduce</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#describe"><span class="nav-number">4.3.</span> <span class="nav-text">describe</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#head"><span class="nav-number">4.4.</span> <span class="nav-text">head</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#first"><span class="nav-number">4.5.</span> <span class="nav-text">first</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#foreach"><span class="nav-number">4.6.</span> <span class="nav-text">foreach</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#foreachPartition"><span class="nav-number">4.7.</span> <span class="nav-text">foreachPartition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#take"><span class="nav-number">4.8.</span> <span class="nav-text">take</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#takeAsList"><span class="nav-number">4.9.</span> <span class="nav-text">takeAsList</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#collect"><span class="nav-number">4.10.</span> <span class="nav-text">collect</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#collectAsList"><span class="nav-number">4.11.</span> <span class="nav-text">collectAsList</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#toLocalIterator"><span class="nav-number">4.12.</span> <span class="nav-text">toLocalIterator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#count"><span class="nav-number">4.13.</span> <span class="nav-text">count</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#untypedrel-无类型转换"><span class="nav-number">5.</span> <span class="nav-text">untypedrel-无类型转换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#na"><span class="nav-number">5.1.</span> <span class="nav-text">na</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#stat"><span class="nav-number">5.2.</span> <span class="nav-text">stat</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#join"><span class="nav-number">5.3.</span> <span class="nav-text">join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#crossJoin"><span class="nav-number">5.4.</span> <span class="nav-text">crossJoin</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#apply"><span class="nav-number">5.5.</span> <span class="nav-text">apply</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#col"><span class="nav-number">5.6.</span> <span class="nav-text">col</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#select"><span class="nav-number">5.7.</span> <span class="nav-text">select</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#selectExpr"><span class="nav-number">5.8.</span> <span class="nav-text">selectExpr</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#groupBy"><span class="nav-number">5.9.</span> <span class="nav-text">groupBy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rollup"><span class="nav-number">5.10.</span> <span class="nav-text">rollup</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cube"><span class="nav-number">5.11.</span> <span class="nav-text">cube</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#agg"><span class="nav-number">5.12.</span> <span class="nav-text">agg</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#explode"><span class="nav-number">5.13.</span> <span class="nav-text">explode</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#withColumn"><span class="nav-number">5.14.</span> <span class="nav-text">withColumn</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#withColumnRenamed"><span class="nav-number">5.15.</span> <span class="nav-text">withColumnRenamed</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#drop"><span class="nav-number">5.16.</span> <span class="nav-text">drop</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#typedrel-有类型的转换"><span class="nav-number">6.</span> <span class="nav-text">typedrel-有类型的转换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#joinWith"><span class="nav-number">6.1.</span> <span class="nav-text">joinWith</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sortWithinPartitions"><span class="nav-number">6.2.</span> <span class="nav-text">sortWithinPartitions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sort"><span class="nav-number">6.3.</span> <span class="nav-text">sort</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#orderBy"><span class="nav-number">6.4.</span> <span class="nav-text">orderBy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#as-1"><span class="nav-number">6.5.</span> <span class="nav-text">as</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alias"><span class="nav-number">6.6.</span> <span class="nav-text">alias</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#select-1"><span class="nav-number">6.7.</span> <span class="nav-text">select</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#filter"><span class="nav-number">6.8.</span> <span class="nav-text">filter</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#where"><span class="nav-number">6.9.</span> <span class="nav-text">where</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#groupByKey"><span class="nav-number">6.10.</span> <span class="nav-text">groupByKey</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#limit"><span class="nav-number">6.11.</span> <span class="nav-text">limit</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#unionAll-已过时"><span class="nav-number">6.12.</span> <span class="nav-text">unionAll-已过时</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#union"><span class="nav-number">6.13.</span> <span class="nav-text">union</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#intersect-交集"><span class="nav-number">6.14.</span> <span class="nav-text">intersect-交集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#except-只显示另个Dataset中没有的值"><span class="nav-number">6.15.</span> <span class="nav-text">except-只显示另个Dataset中没有的值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sample-随机抽样"><span class="nav-number">6.16.</span> <span class="nav-text">sample-随机抽样</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#randomSplit-按照权重分割"><span class="nav-number">6.17.</span> <span class="nav-text">randomSplit-按照权重分割</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#randomSplitAsList"><span class="nav-number">6.18.</span> <span class="nav-text">randomSplitAsList</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dropDuplicates-去重"><span class="nav-number">6.19.</span> <span class="nav-text">dropDuplicates-去重</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transform-自定义转换"><span class="nav-number">6.20.</span> <span class="nav-text">transform-自定义转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#filter-过滤"><span class="nav-number">6.21.</span> <span class="nav-text">filter-过滤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#map"><span class="nav-number">6.22.</span> <span class="nav-text">map</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mapPartitions"><span class="nav-number">6.23.</span> <span class="nav-text">mapPartitions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flatMap-将map结果flat扁平化"><span class="nav-number">6.24.</span> <span class="nav-text">flatMap-将map结果flat扁平化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#repartition-重分区"><span class="nav-number">6.25.</span> <span class="nav-text">repartition-重分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#coalesce-合并分区"><span class="nav-number">6.26.</span> <span class="nav-text">coalesce-合并分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#distinct-去重"><span class="nav-number">6.27.</span> <span class="nav-text">distinct-去重</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      



    </div>
  </aside>


        
      </div>
    </main>
    
    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-paw"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">森</span>

  
</div>









        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>
    
    
    
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  

    
      <script id="dsq-count-scr" src="https://astan.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://stanxia.github.io/2017/11/23/Dataset-scala/';
          this.page.identifier = '2017/11/23/Dataset-scala/';
          this.page.title = 'Dataset.scala';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://astan.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("f8AHUn2FOKCWoFzJTLrnSt4A-gzGzoHsz", "dOlRTKgDWf3Ut87VDHex4Wks");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
  </script>

  

  

  

  


<!-- 页面点击小红心 -->

<script type="text/javascript" src="/js/src/love.js"></script>

</body></html>