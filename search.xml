<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[面试题集锦]]></title>
      <url>https://stanxia.github.io/2017/09/26/%E9%9D%A2%E8%AF%95%E9%A2%98%E9%9B%86%E9%94%A6/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>平时看到一些面试题就记录在这里，没吃过猪肉，也要多见见猪跑。</p>
<p>持续更新。。。</p>
<h2 id="java"><a href="#java" class="headerlink" title="java"></a>java</h2><h3 id="1-HashMap与HashTable的区别"><a href="#1-HashMap与HashTable的区别" class="headerlink" title="1. HashMap与HashTable的区别"></a>1. HashMap与HashTable的区别</h3><p>先说共同点：</p>
<p>都是Map的实现类。都没有自带排序。如果在多线程的情况下使用HashMap，需要使用Collections.SynchronizeMap(new HashMap<k,v>())</k,v></p>
<p>如果在单线程的情况下，建议使用HashMap,性能会更高。</p>
<p>如果在多线程的情况下，也可以使用上述方法将HashMap实现线程安全，从而使用HashMap.</p>
<p>总体而言，HashMap提供的api更丰富，因而还是建议首先考虑HashMap.</p>
<p><strong>Note:</strong>ConcurrentHashMap是良好的HashTable的替代品，实现了更好的拓展。也可以考虑使用。</p>
<table>
<thead>
<tr>
<th></th>
<th>是否支持null</th>
<th>是否synchronized</th>
<th>是否安全</th>
<th>迭代器</th>
</tr>
</thead>
<tbody>
<tr>
<td>HashMap</td>
<td>支持null为key和value</td>
<td>不是synchronized</td>
<td>线程不安全</td>
<td>fail-safe迭代器</td>
</tr>
<tr>
<td>HashTable</td>
<td>不支持null</td>
<td>synchronized</td>
<td>线程安全</td>
<td>Enumerator</td>
</tr>
</tbody>
</table>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><h3 id="1-1000桶酒中寻找一桶毒酒算法"><a href="#1-1000桶酒中寻找一桶毒酒算法" class="headerlink" title="1. 1000桶酒中寻找一桶毒酒算法"></a>1. 1000桶酒中寻找一桶毒酒算法</h3><p>题目：</p>
<p>有1000桶酒，其中1桶有毒。而一旦吃了，毒性会在1周后发作。现在我们用小老鼠做实验，要在1周后找出那桶毒酒，问最少需要多少老鼠，如何检测（老鼠的使用量越少越好，注意，毒性1周后才会发作，而且一周后必须出结果，所以时间紧迫） </p>
<p>思路： </p>
<p>为何需要老鼠做实验，显然是根据老鼠的死活来判断酒的毒性，每一只老鼠只有2种状态，死和活，n只老鼠就是这n个死或活的状态，应该由此敏感的联想到二进制，隐约去感知1000这个数量与n的关系，2^n能表示多少的信息量呢？2^10=1024，想到这里我们可以试着去用10个老鼠去做一下实验。 </p>
<p>步骤： </p>
<p>把1000桶酒分别以10位二进制数标号，从0000000001至1111101000，从这1000个二进制数中寻找毒酒，毒酒也一定是0和1的某种组合，所以问题转化为如何得出这个组合的每一位都是多少，我们先思考如何得出第一位（从右到左）是0还是1，结论是只要把所有第一位是1的酒给一只老鼠喝，如果这只老鼠最终死了，可知毒酒的第一位一定是1，如果这只老鼠还活着，可知毒酒第一位一定是0.依次类推，我们使用10只老鼠便可判断毒酒的每一位是多少。从而得到毒酒的二进制数，转化成10进制便只是第几桶。</p>
<p>即10只老鼠按以下编码：</p>
<p>第一只 00000 00001</p>
<p>第二只 00000 00010</p>
<p>第三只 00000 00100</p>
<p>第四只 00000 01000</p>
<p>…</p>
<p>第十只 10000 00000</p>
<p>每只老鼠只喝其编码与酒编码做位与运算非0的酒。如果毒酒的编码在某一位为1，则监控该位的老鼠必喝，结果为1. </p>
<p>即把10只老鼠的结果，按位填入一个10位二进制数中，其结果即为毒酒编号。</p>
<p>例如：编号为10001 00011的酒是毒酒。则对应的只有第一只，第二只，第六只，第十只死亡。其对应位数置1，即为10001 00011</p>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="1-下面与Zookeeper类似的框架是？"><a href="#1-下面与Zookeeper类似的框架是？" class="headerlink" title="1. 下面与Zookeeper类似的框架是？"></a>1. 下面与Zookeeper类似的框架是？</h3><p>A Protobuf</p>
<p>B Java</p>
<p>C Kafka</p>
<p>（Kafka是一个高吞吐量分布式消息系统。linkedin开源的kafka。 Kafka就跟这个名字一样，设计非常独特。首先，kafka的开发者们认为不需要在内存里缓存什么数据，操作系统的文件缓存已经足够完善和强大，只要你不搞随机写，顺序读写的性能是非常高效的。kafka的数据只会顺序append，数据的删除策略是累积到一定程度或者超过一定时间再删除。Kafka另一个独特的地方是将消费者信息保存在客户端而不是MQ服务器，这样服务器就不用记录消息的投递过程，每个客户端都自己知道自己下一次应该从什么地方什么位置读取消息，消息的投递过程也是采用客户端主动pull的模型，这样大大减轻了服务器的负担。Kafka还强调减少数据的序列化和拷贝开销，它会将一些消息组织成Message Set做批量存储和发送，并且客户端在pull数据的时候，尽量以zero-copy的方式传输，利用sendfile（对应java里的 FileChannel.transferTo/transferFrom）这样的高级IO函数来减少拷贝开销。可见，kafka是一个精心设计，特定于某些应用的MQ系统，这种偏向特定领域的MQ系统我估计会越来越多，垂直化的产品策略值的考虑）</p>
<p><del><strong>D Chubby</strong></del></p>
<p>（MapReduce 很多人已经知道了，但关于Chubyy似乎熟悉它的就非常有限，这倒是不奇怪，因为MapReduce是一个针对开发人员的 ProgrammingModel，自然会有很多人去学习它，而Chubby更多的是一种为了实现MapReduce或者Bigtable而构建的内部的 工具，对于开发人员来说基本上是透明的。</p>
<p>Chubby首先是一个分布式的文件系统。Chubby能够提供机制使得client可以在Chubby service上创建文件和执行一些文件的基本操作。说它是分布式的文件系统，是因为一个Chubby cell是一个分布式的系统，一般包含了5台机器，整个文件系统是部署在这5台机器上的。<br>但是，从更高一点的语义层面上，Chubby是一个 lock service，一个针对松耦合的分布式系统的lock service。所谓lock service，就是这个service能够提供开发人员经常用的“锁”，“解锁”功能。通过Chubby，一个分布式系统中的上千个client都能够 对于某项资源进行“加锁”，“解锁”。<br>那么，Chubby是怎样实现这样的“锁”功能的？就是通过文件。Chubby中的“锁”就是文件，在上例 中，创建文件其实就是进行“加锁”操作，创建文件成功的那个server其实就是抢占到了“锁”。用户通过打开、关闭和读取文件，获取共享锁或者独占锁； 并且通过通信机制，向用户发送更新信息。<br>综上所述，Chubby是一个lock service，通过这个lock service可以解决分布式中的一致性问题，而这个lock service的实现是一个分布式的文件系统。）</p>
<h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><h3 id="1-LSM含义是？"><a href="#1-LSM含义是？" class="headerlink" title="1.  LSM含义是？"></a>1.  LSM含义是？</h3><p><del><strong>A 日志结构合并树（Log-Structured Merge Tree）</strong></del></p>
<p>B 二叉树</p>
<p>C 平衡二叉树</p>
<p>D 长平衡二叉树</p>
<h3 id="2-下面对LSM结构描述正确的是？"><a href="#2-下面对LSM结构描述正确的是？" class="headerlink" title="2. 下面对LSM结构描述正确的是？"></a>2. 下面对LSM结构描述正确的是？</h3><p><strong><del>A 顺序存储</del></strong></p>
<p>B 直接写硬盘</p>
<p><strong><del>C 需要将数据Flush到磁盘</del></strong></p>
<p>D 是一种搜索平衡树</p>
<h3 id="3-LSM更能保证哪种操作的性能？"><a href="#3-LSM更能保证哪种操作的性能？" class="headerlink" title="3. LSM更能保证哪种操作的性能？"></a>3. LSM更能保证哪种操作的性能？</h3><p>A 读</p>
<p><strong><del>B 写</del></strong></p>
<p>C 随机读</p>
<p>D 合并</p>
<h3 id="4-LSM的读操作和写操作是独立的？"><a href="#4-LSM的读操作和写操作是独立的？" class="headerlink" title="4.  LSM的读操作和写操作是独立的？"></a>4.  LSM的读操作和写操作是独立的？</h3><p><strong><del>A 是。</del></strong></p>
<p>B 否。</p>
<p>C LSM并不区分读和写</p>
<p>D LSM中读写是同一种操作</p>
<h3 id="5-LSM结构的数据首先存储在（）。"><a href="#5-LSM结构的数据首先存储在（）。" class="headerlink" title="5.  LSM结构的数据首先存储在（）。"></a>5.  LSM结构的数据首先存储在（）。</h3><p>A 硬盘上</p>
<p><strong><del>B 内存中</del></strong></p>
<p>C 磁盘阵列中</p>
<p>D 闪存中</p>
<h3 id="6-HFile数据格式中的Data字段用于（）。"><a href="#6-HFile数据格式中的Data字段用于（）。" class="headerlink" title="6. HFile数据格式中的Data字段用于（）。"></a>6. HFile数据格式中的Data字段用于（）。</h3><p><strong><del>A 存储实际的KeyValue数据</del></strong></p>
<p>B 存储数据的起点</p>
<p>C 指定字段的长度</p>
<p>D 存储数据块的起点</p>
<h3 id="7-HFile数据格式中的MetaIndex字段用于（）。"><a href="#7-HFile数据格式中的MetaIndex字段用于（）。" class="headerlink" title="7. HFile数据格式中的MetaIndex字段用于（）。"></a>7. HFile数据格式中的MetaIndex字段用于（）。</h3><p>A Meta块的长度</p>
<p>B Meta块的结束点</p>
<p>C Meta块数据内容</p>
<p><strong><del>D Meta块的起始点</del></strong></p>
<h3 id="8-HFile数据格式中的Magic字段用于（）。"><a href="#8-HFile数据格式中的Magic字段用于（）。" class="headerlink" title="8. HFile数据格式中的Magic字段用于（）。"></a>8. HFile数据格式中的Magic字段用于（）。</h3><p><strong><del>A 存储随机数，防止数据损坏</del></strong></p>
<p>B 存储数据的起点</p>
<p>C 存储数据块的起点</p>
<p>D 指定字段的长度</p>
<h3 id="9-HFile数据格式中的KeyValue数据格式，下列选项描述正确的是（）。"><a href="#9-HFile数据格式中的KeyValue数据格式，下列选项描述正确的是（）。" class="headerlink" title="9. HFile数据格式中的KeyValue数据格式，下列选项描述正确的是（）。"></a>9. HFile数据格式中的KeyValue数据格式，下列选项描述正确的是（）。</h3><p><strong><del>A 是byte[]数组</del></strong></p>
<p>B 没有固定的结构</p>
<p>C 数据的大小是定长的</p>
<p><strong><del>D 有固定的结构</del></strong></p>
<h3 id="10-HFile数据格式中的KeyValue数据格式中Value部分是（）。"><a href="#10-HFile数据格式中的KeyValue数据格式中Value部分是（）。" class="headerlink" title="10. HFile数据格式中的KeyValue数据格式中Value部分是（）。"></a>10. HFile数据格式中的KeyValue数据格式中Value部分是（）。</h3><p>A 拥有复杂结构的字符串</p>
<p>B 字符串</p>
<p><strong><del>C 二进制数据</del></strong></p>
<p>D 压缩数据</p>
<h3 id="11-Rowkey设计的原则，下列哪些选项的描述是正确的？"><a href="#11-Rowkey设计的原则，下列哪些选项的描述是正确的？" class="headerlink" title="11. Rowkey设计的原则，下列哪些选项的描述是正确的？"></a>11. Rowkey设计的原则，下列哪些选项的描述是正确的？</h3><p><strong><del>A 尽量保证越短越好</del></strong></p>
<p><strong><del>B 可以使用汉字</del></strong></p>
<p><strong><del>C 可以使用字符串</del></strong></p>
<p>D 本身是无序的</p>
<h3 id="12-HBase构建二级索引的实现方式有哪些？"><a href="#12-HBase构建二级索引的实现方式有哪些？" class="headerlink" title="12. HBase构建二级索引的实现方式有哪些？"></a>12. HBase构建二级索引的实现方式有哪些？</h3><p><strong><del>A MapReduce</del></strong></p>
<p><strong><del>B Coprocessor</del></strong></p>
<p>(HBase在0.92之后引入了协处理器(coprocessors)，实现一些激动人心的新特性：能够轻易建立二次索引、复杂过滤器(谓词下推)以及访问控制等)</p>
<p>C Bloom Filter</p>
<p>D Filter</p>
<h3 id="13-关于HBase二级索引的描述，哪些是正确的？"><a href="#13-关于HBase二级索引的描述，哪些是正确的？" class="headerlink" title="13. 关于HBase二级索引的描述，哪些是正确的？"></a>13. 关于HBase二级索引的描述，哪些是正确的？</h3><p><strong><del>A 核心是倒排表</del></strong></p>
<p><strong><del>B 二级索引概念是对应Rowkey这个“一级”索引</del></strong></p>
<p>C 二级索引使用平衡二叉树</p>
<p>D 二级索引使用LSM结构</p>
<h3 id="14-下列关于Bloom-Filter的描述正确的是？"><a href="#14-下列关于Bloom-Filter的描述正确的是？" class="headerlink" title="14. 下列关于Bloom Filter的描述正确的是？"></a>14. 下列关于Bloom Filter的描述正确的是？</h3><p><strong><del>A 是一个很长的二进制向量和一系列随机映射函数</del></strong></p>
<p>B 没有误算率</p>
<p><strong><del>C 有一定的误算率</del></strong></p>
<p>D 可以在Bloom Filter中删除元素</p>
<h3 id="15-每天百亿数据入-hbase，如何保证数据的存储正确和在规定的时间里全部录入完毕，-不残留数据"><a href="#15-每天百亿数据入-hbase，如何保证数据的存储正确和在规定的时间里全部录入完毕，-不残留数据" class="headerlink" title="15. 每天百亿数据入 hbase，如何保证数据的存储正确和在规定的时间里全部录入完毕， 不残留数据?"></a>15. 每天百亿数据入 hbase，如何保证数据的存储正确和在规定的时间里全部录入完毕， 不残留数据?</h3><h3 id="16-hbase-过滤器实现原则"><a href="#16-hbase-过滤器实现原则" class="headerlink" title="16. hbase 过滤器实现原则?"></a>16. hbase 过滤器实现原则?</h3><h2 id="HADOOP"><a href="#HADOOP" class="headerlink" title="HADOOP"></a>HADOOP</h2><ol>
<li><h3 id="简要描述如何安装配置一个apache开源版hadoop，只描述即可，无需列出完整步骤，能列出步骤更好。"><a href="#简要描述如何安装配置一个apache开源版hadoop，只描述即可，无需列出完整步骤，能列出步骤更好。" class="headerlink" title="简要描述如何安装配置一个apache开源版hadoop，只描述即可，无需列出完整步骤，能列出步骤更好。"></a>简要描述如何安装配置一个apache开源版hadoop，只描述即可，无需列出完整步骤，能列出步骤更好。</h3></li>
<li><h3 id="请列出正常工作的hadoop集群中hadoop都分别需要启动那些进程，他们的作用分别是什么，尽可能写得全面些。"><a href="#请列出正常工作的hadoop集群中hadoop都分别需要启动那些进程，他们的作用分别是什么，尽可能写得全面些。" class="headerlink" title="请列出正常工作的hadoop集群中hadoop都分别需要启动那些进程，他们的作用分别是什么，尽可能写得全面些。"></a>请列出正常工作的hadoop集群中hadoop都分别需要启动那些进程，他们的作用分别是什么，尽可能写得全面些。</h3></li>
<li><h3 id="hdfs-的数据压缩算法"><a href="#hdfs-的数据压缩算法" class="headerlink" title="hdfs 的数据压缩算法?"></a>hdfs 的数据压缩算法?</h3></li>
<li><h3 id="启动hadoop时报如下错误，如何解决："><a href="#启动hadoop时报如下错误，如何解决：" class="headerlink" title="启动hadoop时报如下错误，如何解决："></a>启动hadoop时报如下错误，如何解决：</h3><p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fdjxmsidiej20xo0mu7nx.jpg" alt=""></p>
</li>
<li><h3 id="请写出以下执行命令"><a href="#请写出以下执行命令" class="headerlink" title="请写出以下执行命令"></a>请写出以下执行命令</h3><p>1）杀死一个job</p>
<p>2）删除hdfs上的/tmp/aaa目录</p>
<p>3）加入一个新的存储节点和删除一个计算节点需要刷新集群状态命令</p>
</li>
<li><h3 id="请列出你所知道的hadoop调度器，并简要说明其工作方法。"><a href="#请列出你所知道的hadoop调度器，并简要说明其工作方法。" class="headerlink" title="请列出你所知道的hadoop调度器，并简要说明其工作方法。"></a>请列出你所知道的hadoop调度器，并简要说明其工作方法。</h3></li>
<li><h3 id="请列出在你以前工作中所使用过的开发map-reduce的语言。"><a href="#请列出在你以前工作中所使用过的开发map-reduce的语言。" class="headerlink" title="请列出在你以前工作中所使用过的开发map reduce的语言。"></a>请列出在你以前工作中所使用过的开发map reduce的语言。</h3></li>
<li><h3 id="当前的日志采样格式为"><a href="#当前的日志采样格式为" class="headerlink" title="当前的日志采样格式为"></a>当前的日志采样格式为</h3><p>a,b,c,d</p>
<p>b,b,f,e</p>
<p>a,a,c,f</p>
<p>请用你最熟悉的语言编写一个map reduce 程序，计算第四列每个元素出现的个数。</p>
</li>
<li><h3 id="你认为用java，streaming，pipe方式开发-map-reduce-，各有哪些优缺点。"><a href="#你认为用java，streaming，pipe方式开发-map-reduce-，各有哪些优缺点。" class="headerlink" title="你认为用java，streaming，pipe方式开发 map reduce ，各有哪些优缺点。"></a>你认为用java，streaming，pipe方式开发 map reduce ，各有哪些优缺点。</h3></li>
<li><h3 id="hive有哪些方式保存元数据的，各有哪些特点。"><a href="#hive有哪些方式保存元数据的，各有哪些特点。" class="headerlink" title="hive有哪些方式保存元数据的，各有哪些特点。"></a>hive有哪些方式保存元数据的，各有哪些特点。</h3></li>
<li><h3 id="请简述hadoop怎样实现二级排序。"><a href="#请简述hadoop怎样实现二级排序。" class="headerlink" title="请简述hadoop怎样实现二级排序。"></a>请简述hadoop怎样实现二级排序。</h3></li>
<li><h3 id="简述hadoop实现join的几种方法。"><a href="#简述hadoop实现join的几种方法。" class="headerlink" title="简述hadoop实现join的几种方法。"></a>简述hadoop实现join的几种方法。</h3></li>
<li><h3 id="请用java实现非递归二分查找。"><a href="#请用java实现非递归二分查找。" class="headerlink" title="请用java实现非递归二分查找。"></a>请用java实现非递归二分查找。</h3></li>
<li><h3 id="请简述mapreduce中combiner，partition作用。"><a href="#请简述mapreduce中combiner，partition作用。" class="headerlink" title="请简述mapreduce中combiner，partition作用。"></a>请简述mapreduce中combiner，partition作用。</h3></li>
<li><h3 id="某个目录下有两个文件a-txt和b-txt，文件格式为（ip-username），例如："><a href="#某个目录下有两个文件a-txt和b-txt，文件格式为（ip-username），例如：" class="headerlink" title="某个目录下有两个文件a.txt和b.txt，文件格式为（ip username），例如："></a>某个目录下有两个文件a.txt和b.txt，文件格式为（ip username），例如：</h3><p>a.txt</p>
<p>127.0.0.1 zhangsan</p>
<p>127.0.0.1 wangxiaoer</p>
<p>127.0.0.2 lisi</p>
<p>127.0.0.3 wangwu</p>
<p>​</p>
<p>b.txt</p>
<p>127.0.0.4 lixiaolu</p>
<p>127.0.0.1 lisi</p>
<p>每个文件至少有100万行，请使用linux命令行完成如下工作：</p>
<p>1）两个文件各自的ip数，以及宗ip数</p>
<p>2）出现在b.txt而没有出现在a.txt的ip</p>
<p>3）每个username 出现的次数，以及每个username对应的ip数</p>
</li>
<li><h3 id="hive内部表和外部表的区别？"><a href="#hive内部表和外部表的区别？" class="headerlink" title="hive内部表和外部表的区别？"></a>hive内部表和外部表的区别？</h3></li>
<li><h3 id="hbase的rowkey怎么创建比较好？列族怎么创建比较好？"><a href="#hbase的rowkey怎么创建比较好？列族怎么创建比较好？" class="headerlink" title="hbase的rowkey怎么创建比较好？列族怎么创建比较好？"></a>hbase的rowkey怎么创建比较好？列族怎么创建比较好？</h3></li>
<li><h3 id="用mapreduce怎么处理数据倾斜问题？"><a href="#用mapreduce怎么处理数据倾斜问题？" class="headerlink" title="用mapreduce怎么处理数据倾斜问题？"></a>用mapreduce怎么处理数据倾斜问题？</h3></li>
<li><h3 id="hadoop框架中怎么优化？"><a href="#hadoop框架中怎么优化？" class="headerlink" title="hadoop框架中怎么优化？"></a>hadoop框架中怎么优化？</h3></li>
<li><h3 id="hbase内部是什么机制？"><a href="#hbase内部是什么机制？" class="headerlink" title="hbase内部是什么机制？"></a>hbase内部是什么机制？</h3></li>
<li><h3 id="我们在开发分布式计算job的，是否可以去掉reduce阶段？"><a href="#我们在开发分布式计算job的，是否可以去掉reduce阶段？" class="headerlink" title="我们在开发分布式计算job的，是否可以去掉reduce阶段？"></a>我们在开发分布式计算job的，是否可以去掉reduce阶段？</h3></li>
<li><h3 id="hdfs的数据压缩算法？"><a href="#hdfs的数据压缩算法？" class="headerlink" title="hdfs的数据压缩算法？"></a>hdfs的数据压缩算法？</h3></li>
<li><h3 id="mapreduce的调度模式？"><a href="#mapreduce的调度模式？" class="headerlink" title="mapreduce的调度模式？"></a>mapreduce的调度模式？</h3></li>
<li><h3 id="hive底层与数据库交互原理？"><a href="#hive底层与数据库交互原理？" class="headerlink" title="hive底层与数据库交互原理？"></a>hive底层与数据库交互原理？</h3></li>
<li><h3 id="hbase过滤器实现原则？"><a href="#hbase过滤器实现原则？" class="headerlink" title="hbase过滤器实现原则？"></a>hbase过滤器实现原则？</h3></li>
<li><h3 id="reduce后输出的数据量有多大？"><a href="#reduce后输出的数据量有多大？" class="headerlink" title="reduce后输出的数据量有多大？"></a>reduce后输出的数据量有多大？</h3></li>
<li><h3 id="现场出问题测试mapreduce掌握情况和hive的hql语句掌握情况？"><a href="#现场出问题测试mapreduce掌握情况和hive的hql语句掌握情况？" class="headerlink" title="现场出问题测试mapreduce掌握情况和hive的hql语句掌握情况？"></a>现场出问题测试mapreduce掌握情况和hive的hql语句掌握情况？</h3></li>
<li><h3 id="datanode在什么情况下不会备份？"><a href="#datanode在什么情况下不会备份？" class="headerlink" title="datanode在什么情况下不会备份？"></a>datanode在什么情况下不会备份？</h3></li>
<li><h3 id="combine出现在那个过程？"><a href="#combine出现在那个过程？" class="headerlink" title="combine出现在那个过程？"></a>combine出现在那个过程？</h3></li>
<li><h3 id="hdfs的体系结构？"><a href="#hdfs的体系结构？" class="headerlink" title="hdfs的体系结构？"></a>hdfs的体系结构？</h3></li>
<li><h3 id="flush的过程？"><a href="#flush的过程？" class="headerlink" title="flush的过程？"></a>flush的过程？</h3></li>
<li><h3 id="什么是队列？"><a href="#什么是队列？" class="headerlink" title="什么是队列？"></a>什么是队列？</h3></li>
<li><h3 id="list和set的区别？"><a href="#list和set的区别？" class="headerlink" title="list和set的区别？"></a>list和set的区别？</h3></li>
<li><h3 id="数据库的三大范式？"><a href="#数据库的三大范式？" class="headerlink" title="数据库的三大范式？"></a>数据库的三大范式？</h3></li>
<li><h3 id="三个datanode，当有一个datanode出现错误会怎么样？"><a href="#三个datanode，当有一个datanode出现错误会怎么样？" class="headerlink" title="三个datanode，当有一个datanode出现错误会怎么样？"></a>三个datanode，当有一个datanode出现错误会怎么样？</h3></li>
<li><h3 id="sqoop在导入数据到mysql中，如何让数据不重复导入？如果存在数据问题sqoop如何处理？"><a href="#sqoop在导入数据到mysql中，如何让数据不重复导入？如果存在数据问题sqoop如何处理？" class="headerlink" title="sqoop在导入数据到mysql中，如何让数据不重复导入？如果存在数据问题sqoop如何处理？"></a>sqoop在导入数据到mysql中，如何让数据不重复导入？如果存在数据问题sqoop如何处理？</h3></li>
<li><h3 id="使用hive或者自定义MR实现如下逻辑："><a href="#使用hive或者自定义MR实现如下逻辑：" class="headerlink" title="使用hive或者自定义MR实现如下逻辑："></a>使用hive或者自定义MR实现如下逻辑：</h3><p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fdjyfmy5pwj212q0gkju7.jpg" alt=""></p>
<p>字段解释：</p>
<p>product_ no:用户手机号；</p>
<p>lac_id:用户所在基站；</p>
<p>start_time:用户在此基站的开始时间；</p>
<p>staytime:用户在此基站的逗留时间。</p>
<p>需求描述：</p>
<p>根据lac_id和start_time知道用户当时的位置，根据staytime知道用户各个基站的逗留时长。根据轨迹合并连续基站的staytime。最终得到每一个用户按时间排序在每一个基站驻留时长。</p>
<p>期望输出举例：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdjyfn58u8j212c080wfn.jpg" alt=""></p>
</li>
<li><h3 id="请随意使用各种类型的脚本语言实现：批量将指定目录下的所有文件中的-HADOOP-HOME替换成-home-ocetl-app-hadoop"><a href="#请随意使用各种类型的脚本语言实现：批量将指定目录下的所有文件中的-HADOOP-HOME替换成-home-ocetl-app-hadoop" class="headerlink" title="请随意使用各种类型的脚本语言实现：批量将指定目录下的所有文件中的$HADOOP_HOME替换成/home/ocetl/app/hadoop"></a>请随意使用各种类型的脚本语言实现：批量将指定目录下的所有文件中的$HADOOP_HOME替换成/home/ocetl/app/hadoop</h3></li>
<li><h3 id="假设有-10-台主机，H1-到-H10，在开启-SSH-互信的情况下，编写一个或多个脚本实-现在所有的远程主机上执行脚本的功能："><a href="#假设有-10-台主机，H1-到-H10，在开启-SSH-互信的情况下，编写一个或多个脚本实-现在所有的远程主机上执行脚本的功能：" class="headerlink" title="假设有 10 台主机，H1 到 H10，在开启 SSH 互信的情况下，编写一个或多个脚本实 现在所有的远程主机上执行脚本的功能："></a>假设有 10 台主机，H1 到 H10，在开启 SSH 互信的情况下，编写一个或多个脚本实 现在所有的远程主机上执行脚本的功能：</h3><p>例如:runRemoteCmd.sh “ls -l”</p>
<p>期望结果:</p>
<p>H1:</p>
<p>XXXXXXXX</p>
<p>XXXXXXXX</p>
<p>XXXXXXXX</p>
<p>H2:</p>
<p>XXXXXXXX</p>
<p>XXXXXXXX</p>
<p>XXXXXXXX</p>
<p>H3:</p>
<p>…</p>
</li>
<li><h3 id="描述一下-hadoop-中，有哪些地方使用了缓存机制，作用分别是什么"><a href="#描述一下-hadoop-中，有哪些地方使用了缓存机制，作用分别是什么" class="headerlink" title="描述一下 hadoop 中，有哪些地方使用了缓存机制，作用分别是什么"></a>描述一下 hadoop 中，有哪些地方使用了缓存机制，作用分别是什么</h3></li>
<li><h3 id="请描述-https-issues-apache-org-jira-browse-HDFS-2379-说的是什么问题，最终-解决的思路是什么"><a href="#请描述-https-issues-apache-org-jira-browse-HDFS-2379-说的是什么问题，最终-解决的思路是什么" class="headerlink" title="请描述 https://issues.apache.org/jira/browse/HDFS-2379 说的是什么问题，最终 解决的思路是什么?"></a>请描述 <a href="https://issues.apache.org/jira/browse/HDFS-2379" target="_blank" rel="external">https://issues.apache.org/jira/browse/HDFS-2379</a> 说的是什么问题，最终 解决的思路是什么?</h3></li>
<li><h3 id="MapReduce-开发能力"><a href="#MapReduce-开发能力" class="headerlink" title="MapReduce 开发能力"></a>MapReduce 开发能力</h3><p>请参照 wordcount 实现一个自己的 map reduce，需求为:</p>
<p>a 输入文件格式: </p>
<p>xxx,xxx,xxx,xxx,xxx,xxx,xxx</p>
<p>b 输出文件格式: </p>
<p>xxx,20</p>
<p>xxx,30</p>
<p>xxx.40</p>
<p>c 功能:根据命令行参数统计输入文件中指定关键字出现的次数，并展示出来</p>
<p>例如:hadoop jar xxxxx.jar keywordcount xxx,xxx,xxx,xxx(四个关键字)</p>
</li>
<li><h3 id="Linux-操作系统知识考察"><a href="#Linux-操作系统知识考察" class="headerlink" title="Linux 操作系统知识考察"></a>Linux 操作系统知识考察</h3><p>请列举曾经修改过的/etc 下的配置文件，并说明修改要解决的问题?</p>
</li>
<li><h3 id="写代码实现-1G-大小的文本文件，行分隔符为-x01-x02-统计一下该文件中的总行数，要求注意边界情况的处理"><a href="#写代码实现-1G-大小的文本文件，行分隔符为-x01-x02-统计一下该文件中的总行数，要求注意边界情况的处理" class="headerlink" title="写代码实现 1G 大小的文本文件，行分隔符为\x01\x02,统计一下该文件中的总行数，要求注意边界情况的处理"></a>写代码实现 1G 大小的文本文件，行分隔符为\x01\x02,统计一下该文件中的总行数，要求注意边界情况的处理</h3></li>
<li><h3 id="设计一套系统，使之能够从不断增加的不同的数据源中，提取指定格式的数据。-要求"><a href="#设计一套系统，使之能够从不断增加的不同的数据源中，提取指定格式的数据。-要求" class="headerlink" title="设计一套系统，使之能够从不断增加的不同的数据源中，提取指定格式的数据。 要求:"></a>设计一套系统，使之能够从不断增加的不同的数据源中，提取指定格式的数据。 要求:</h3><p>1)、运行结果要能大致得知提取效果，并可据此持续改进提取方法; </p>
<p>2)、由于数据来源的差异性，请给出可弹性配置的程序框架;</p>
<p>3)、数据来源可能有 Mysql,sqlserver 等; </p>
<p>4)、该系统具备持续挖掘的能力，即，可重复提取更多信息</p>
</li>
<li><h3 id="现有-1-亿个整数均匀分布，如果要得到前-1K-个最大的数，求最优的算法。-先不考虑内存的限制，也不考虑读写外存，时间复杂度最少的算法即为最优算法"><a href="#现有-1-亿个整数均匀分布，如果要得到前-1K-个最大的数，求最优的算法。-先不考虑内存的限制，也不考虑读写外存，时间复杂度最少的算法即为最优算法" class="headerlink" title="现有 1 亿个整数均匀分布，如果要得到前 1K 个最大的数，求最优的算法。(先不考虑内存的限制，也不考虑读写外存，时间复杂度最少的算法即为最优算法)"></a>现有 1 亿个整数均匀分布，如果要得到前 1K 个最大的数，求最优的算法。(先不考虑内存的限制，也不考虑读写外存，时间复杂度最少的算法即为最优算法)</h3></li>
<li><h3 id="MapReduce-大致流程"><a href="#MapReduce-大致流程" class="headerlink" title="MapReduce 大致流程?"></a>MapReduce 大致流程?</h3></li>
<li><h3 id="用-mapreduce-实现-sql-语句-select-count-x-from-a-group-by-b"><a href="#用-mapreduce-实现-sql-语句-select-count-x-from-a-group-by-b" class="headerlink" title="用 mapreduce 实现 sql 语句 select count(x) from a group by b?"></a>用 mapreduce 实现 sql 语句 select count(x) from a group by b?</h3></li>
<li><h3 id="用-mapreduce-如何实现两张表连接，有哪些方法"><a href="#用-mapreduce-如何实现两张表连接，有哪些方法" class="headerlink" title="用 mapreduce 如何实现两张表连接，有哪些方法?"></a>用 mapreduce 如何实现两张表连接，有哪些方法?</h3></li>
<li><h3 id="搭建-hadoop-集群，master-slave-都运行那些服务？"><a href="#搭建-hadoop-集群，master-slave-都运行那些服务？" class="headerlink" title="搭建 hadoop 集群，master/slave 都运行那些服务？"></a>搭建 hadoop 集群，master/slave 都运行那些服务？</h3></li>
<li><h3 id="HDFS，replica-如何定位？"><a href="#HDFS，replica-如何定位？" class="headerlink" title="HDFS，replica 如何定位？"></a>HDFS，replica 如何定位？</h3></li>
<li><h3 id="Hadoop-参数调优，cluster-level-JVM-map-reduce-slots-job-level-reducer-memory-use-combiner-use-compression"><a href="#Hadoop-参数调优，cluster-level-JVM-map-reduce-slots-job-level-reducer-memory-use-combiner-use-compression" class="headerlink" title="Hadoop 参数调优，cluster level: JVM, map/reduce slots, job level: reducer #,memory, use combiner? use compression?"></a>Hadoop 参数调优，cluster level: JVM, map/reduce slots, job level: reducer #,memory, use combiner? use compression?</h3></li>
<li><h3 id="pig-latin-Hive-语法有什么不同？"><a href="#pig-latin-Hive-语法有什么不同？" class="headerlink" title="pig latin, Hive 语法有什么不同？"></a>pig latin, Hive 语法有什么不同？</h3></li>
<li><h3 id="描述-HBase-zookeeper-搭建过程？"><a href="#描述-HBase-zookeeper-搭建过程？" class="headerlink" title="描述 HBase, zookeeper 搭建过程？"></a>描述 HBase, zookeeper 搭建过程？</h3></li>
<li><h3 id="hadoop-运行的原理"><a href="#hadoop-运行的原理" class="headerlink" title="hadoop 运行的原理?"></a>hadoop 运行的原理?</h3></li>
<li><h3 id="HDFS-存储的机制"><a href="#HDFS-存储的机制" class="headerlink" title="HDFS 存储的机制?"></a>HDFS 存储的机制?</h3></li>
<li><h3 id="如何确认-Hadoop-集群的健康状况。"><a href="#如何确认-Hadoop-集群的健康状况。" class="headerlink" title="如何确认 Hadoop 集群的健康状况。"></a>如何确认 Hadoop 集群的健康状况。</h3></li>
<li><h3 id="mapreduce-作业，不使用-reduce-来输出，用什么能代替-reduce-的功能-71、hive-如何调优"><a href="#mapreduce-作业，不使用-reduce-来输出，用什么能代替-reduce-的功能-71、hive-如何调优" class="headerlink" title="mapreduce 作业，不使用 reduce 来输出，用什么能代替 reduce 的功能 71、hive 如何调优?"></a>mapreduce 作业，不使用 reduce 来输出，用什么能代替 reduce 的功能 71、hive 如何调优?</h3></li>
<li><h3 id="hive-如何权限控制"><a href="#hive-如何权限控制" class="headerlink" title="hive 如何权限控制?"></a>hive 如何权限控制?</h3></li>
<li><h3 id="hbase-写数据的原理是什么"><a href="#hbase-写数据的原理是什么" class="headerlink" title="hbase 写数据的原理是什么?"></a>hbase 写数据的原理是什么?</h3></li>
<li><h3 id="hive-能像关系数据库那样，建多个库吗"><a href="#hive-能像关系数据库那样，建多个库吗" class="headerlink" title="hive 能像关系数据库那样，建多个库吗?"></a>hive 能像关系数据库那样，建多个库吗?</h3></li>
<li><h3 id="hbase-宕机如何处理"><a href="#hbase-宕机如何处理" class="headerlink" title="hbase 宕机如何处理?"></a>hbase 宕机如何处理?</h3></li>
<li><h3 id="假设公司要建一个数据中心，你会如何规划"><a href="#假设公司要建一个数据中心，你会如何规划" class="headerlink" title="假设公司要建一个数据中心，你会如何规划?"></a>假设公司要建一个数据中心，你会如何规划?</h3></li>
<li><h3 id="用-Hadoop-分析海量日志文件，每行日志记录了如下数据-TableName-表名-，Time-时间-，User-用户-，TimeSpan-时间开销-。要求-编写-MapReduce-程序算出高峰时间段-如上午-10-点-哪张表被访问的最频繁，以-及这段时间访问这张表最多的用户，以及这个用户的总时间开销。"><a href="#用-Hadoop-分析海量日志文件，每行日志记录了如下数据-TableName-表名-，Time-时间-，User-用户-，TimeSpan-时间开销-。要求-编写-MapReduce-程序算出高峰时间段-如上午-10-点-哪张表被访问的最频繁，以-及这段时间访问这张表最多的用户，以及这个用户的总时间开销。" class="headerlink" title="用 Hadoop 分析海量日志文件，每行日志记录了如下数据: TableName(表名)，Time(时间)，User(用户)，TimeSpan(时间开销)。要求:编写 MapReduce 程序算出高峰时间段(如上午 10 点)哪张表被访问的最频繁，以 及这段时间访问这张表最多的用户，以及这个用户的总时间开销。"></a>用 Hadoop 分析海量日志文件，每行日志记录了如下数据: TableName(表名)，Time(时间)，User(用户)，TimeSpan(时间开销)。要求:编写 MapReduce 程序算出高峰时间段(如上午 10 点)哪张表被访问的最频繁，以 及这段时间访问这张表最多的用户，以及这个用户的总时间开销。</h3><h2 id="hadoop-选择判断题"><a href="#hadoop-选择判断题" class="headerlink" title="hadoop 选择判断题"></a>hadoop 选择判断题</h2></li>
<li><h3 id="下面哪个程序负责-HDFS-数据存储。"><a href="#下面哪个程序负责-HDFS-数据存储。" class="headerlink" title="下面哪个程序负责 HDFS 数据存储。"></a>下面哪个程序负责 HDFS 数据存储。</h3><p>a)NameNode </p>
<p>b)Jobtracker </p>
<p>c)Datanode </p>
<p>d)secondaryNameNode </p>
<p>e)tasktracker </p>
</li>
<li><h3 id="HDfS-中的-block-默认保存几份"><a href="#HDfS-中的-block-默认保存几份" class="headerlink" title="HDfS 中的 block 默认保存几份?"></a>HDfS 中的 block 默认保存几份?</h3><p>a)3 份 </p>
<p>b)2 份 </p>
<p>c)1 份 </p>
<p>d)不确定</p>
</li>
<li><h3 id="下列哪个程序通常与-NameNode-在一个节点启动"><a href="#下列哪个程序通常与-NameNode-在一个节点启动" class="headerlink" title="下列哪个程序通常与 NameNode 在一个节点启动?"></a>下列哪个程序通常与 NameNode 在一个节点启动?</h3><p>a)SecondaryNameNode </p>
<p>b)DataNode </p>
<p>c)TaskTracker </p>
<p>d)Jobtracke</p>
</li>
<li><h3 id="关于-SecondaryNameNode-哪项是正确的"><a href="#关于-SecondaryNameNode-哪项是正确的" class="headerlink" title="关于 SecondaryNameNode 哪项是正确的?"></a>关于 SecondaryNameNode 哪项是正确的?</h3><p>a)它是 NameNode 的热备 </p>
<p>b)它对内存没有要求</p>
<p>c)它的目的是帮助 NameNode 合并编辑日志，减少 NameNode 启动时间 </p>
<p>d)SecondaryNameNode 应与 NameNode 部署到一个节点</p>
<p>​</p>
<h3 id="多选题"><a href="#多选题" class="headerlink" title="多选题:"></a>多选题:</h3></li>
<li><h3 id="下列哪项可以作为集群的管理工具？"><a href="#下列哪项可以作为集群的管理工具？" class="headerlink" title="下列哪项可以作为集群的管理工具？"></a>下列哪项可以作为集群的管理工具？</h3><p>a)Puppet </p>
<p>b)Pdsh </p>
<p>c)Cloudera Manager </p>
<p>d)Zookeeper </p>
</li>
<li><h3 id="配置机架感知的下面哪项正确-？"><a href="#配置机架感知的下面哪项正确-？" class="headerlink" title="配置机架感知的下面哪项正确 ？"></a>配置机架感知的下面哪项正确 ？</h3><p>a)如果一个机架出问题，不会影响数据读写 </p>
<p>b)写入数据的时候会写到不同机架的 DataNode 中 </p>
<p>c)MapReduce 会根据机架获取离自己比较近的网络数据</p>
</li>
<li><h3 id="Client-端上传文件的时候下列哪项正确？"><a href="#Client-端上传文件的时候下列哪项正确？" class="headerlink" title="Client 端上传文件的时候下列哪项正确？"></a>Client 端上传文件的时候下列哪项正确？</h3><p>a)数据经过 NameNode 传递给 DataNode</p>
<p>b)Client 端将文件切分为 Block，依次上传</p>
<p>c)Client 只上传数据到一台 DataNode，然后由 NameNode 负责 Block 复制工作 </p>
</li>
<li><h3 id="下列哪个是-Hadoop-运行的模式？"><a href="#下列哪个是-Hadoop-运行的模式？" class="headerlink" title="下列哪个是 Hadoop 运行的模式？"></a>下列哪个是 Hadoop 运行的模式？</h3><p>a)单机版 </p>
<p>b)伪分布式 </p>
<p>c)分布式</p>
</li>
<li><h3 id="Cloudera-提供哪几种安装-CDH-的方法？"><a href="#Cloudera-提供哪几种安装-CDH-的方法？" class="headerlink" title="Cloudera 提供哪几种安装 CDH 的方法？"></a>Cloudera 提供哪几种安装 CDH 的方法？</h3><p>a)Cloudera manager </p>
<p>b)Tar ball </p>
<p>c)Yum </p>
<p>d)Rpm</p>
<h3 id="判断题"><a href="#判断题" class="headerlink" title="判断题:"></a>判断题:</h3></li>
<li><h3 id="Ganglia-不仅可以进行监控，也可以进行告警。"><a href="#Ganglia-不仅可以进行监控，也可以进行告警。" class="headerlink" title="Ganglia 不仅可以进行监控，也可以进行告警。( )"></a>Ganglia 不仅可以进行监控，也可以进行告警。( )</h3></li>
<li><h3 id="Block-Size-是不可以修改的。"><a href="#Block-Size-是不可以修改的。" class="headerlink" title="Block Size 是不可以修改的。( )"></a>Block Size 是不可以修改的。( )</h3></li>
<li><h3 id="Nagios-不可以监控-Hadoop-集群，因为它不提供-Hadoop-支持。"><a href="#Nagios-不可以监控-Hadoop-集群，因为它不提供-Hadoop-支持。" class="headerlink" title="Nagios 不可以监控 Hadoop 集群，因为它不提供 Hadoop 支持。( )"></a>Nagios 不可以监控 Hadoop 集群，因为它不提供 Hadoop 支持。( )</h3></li>
<li><h3 id="如果-NameNode-意外终止，SecondaryNameNode-会接替它使集群继续工作。"><a href="#如果-NameNode-意外终止，SecondaryNameNode-会接替它使集群继续工作。" class="headerlink" title="如果 NameNode 意外终止，SecondaryNameNode 会接替它使集群继续工作。( )"></a>如果 NameNode 意外终止，SecondaryNameNode 会接替它使集群继续工作。( )</h3></li>
<li><h3 id="Cloudera-CDH-是需要付费使用的。"><a href="#Cloudera-CDH-是需要付费使用的。" class="headerlink" title="Cloudera CDH 是需要付费使用的。( )"></a>Cloudera CDH 是需要付费使用的。( )</h3></li>
<li><h3 id="Hadoop-是-Java-开发的，所以-MapReduce-只支持-Java-语言编写。"><a href="#Hadoop-是-Java-开发的，所以-MapReduce-只支持-Java-语言编写。" class="headerlink" title="Hadoop 是 Java 开发的，所以 MapReduce 只支持 Java 语言编写。( )"></a>Hadoop 是 Java 开发的，所以 MapReduce 只支持 Java 语言编写。( )</h3></li>
<li><h3 id="Hadoop-支持数据的随机读写。"><a href="#Hadoop-支持数据的随机读写。" class="headerlink" title="Hadoop 支持数据的随机读写。( )"></a>Hadoop 支持数据的随机读写。( )</h3></li>
<li><h3 id="NameNode-负责管理-metadata，client-端每次读写请求，它都会从磁盘中读取或-则会写入-metadata-信息并反馈-client-端。"><a href="#NameNode-负责管理-metadata，client-端每次读写请求，它都会从磁盘中读取或-则会写入-metadata-信息并反馈-client-端。" class="headerlink" title="NameNode 负责管理 metadata，client 端每次读写请求，它都会从磁盘中读取或 则会写入 metadata 信息并反馈 client 端。( )"></a>NameNode 负责管理 metadata，client 端每次读写请求，它都会从磁盘中读取或 则会写入 metadata 信息并反馈 client 端。( )</h3></li>
<li><h3 id="NameNode-本地磁盘保存了-Block-的位置信息。"><a href="#NameNode-本地磁盘保存了-Block-的位置信息。" class="headerlink" title="NameNode 本地磁盘保存了 Block 的位置信息。( )"></a>NameNode 本地磁盘保存了 Block 的位置信息。( )</h3></li>
<li><h3 id="DataNode-通过长连接与-NameNode-保持通信。"><a href="#DataNode-通过长连接与-NameNode-保持通信。" class="headerlink" title="DataNode 通过长连接与 NameNode 保持通信。( )"></a>DataNode 通过长连接与 NameNode 保持通信。( )</h3></li>
<li><h3 id="Hadoop-自身具有严格的权限管理和安全措施保障集群正常运行。"><a href="#Hadoop-自身具有严格的权限管理和安全措施保障集群正常运行。" class="headerlink" title="Hadoop 自身具有严格的权限管理和安全措施保障集群正常运行。( )"></a>Hadoop 自身具有严格的权限管理和安全措施保障集群正常运行。( )</h3></li>
<li><h3 id="Slave-节点要存储数据，所以它的磁盘越大越好。"><a href="#Slave-节点要存储数据，所以它的磁盘越大越好。" class="headerlink" title="Slave 节点要存储数据，所以它的磁盘越大越好。( )"></a>Slave 节点要存储数据，所以它的磁盘越大越好。( )</h3></li>
<li><h3 id="hadoop-dfsadmin-–report-命令用于检测-HDFS-损坏块。"><a href="#hadoop-dfsadmin-–report-命令用于检测-HDFS-损坏块。" class="headerlink" title="hadoop dfsadmin –report 命令用于检测 HDFS 损坏块。( )"></a>hadoop dfsadmin –report 命令用于检测 HDFS 损坏块。( )</h3></li>
<li><h3 id="Hadoop-默认调度器策略为-FIFO"><a href="#Hadoop-默认调度器策略为-FIFO" class="headerlink" title="Hadoop 默认调度器策略为 FIFO( )"></a>Hadoop 默认调度器策略为 FIFO( )</h3></li>
<li><h3 id="集群内每个节点都应该配-RAID，这样避免单磁盘损坏，影响整个节点运行。"><a href="#集群内每个节点都应该配-RAID，这样避免单磁盘损坏，影响整个节点运行。" class="headerlink" title="集群内每个节点都应该配 RAID，这样避免单磁盘损坏，影响整个节点运行。( )"></a>集群内每个节点都应该配 RAID，这样避免单磁盘损坏，影响整个节点运行。( )</h3></li>
<li><h3 id="因为-HDFS-有多个副本，所以-NameNode-是不存在单点问题的。"><a href="#因为-HDFS-有多个副本，所以-NameNode-是不存在单点问题的。" class="headerlink" title="因为 HDFS 有多个副本，所以 NameNode 是不存在单点问题的。( )"></a>因为 HDFS 有多个副本，所以 NameNode 是不存在单点问题的。( )</h3></li>
<li><h3 id="每个-map-槽就是一个线程。"><a href="#每个-map-槽就是一个线程。" class="headerlink" title="每个 map 槽就是一个线程。( )"></a>每个 map 槽就是一个线程。( )</h3></li>
<li><h3 id="Mapreduce-的-input-split-就是一个-block。"><a href="#Mapreduce-的-input-split-就是一个-block。" class="headerlink" title="Mapreduce 的 input split 就是一个 block。( )"></a>Mapreduce 的 input split 就是一个 block。( )</h3></li>
<li><h3 id="NameNode-的-Web-UI-端口是-50030，它通过-jetty-启动的-Web-服务。"><a href="#NameNode-的-Web-UI-端口是-50030，它通过-jetty-启动的-Web-服务。" class="headerlink" title="NameNode 的 Web UI 端口是 50030，它通过 jetty 启动的 Web 服务。( )"></a>NameNode 的 Web UI 端口是 50030，它通过 jetty 启动的 Web 服务。( )</h3></li>
<li><h3 id="Hadoop-环境变量中的-HADOOP-HEAPSIZE-用于设置所有-Hadoop-守护线程的内存。它默认是-200-GB。"><a href="#Hadoop-环境变量中的-HADOOP-HEAPSIZE-用于设置所有-Hadoop-守护线程的内存。它默认是-200-GB。" class="headerlink" title="Hadoop 环境变量中的 HADOOP_HEAPSIZE 用于设置所有 Hadoop 守护线程的内存。它默认是 200 GB。( )"></a>Hadoop 环境变量中的 HADOOP_HEAPSIZE 用于设置所有 Hadoop 守护线程的内存。它默认是 200 GB。( )</h3></li>
<li><h3 id="DataNode-首次加入-cluster-的时候，如果-log-中报告不兼容文件版本，那需要-NameNode执行“Hadoopnamenode-format”操作格式化磁盘。"><a href="#DataNode-首次加入-cluster-的时候，如果-log-中报告不兼容文件版本，那需要-NameNode执行“Hadoopnamenode-format”操作格式化磁盘。" class="headerlink" title="DataNode 首次加入 cluster 的时候，如果 log 中报告不兼容文件版本，那需要 NameNode执行“Hadoopnamenode-format”操作格式化磁盘。( )"></a>DataNode 首次加入 cluster 的时候，如果 log 中报告不兼容文件版本，那需要 NameNode执行“Hadoopnamenode-format”操作格式化磁盘。( )</h3><h2 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h2></li>
<li><h3 id="hive-实现统计的查询语句是什么"><a href="#hive-实现统计的查询语句是什么" class="headerlink" title="hive 实现统计的查询语句是什么?"></a>hive 实现统计的查询语句是什么?</h3></li>
<li><h3 id="生产环境中为什么建议使用外部表"><a href="#生产环境中为什么建议使用外部表" class="headerlink" title="生产环境中为什么建议使用外部表?"></a>生产环境中为什么建议使用外部表?</h3></li>
<li><h3 id="hadoop-mapreduce-创建类-DataWritable-的作用是什么"><a href="#hadoop-mapreduce-创建类-DataWritable-的作用是什么" class="headerlink" title="hadoop mapreduce 创建类 DataWritable 的作用是什么?"></a>hadoop mapreduce 创建类 DataWritable 的作用是什么?</h3></li>
<li><h3 id="为什么创建类-DataWritable"><a href="#为什么创建类-DataWritable" class="headerlink" title="为什么创建类 DataWritable?"></a>为什么创建类 DataWritable?</h3></li>
<li><h3 id="如何实现统计手机流量"><a href="#如何实现统计手机流量" class="headerlink" title="如何实现统计手机流量?"></a>如何实现统计手机流量?</h3></li>
<li><h3 id="对比-hive-与-mapreduce-统计手机流量的区别"><a href="#对比-hive-与-mapreduce-统计手机流量的区别" class="headerlink" title="对比 hive 与 mapreduce 统计手机流量的区别?"></a>对比 hive 与 mapreduce 统计手机流量的区别?</h3></li>
<li><h3 id="对于-hive，你写过哪些-UDF-函数，作用是什么"><a href="#对于-hive，你写过哪些-UDF-函数，作用是什么" class="headerlink" title="对于 hive，你写过哪些 UDF 函数，作用是什么?"></a>对于 hive，你写过哪些 UDF 函数，作用是什么?</h3></li>
</ol>
<h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><h3 id="1-RPC原理？"><a href="#1-RPC原理？" class="headerlink" title="1. RPC原理？"></a>1. RPC原理？</h3><p><strong>远程过程调用</strong>（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信<a href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E7%B5%A1%E5%82%B3%E8%BC%B8%E5%8D%94%E8%AD%B0" target="_blank" rel="external">协议</a>。该协议允许运行于一台计算机的<a href="https://zh.wikipedia.org/wiki/%E7%A8%8B%E5%BA%8F" target="_blank" rel="external">程序</a>调用另一台计算机的<a href="https://zh.wikipedia.org/wiki/%E5%AD%90%E7%A8%8B%E5%BA%8F" target="_blank" rel="external">子程序</a>，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用<a href="https://zh.wikipedia.org/wiki/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B" target="_blank" rel="external">面向对象编程</a>，那么远程过程调用亦可称作<strong>远程调用</strong>或<strong>远程方法调用</strong>，例：<a href="https://zh.wikipedia.org/wiki/Java_RMI" target="_blank" rel="external">Java RMI</a>。</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop 集群模式]]></title>
      <url>https://stanxia.github.io/2017/03/14/hadoop-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h2><p><font color="red">Single Node Cluster，即伪分布式模式（单机模式）</font>，将hadoop安装在一台机器上，通过进程来模拟各主机节点的协作和运行，其可靠性、稳定性都是非常差的，并且具备糟糕的性能效率，没有团队会在生产环境使用它。那么它是否就没有用呢？也不是的，通常使用这种模式进行开发和调试工作。</p>
<h2 id="完全分布式模式"><a href="#完全分布式模式" class="headerlink" title="完全分布式模式"></a>完全分布式模式</h2><p><font color="red">完全分布式模式(Full Distributed Cluster)</font>，将hadoop部署在至少两台机子上，数据块副本的数量通常也设置为2以上。该模式的集群，无论规模多大，只拥有1台Namenode节点，且也是唯一Active的工作节点。Namenode（简称NN）相当于hadoop文件系统的管家，对集群的所有文件访问和操作都经由NN统一协调管理。可想，当集群规模越来越庞大时，仅有一台NN，必定是不堪重负，那么它很容易就会挂掉，一旦挂掉，不仅集群立即瘫痪，还很容易造成数据丢失。另外，该模式通常ResourceManager（RM）也仅部署1台，ResourceManager是yarn的管家，主要管理任务的执行，例如MapReduce任务。与NN类似，当集群提交的作业过于繁重时，其同样面临超负载的问题。那么此模式是否也无用武之地呢？也不是的，视业务、资金等情况而定，因为该模式日后也可以安全升级成高可用模式。</p>
<h2 id="高可用模式"><a href="#高可用模式" class="headerlink" title="高可用模式"></a>高可用模式</h2><p><font color="red">高可用模式(HA Cluster)</font>，一般来说，分为NN的高可用和RM的高可用。在完全分布式的基础上，增加备用NN和RM节点。NN高可用，也就是集群里面会部署两台NN（最多也只能两台），以形成主备NN节点，达到高可用的目的。RM高可用与NN高可用类似，也是在集群里部署备用RM节点。不过此种模式下集群里面依然只有一台NN/RM处于Active工作状态，另一台则处于Standby的等待状态。当Active的NN/RM出现问题无法工作时，Standby的那台则立即无缝切入，继续保障集群正常运转。这种模式是很多企业都使用的，但是依然有缺陷。什么缺陷呢？虽然集群的可用性问题解决了，但是性能瓶颈依然存在——仅有一台NN/RM，由于无法横向扩展，其很可能会超负载运行。</p>
<h2 id="高可用联邦模式"><a href="#高可用联邦模式" class="headerlink" title="高可用联邦模式"></a>高可用联邦模式</h2><p><font color="red">高可用联邦模式(HA + Federation Cluster)</font>，解决了单纯HA模式的性能瓶颈。单纯的HA模式NN和RM之间虽然配置了HA，但是依旧仅有一台NN或RM同时运行，这可能会导致了NN或RM的负载过重，从而造成整个集群的性能瓶颈。而联邦模式将整个HA集群再划分为两个以上的集群，不同的集群之间通过Federation进行连接，不同集群间可以共享数据节点，也可以不共享，可以互相访问和操作数据，也可以不。这样便做到了HA集群的横向扩展，从而移除了单纯HA模式同时仅有1台NN/RM工作所带来的性能瓶颈。Federation模式，相当于在多个集群之上又构建了一个集群层次，从数据访问的角度看，也可以简单的将其理解为一台路由器，而每一个HA集群则是单独的网络，不同网络间通过Federation路由器进行沟通。此模式是目前hadoop生态中最高的一种模式，适用于规模较大的企业。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Yarn的ResourceManager配置HA(2.7.1)]]></title>
      <url>https://stanxia.github.io/2017/03/14/Yarn%E7%9A%84ResourceManager%E9%85%8D%E7%BD%AEHA-2-7-1/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Hadoop 2.4之前的版本，Yarn的ResourceManager是单点的。在Hadoop 2.4版本中，引入了ResourceManager HA。</p>
<ul>
<li>ResourceManager是主备模式。</li>
<li>可以一个主用RM、一个备用RM。也可以是一个主用RM，多个备用RM。</li>
<li>客户端可以看到多个RM。客户端连接时，需要轮循各个RM，直到找到主用RM。</li>
</ul>
<p>主备模式切换有两种模式：</p>
<ol>
<li>自动切换</li>
<li>手工切换</li>
</ol>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>在需要配置主备关系的两个节点的yarn-site.xml中，增加如下配置：</p>
<p>以ctrl、data01两个节点上配置主备RM为例。</p>
<p>本例为自动切换模式。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ctrl<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>data01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ctrl:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>data01:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>data01:2181,data02:2181,data03:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.zk-base-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/yarn-leader-election<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>Optional setting. The default value is /yarn-leader-election<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Enable automatic failover; By default, it is enabled only when HA is enabled.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ctrl:8132<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>data01:8132<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ctrl:8130<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>data01:8130<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ctrl:8131<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>data01:8131<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ctrl:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>data01:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<p><font color="red">注意：如下配置项需要删除：</font></p>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ctrl,data01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>在ctrl节点：通过start-yarn.sh启动ctrl节点上的ResourceManager以及各节点的NodeManager。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">start-yarn.sh</div></pre></td></tr></table></figure>
<p>在data01节点：启用第二个ResourceManager：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">su - hadoop</div><div class="line">yarn-daemon.sh start resourcemanager</div></pre></td></tr></table></figure>
<h2 id="维护"><a href="#维护" class="headerlink" title="维护"></a>维护</h2><p>查询主备状态</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ yarn rmadmin -getServiceState rm1</div><div class="line">active</div><div class="line"></div><div class="line">$ yarn rmadmin -getServiceState rm2</div><div class="line">standby</div></pre></td></tr></table></figure>
<p>对于手工切换模式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -transitionToActive rm1</div><div class="line">yarn rmadmin -transitionToStandby rm1</div></pre></td></tr></table></figure>
<p>对于自动切换模式，可以强制手工切换：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -transitionToActive rm1 --forcemanual</div><div class="line">yarn rmadmin -transitionToStandby rm1 --forcemanual</div></pre></td></tr></table></figure>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HDFS机架感知功能原理（rack awareness）]]></title>
      <url>https://stanxia.github.io/2017/03/14/HDFS%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%E5%8A%9F%E8%83%BD%E5%8E%9F%E7%90%86%EF%BC%88rack-awareness%EF%BC%89/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="机架感知"><a href="#机架感知" class="headerlink" title="机架感知"></a>机架感知</h2><p>HDFS NameNode对文件块复制相关所有事物负责，它周期性接受来自于DataNode的HeartBeat和BlockReport信息，HDFS文件块副本的放置对于系统整体的可靠性和性能有关键性影响。<br>一个简单但非优化的副本放置策略是，把副本分别放在不同机架，甚至不同IDC。这样可以防止整个机架、甚至整个IDC崩溃带来的错误，但是这样文件写必须在多个机架之间、甚至IDC之间传输，增加了副本写的代价。<br>在缺省配置下副本数是3个，通常的策略是：第一个副本放在和Client相同机架的Node里（如果Client不在集群范围，第一个Node是随机选取不太满或者不太忙的Node）；第二个副本放在与第一个Node不同的机架中的Node；第三个副本放在与第二个Node所在机架里不同的Node。<br>Hadoop的副本放置策略在可靠性（副本在不同机架）和带宽（只需跨越一个机架）中做了一个很好的平衡。<br>但是，HDFS如何知道各个DataNode的网络拓扑情况呢？它的机架感知功能需要 topology.script.file.name 属性定义的可执行文件（或者脚本）来实现，文件提供了NodeIP对应RackID的翻译。如果 topology.script.file.name 没有设定，则每个IP都会翻译成/default-rack。</p>
<h2 id="开启机架感知"><a href="#开启机架感知" class="headerlink" title="开启机架感知"></a>开启机架感知</h2><p><font color="red">默认情况下，Hadoop机架感知是没有启用的</font>，需要在NameNode机器的hadoop-site.xml里配置一个选项，例如：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>topology.script.file.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/path/to/script<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<p>这个配置选项的value指定为一个可执行程序，通常为一个脚本，该脚本接受一个参数，输出一个值。接受的参数通常为datanode机器的ip地址，而输出的值通常为该ip地址对应的datanode所在的rackID，例如”/rack1”。Namenode启动时，会判断该配置选项是否为空，如果非空，则表示已经启用机架感知的配置，此时namenode会根据配置寻找该脚本，并在接收到每一个datanode的heartbeat时，将该datanode的ip地址作为参数传给该脚本运行，并将得到的输出作为该datanode所属的机架，保存到内存的一个map中。</p>
<p>至于脚本的编写，就需要将真实的网络拓朴和机架信息了解清楚后，通过该脚本能够将机器的ip地址正确的映射到相应的机架上去。Hadoop官方给出的脚本：<a href="http://wiki.apache.org/hadoop/topology_rack_awareness_scripts" target="_blank" rel="external">http://wiki.apache.org/hadoop/topology_rack_awareness_scripts</a></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="没有开启机架感知"><a href="#没有开启机架感知" class="headerlink" title="没有开启机架感知"></a>没有开启机架感知</h3><p>当没有配置机架信息时，所有的机器hadoop都默认在同一个默认的机架下，名为 “/default-rack”，这种情况下，任何一台datanode机器，不管物理上是否属于同一个机架，都会被认为是在同一个机架下，此时，就很容易出现之前提到的增添机架间网络负载的情况。在没有机架信息的情况下，namenode默认将所有的slaves机器全部默认为在/default-rack下，此时写block时，三个datanode机器的选择完全是随机的。</p>
<h3 id="开启机架感知-1"><a href="#开启机架感知-1" class="headerlink" title="开启机架感知"></a>开启机架感知</h3><p>当配置了机架感知信息以后，hadoop在选择三个datanode时，就会进行相应的判断：</p>
<ol>
<li>如果上传本机不是一个datanode，而是一个客户端，那么就从所有slave机器中随机选择一台datanode作为第一个块的写入机器(datanode1)。而此时如果上传机器本身就是一个datanode，那么就将该datanode本身作为第一个块写入机器(datanode1)。</li>
<li>随后在datanode1所属的机架以外的另外的机架上，随机的选择一台，作为第二个block的写入datanode机器(datanode2)。</li>
<li>在写第三个block前，先判断是否前两个datanode是否是在同一个机架上，如果是在同一个机架，那么就尝试在另外一个机架上选择第三个datanode作为写入机器(datanode3)。而如果datanode1和datanode2没有在同一个机架上，则在datanode2所在的机架上选择一台datanode作为datanode3。</li>
<li>得到3个datanode的列表以后，从namenode返回该列表到DFSClient之前，会在namenode端首先根据该写入客户端跟datanode列表中每个datanode之间的“距离”由近到远进行一个排序，客户端根据这个顺序有近到远的进行数据块的写入。</li>
<li>当根据“距离”排好序的datanode节点列表返回给DFSClient以后，DFSClient便会创建Block OutputStream，并向这次block写入pipeline中的第一个节点（最近的节点）开始写入block数据。</li>
<li>写完第一个block以后，依次按照datanode列表中的次远的node进行写入，直到最后一个block写入成功，DFSClient返回成功，该block写入操作结束。</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>开启机架感知，namenode在选择数据块的写入datanode列表时，就充分考虑到了将block副本分散在不同机架下，并同时尽量地避免了之前描述的网络开销。</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[兼顾稳定和性能，58大数据平台的技术演进与实践]]></title>
      <url>https://stanxia.github.io/2017/03/13/%E5%85%BC%E9%A1%BE%E7%A8%B3%E5%AE%9A%E5%92%8C%E6%80%A7%E8%83%BD%EF%BC%8C58%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%AE%9E%E8%B7%B5/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>讲师｜赵健博</p>
<p>编辑｜尚剑</p>
<p>大家好！我是赵健博，来自58赶集，今天给大家分享一下58大数据这块的经验。我先做个自我介绍，我本科和研究生分别是在北京邮电大学和中国科学院计算技术研究所先后毕业的，之前在百度和360工作，现在是58赶集高级架构师、58大数据平台负责人。我有多年的分布式系统（存储、计算）的实践和研发经验，在我工作的这些年中运营了大大小小的集群，最大单集群也达到了四五千台，在这个过程中做了大量的功能研发、系统优化，当然也淌了大量的坑，今天会给大家介绍一些我认为比较重要的。</p>
<p>接下来我会跟大家分享一下58大数据平台在最近一年半的时间内技术演进的过程。主要内容分为三方面：58大数据平台目前的整体架构是怎么样的；最近一年半的时间内我们面临的问题、挑战以及技术演进过程；以及未来的规划。</p>
<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fdlmey6jh8j20hs0ao765.jpg" alt="img"></p>
<p>首先看一下58大数据平台架构。大的方面来说分为三层：数据基础平台层、数据应用平台层、数据应用层，还有两列监控与报警和平台管理。</p>
<p>数据基础平台层又分为四个子层：</p>
<ul>
<li>接入层，包括了Canal/Sqoop（主要解决数据库数据接入问题）、还有大量的数据采用Flume解决方案；</li>
<li>存储层，典型的系统HDFS（文件存储）、HBase（KV存储）、Kafka（消息缓存）；</li>
<li>再往上就是调度层，这个层次上我们采用了Yarn的统一调度以及Kubernetes的基于容器的管理和调度的技术；</li>
<li>再往上是计算层，包含了典型的所有计算模型的计算引擎，包含了MR、HIVE、Storm、Spark、Kylin以及深度学习平台比如Caffe、Tensorflow等等。</li>
</ul>
<p>数据应用平台主要包括以下功能：</p>
<ul>
<li>元信息管理，还有针对所有计算引擎、计算引擎job的作业管理，之后就是交互分析、多维分析以及数据可视化的功能。</li>
<li>再往上是支撑58集团的数据业务，比如说流量统计、用户行为分析、用户画像、搜索、广告等等。</li>
<li>针对业务、数据、服务、硬件要有完备的检测与报警体系。</li>
<li>平台管理方面，需要对流程、权限、配额、升级、版本、机器要有很全面的管理平台。</li>
</ul>
<p>这个就是目前58大数据平台的整体架构图。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdlmey8dbvj20hs09zjrv.jpg" alt="img"></p>
<p>这个图展示的是架构图中所包含的系统数据流动的情况。分为两个部分：</p>
<p><font color="red">首先是实时流，就是黄色箭头标识的这个路径。数据实时采集过来之后首先会进入到Kafka平台，先做缓存。实时计算引擎比如Spark streaming或storm会实时的从Kafka中取出它们想要计算的数据。经过实时的处理之后结果可能会写回到Kafka或者是形成最终的数据存到MySQL或者HBase，提供给业务系统，这是一个实时路径。</font></p>

<p><font color="red">对于离线路径，通过接入层的采集和收集，数据最后会落到HDFS上，然后经过Spark、MR批量计算引擎处理甚至是机器学习引擎的处理。其中大部分的数据要进去数据仓库中，在数据仓库这部分是要经过数据抽取、清洗、过滤、映射、合并汇总，最后聚合建模等等几部分的处理，形成数据仓库的数据。然后通过HIVE、Kylin、SparkSQL这种接口将数据提供给各个业务系统或者我们内部的数据产品，有一部分还会流向MySQL。以上是数据在大数据平台上的流动情况。</font></p>

<p>在数据流之外还有一套管理平台。包括元信息管理（云窗）、作业管理平台（58dp）、权限审批和流程自动化管理平台（NightFury）。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdlmeyoh1oj20hs07qweu.jpg" alt="img"></p>
<p>我们的规模可能不算大，跟BAT比起来有些小，但是也过了一千台，目前有1200台的机器。我们的数据规模目前有27PB，每天增量有50TB。作业规模每天大概有80000个job，核心job（产生公司核心指标的job）有20000个，每天80000个job要处理数据量是2.5PB。</p>
<h2 id="技术平台技术演进与实现"><a href="#技术平台技术演进与实现" class="headerlink" title="技术平台技术演进与实现"></a>技术平台技术演进与实现</h2><p>接下来我会重点介绍一下在最近一年半时间内我们大数据平台的技术演进过程，共分四个部分：稳定性、平台治理、性能以及异构计算。第一个部分关于稳定性的改进，稳定性是最基础的工作，我们做了比较多的工作。第二个部分是在平台治理方面的内容。第三个方面我们针对性能也做了一些优化。第四个方面，我们针对异构环境，比如说机器的异构、作业的异构，在这种环境下怎么合理地使用资源。</p>
<h3 id="稳定性改进"><a href="#稳定性改进" class="headerlink" title="稳定性改进"></a>稳定性改进</h3><p>首先看一下稳定性的改进。这块我会举一些例子进行说明。稳定性包含了几个方面，其中第一个方面就是系统的可用性，大家可以采用社区提供的HDFS  HA、Yarn  HA，Storm  HA来解决。另外一个方面是关于扩展性，例如Flume、HDFS，Yarn，Storm的扩展性。这里主要介绍下Flume和HDFS的扩展性相关的一些考虑。此外，有了可用性和扩展性，系统就稳定了吗？实际上不是这样。因为还有很多的突发问题。即使解决了可用性和扩展性，但突发问题还是可能会造成系统不可用，例如由于一些问题造成两台NameNode全部宕机。</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fdlmeysmfqj20hs0a6jrn.jpg" alt="img"></p>
<p>首先看一下Flume的扩展性。我们人为的把它定义了两层。一个是FlumeLocal（主要解决一台机器的日志采集问题，简称Local），一个是FlumeCenter（主要从Local上收集数据，然后把数据写到HDFS上，简称Center），Local和Center之间是有一个HA的考虑的，就是Local需要在配置文件里指定两个Center去写入，一旦一个Center出现问题，数据可以马上从另一个Center流向HDFS。此外，我们还开发了一个高可靠的Agent。业务系统中会把数据产生日志写到磁盘上，Agent保证数据从磁盘上实时可靠的收集给本地的Local，其中我们采用了检查点的技术来解决数据可靠性的问题。</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fdlmez0d2qj20hs0avmxi.jpg" alt="img"></p>
<p>这是Flume的典型架构。Local需要在配置文件里面指定死要连到哪几个Center上。如果说10台，可能还OK，100台也OK，如果一千台呢？如果发现两台Flume Center已经达到机器资源的上限，如何做紧急的扩容呢？所以从这个角度看Flume的扩展性是有问题的。</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fdlmezg1ymj20hs0adwew.jpg" alt="img"></p>
<p>我们的解决方法是在Local和Center中间加了一个ZooKeeper，Local通过ZK动态发现Center，动态的发现下游有什么，就可以达到Center自动扩容的目标了。我们公司Local有两千多台，扩容一台Center仅需一分钟，这种架构实际上可以支持达到万台规模的，这是Flume扩展性的一些改进。</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fdlmezrfdpj20hs0art91.jpg" alt="img"></p>
<p>接下来看一下HDFS扩展性的问题。上面这张图展示了hdfs federation的架构，左侧是一个单namespace架构，即整个目录树在一个namespace中，整个集群的文件数规模受限制于单机内存的限制。federation的思想是把目录树拆分，形成不同的namespace，不同namespace由不同namenode管理，这样就打破了单机资源限制，从而达到了可扩展的目标，如右侧图。</p>
<p>但这个方案有一些隐藏的问题，不知道大家有没有注意到，比如这里每个Datanode都会与所有的NameNode去心跳，如果DataNode数量上万台，那么就可能会出现两个问题：第一，从主节点之间的心跳、块汇报成为瓶颈，第二，如果单个部门的数据规模过大那该怎么办？</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fdlmezrq4dj20hs0afmxl.jpg" alt="img"></p>
<p>针对从主节点之间交互的问题，我们可以进行拆分，控制一个NameNode管理的DateNode的数量，这样就可以避免主从节点交互开销过大的问题。针对单部门数据过大的话可以针对部门内数据进行进一步细拆，就OK了。或者可以考虑百度之前提供的一个方案，即把目录树和inode信息进行抽象，然后分层管理和存储。当然我们目前采用社区federation的方案。如果好好规划的话，也是可以到万台了。</p>
<p>不知道大家有没有在自己运营集群过程中遇到过一些问题，你们是怎么解决的，有些问题可能相当的棘手。突发问题是非常紧急而且重要的，需要在短时间内搞定。接下来我会分享三个例子。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfe5s06j20hs0b5t98.jpg" alt="img"></p>
<p>第一个例子是HDFS的Active NN会不定期异常退出，触发HA切换，这就好像一个不定时炸弹一样。这个图展示了HDFS的HA的架构图，客户端进行变更操作（如创建文件）的话会发出请求给namenode，namenode请求处理完之后会进行持久化工作，会在本地磁盘存一份，同时会在共享存储存一份，共享存储是为了active和standby之间同步状态的，standby会周期从共享存储中拉取更新的数据应用到自己的内存和目录树当中，所有的DataNode都是双汇报的，这样两个namenode都会有最新的块信息。最上面的是两个Checker，是为了仲裁究竟谁是Active的。</p>
<p>还有一个过程，Standby NameNode会定期做checkpoint工作，然后在checkpoint做完之后会回传最新的fsimage给active，最终保存在active的磁盘中，默认情况下在回传过程会造成大量的网络和磁盘的压力，导致active的本地磁盘的Util达到100%，此时用户变更请求延迟就会变高。如果磁盘的Util100%持续时间很长就会导致用户请求超时，甚至Checher的检测请求也因排队过长而超时，最终然后触发Checker仲裁HA切换。</p>
<p>切换的过程中在设计上有很重要一点考虑，不能同时有两个Active，所以要成为新Active NameNode，要把原来的Active NameNode停止掉。先会很友好地停止，什么是友好呢？就是发一个RPC，如果成功了就是友好的，如果失败了，就会ssh过去，把原来active namenode进程kill掉，这就是Active NameNode异常退的原因。</p>
<p>当这个原因了解了之后，其实要解决这个问题也非常简单。</p>
<p>第一点要把editlog与fsimage保存的本地目录分离配置，这种分离是磁盘上的分离，物理分离。</p>
<p>第二是checkpoint之后fsimage回传限速。把editlog与fsimage两个磁盘分离，fsimage回传的io压力不会对客户端请求造成影响，另外，回传限速后，也能限制io压力。这是比较棘手的问题。原因看起来很简单，但是从现象找到原因，这个过程并没有那么容易。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfekc1hj20hs0ad0te.jpg" alt="img"></p>
<p>第二个案例也是一样，Active NN又出现异常退出，产生HA切换。这次和网络连接数有关，这张图是Active NameNode的所在机器的网络连接数，平时都挺正常，20000到30000之间，忽然有一个点一下打到60000多，然后就打平了，最后降下来，降下来的原因很明显，是服务进程退了。</p>
<p>为什么会出现这个情况呢？在后续分析的过程中我们发现了一个线索，在NameNode日志里报了一个空指针的异常。就顺藤摸瓜发现了一个JDK1.7的BUG，参见上面图片所示，在java select库函数调度路径过程中最终会调用这个函数（setUpdateEvents），大家可以看到，如果fd的个数超过了MAX_UPDATE_ARRAY_SIZE（65535）这个数的话，将会走到else路径，这个路径在if进行不等表达式判断时，将会出发空指针异常。</p>
<p>接下来的问题是，为什么会产生这么多的链接呢？经过分析我们发现，在问题出现的时候，存在一次大目录的DU操作，而DU会锁住整个namespace，这样就导致后续的写请求被阻塞，最终导致请求的堆积，请求的堆积导致了连接数大量堆积，连接数堆积到一定程度就触发JDK1.7的这个BUG。这个问题的解决，从两个方面看，首先我们先把JDK升级到1.8。其次，调整参数dfs.content-summary.limit，限制du操作的持锁时间。该参数默认参数是0。我们现在是设成10000了，大家可以参考。这是第二个非常棘手的问题。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdlmff4kp0j20hs0azq3m.jpg" alt="img"></p>
<p>第三个案例关于YARN主节点的，有一天中午，我们收到报警，发现Active RM异常进程退出，触发HA的切换，然而切换后一会新的Active RM节点也会异常退出，这就比较悲剧，我们先进行了恢复。之后我们从当时的日志中发现了原因：一个用户写了一万个文件到分布式缓存里，分布式缓存里数据会同步到ZK上，RM持久化作业状态到ZK时超过Znode单节点最大上限，抛出异常，最终导致ResourceManager进程的异常退出。其实问题的解决方法也非常简单，我们增加了限制逻辑，对于序列化数据量大于Znode节点大小的Job，直接抛异常触发Job的失败。另外我们还适当提升Znode节点大小。</p>
<p>以上是在稳定性方面的一些工作，这三个案例跟大家分享一下，如果有类似的问题建议大家可以尝试一下，这些方案是被我们验证OK的。</p>
<h3 id="平台治理"><a href="#平台治理" class="headerlink" title="平台治理"></a>平台治理</h3><p>接下来介绍一下平台治理这块。包含几个问题，其中第一问题是关于数据的，一方面，就是大家开发了数据之后，经常找不到，要靠喊，比如说在群里喊一下什么数据在哪，谁能告诉我一下，这个效率很低下。另外一方面是之前的管理数据是共享的，不安全，任何人都可以访问其他人的数据。</p>
<p>第二个问题是关于资源，之前是“大锅饭”模式，大家共享计算资源，相互竞争，这样“能吃的“肯定是挤兑”不能吃的“，经常出现核心任务不能按时按点完成，老板看不到数据，这点很可怕。还有是整个集群资源使用情况没有感知，这样根本不知道资源要怎么分配，是否够用。</p>
<p>第三个问题是关于作业的，开发人员开发大量的作业之后，这些作业要怎么管理，实际上他们可能都不知道。还有就是关于作业之间依赖，经常一个指标计算出来要经历多个作业，作业之间依赖是怎么考虑的，单纯靠时间上的依赖是非常脆弱的，如果前期的job延迟产生了，后续的job必然失败。最后一个问题是数据开发人员的效率不高，所需要做的步骤过多。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdlmff22ldj20hs0b3t9c.jpg" alt="img"></p>
<p>针对这四个问题我们做了一些改进，首先是数据与资源治理。数据方面要引入安全策略、元信息管理与基础数仓建设。我们自己开发了一套安全控制策略，主要增加了白名单和权限控制策略。一个HDFS的请求的流程，首先客户端会向NameNode发请求，NameNode接到请求之后首先要做连接解析，读取出请求相关内容做请求处理，再把结果反馈回来，之后客户端向相应的DataNode进行写入数据或者读取数据。从上述流程可以看出，所有HDFS操作全部要经过NameNode这一层。</p>
<p>那么安全策略只要在NameNode的两个点做下控制既可完成：在连接解析后，我们会验证请求方的IP，以及用户是不是在合法配置下面的。如果验证失败，则拒绝请求。如果验证通过，我们会进一步在请求处理过程中验证用户访问的目录和用户在否在合法的配置下。比如说用户A想访问用户B的数据，如果没在允许的情况下会把连接关掉，通过简单的策略调整就能达到灵活的数据的安全控制和数据共享的方式。接下来针对数据找不到的问题，我们开发了全公司层面的基础数据仓库以及针对全公司层面元数据管理平台。</p>
<p>这张图展示了基础数据仓库覆盖度，它覆盖了集团各个公司，又覆盖了多个平台，比如说手机、App端、PC端、微信端等等。数据层次，是数据仓库层、数据集市层还是数据应用层，所属哪个事业群，最后针对数据进行分类标签，比如说帖子数据、用户数据等等都可以通过标签的方式来找到。当想找具体一份数据的时候可以通过这个界面，点一些标签，筛选出一些数据表，甚至在搜索框里面搜数据的关键字。当查到数据表的时候可以在右侧按钮，将显示出表结构，还有表信息，表信息表明了这个表有多少列，这个表的负责人是什么，还有关于数据质量，表的数据量的变化情况等等，如果你想申请可以点击最右边的权限开通。整体开通流程也是自动化的。这是针对数据找不到的问题做的一些改进。</p>
<p>针对资源问题要避免大锅饭，必须要引入账号概念，资源按照账号预留与隔离。我们划分了不同的配额，根据预算、业务需求去申请配额，然后我们调整配额。针对队列这块我们划分多个队列，每个业务线有自己的队列，不同业务线不能跨队列提交任务，每个队列划分出不同资源，资源主要是针对业务线需求而定的。通过这些改进可以达到资源的隔离以及适度的共享。</p>
<p>有了账号的概念之后我们就可以统计每个业务线资源使用情况。我们每天都会有报表。显示了业务线的计算和存储资源的使用情况，甚至是Job的细节情况。</p>
<p>接下来我会介绍一下业务线开发效率低下问题的改进，实际上我们在易用性上也做了很多改进。首先我们开发了云窗平台，它主要解决了元信息查找、数据查询、可是化展示和多维分析这些需求。然后针对任务开发这块我们开发了58DP解决了元信息开发、作业管理与统计等。我们针对实时多维分析开发了飞流，实时作业开发全部配置化、同时支持多种统计算子、自动图表生成等等。还有NightFury，流程自动化管理平台。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfffd06j20hs098dgb.jpg" alt="img"></p>
<p>这是云窗的界面，上面是一个SQL查询界面，下面是可视化产品界面，这是我们数据可视化的一个结果。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fdlmffnbcbj20hs0bq74i.jpg" alt="img"></p>
<p>然后关于任务开发的话，我们用58DP来做任务开发，可以支持的不同任务，涵盖目前的所有主流作业以及作业依赖等管理。这是58DP的页面，可以设置基本信息、调度及依赖等。</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfg7udgj20hs0cet96.jpg" alt="img"></p>
<p>飞流是支持周期性的统计、全天累计性的统计，大家可以定义统计方法、定义任务的一些基本信息，设置维度、设置度量，设置完之后就展现了图形，也提供了跟昨天的对比情况。当在图里点任何一个点的时候，可以看到不同维度组合下在这个点上的数据分布，点击两个点可以看到不同维度下两个点的分布对比。针对历史数据可以进行对比，我们可以把时间拉的更长，可以查看不同周的实时统计结果，而不是一天。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfgfx1dj20hs0cgdgb.jpg" alt="img"></p>
<p>这是NightFury的界面，这就是我们运维的自动化管理平台，大家可以看到有很多个流程和权限的开通申请，表单的填写、工单审批，审批之后的一些流程全部是自动化的。</p>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>性能方面，主要分为四个方面：</p>
<p>MR作业性能、数据收集性能、SQL查询性能和多维分析的性能。针对MR作业性能，我们引用多租户功能，资源预留，核心作业执行有保障。</p>
<p>第二点小文件合并处理，可以提升任务执行效率，减少调度本身的开销。</p>
<p>第三点我们针对Shuffle阶段参数优化，可以实现并发度提升，IO消耗降低。</p>
<p>经过三个方面的改进之后，我们整体任务的运行时间实际上有一倍左右的提升。数据传输优化方面，我们经过消息合并改进数据传输性能，提升了20倍。在SQL优化方面我们引用内存执行引擎与列存储方案的结合，在同等资源情况下针对线上一百多条SQL进行测试，总体性能大概提升80%。在多维计算这块，我们引入Kylin，针对多维的查询95%以上查询能控制在2s以内。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfgr3zaj20hs0dawfa.jpg" alt="img"></p>
<h3 id="异构计算"><a href="#异构计算" class="headerlink" title="异构计算"></a>异构计算</h3><p>异构计算方面我们面临了两个主要问题，一个是作业的异构，我们有多种类型的作业，比如说实时作业强调低时延，而离线作业强调高吞吐，这本身就是矛盾的，怎么解决这个矛盾。第二方面是机器异构，CPU、内存、网络、磁盘配置不同，这种异构环境又要怎么办。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfsgkbwj20hs0cswfe.jpg" alt="img"></p>
<p>从上面图中可以看出：如果实时作业的task和批处理作业的task被调度到一台机器上了，如果批处理作业把资源占满了（例如网络带宽），则实时作业的task必将收到影响。所以，需要对实时作业和批处理作业做隔离才行。</p>
<p>做资源隔离，我们的思路是采用标签化，给每个NodeManager赋予不同标签，表示不同机器被分配了不同标签；资源队列也赋予不同标签，然后在RM调度时，保证相同标签的队列里容器资源必从相同标签的NodeManager上分配的。这样就可以通过标签的不同达到物理上的资源隔离目标。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfsuruej20hs0a10t0.jpg" alt="img"></p>
<p>这张图是实现图。首先可以看到NodeManager分成了两个集合，一个是实时的，一个是离线的，不同的队列也被赋予了实时或离线的标签，当用户提交一个job的时候它可以指定一个队列，提交到离线队列里就是离线任务，ResourceManager就会把这个作业所需要的资源分配到离线标签的NodeManager上，这样就可以做到物理资源隔离。</p>
<h2 id="未来规划"><a href="#未来规划" class="headerlink" title="未来规划"></a>未来规划</h2><p>以上主要是介绍了我们最近一年半做的一些工作。接下来我会介绍一下未来的规划。首先就是深度学习。这个概念今年非常火爆，甚至是要爆炸了，深度学习在58这块需求也是蛮强烈的。目前深度学习工具有这么多，caffe、theano、torch等等非常多，怎么做整合，怎么降低使用成本，这是第一个问题。第二个问题，机器是有限的，怎么高效利用资源，需要把机器分配模式变成资源分配模式。还有光有单机的机器学习或者深度学习工具还不够，因为性能太差，所以我们需要将深度学习训练分布式化。我们做了一个初步的测试，针对caffe与Tensorflow工具的分布式化训练做了比较，4卡相对于单卡模型训练性能提升100%~170%，所以分布式化的工作本身意义也是非常大的。</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fdlmftc0xlj20hs0a0q3h.jpg" alt="img"></p>
<p>这个图展示的是工具融合方案。我们这里利用的是Kubernetes，支持主流的深度学习工具，每个工具做成镜像形成POD，用户需要的话可以直接把POD分发给他，用户在训练的时候从HDFS上直接拉取样本，并且把训练的参数回写到HDFS上，也就是说通过HDFS做数据的共享，通过这种模式可以很轻松地支持多种深度学习工具，也可以达到按所需资源量进行资源的分配目标。</p>
<p>另外我们会做一个深度学习工具分布式的改造，是针对caffe，我们用的是CaffeOnSpark，即把整个分布式的方案做成模板供用户使用。首先启动多个POD，通过POD启动一个Spark集群，然后再提一个Spark job来做训练，最后在整个训练结束之后再把集群停掉。Tensorflow也是一样的，首先启动tensorflow集群，然后提交任务，任务训练完以后再把集群停掉。其他工具分布式化我们也会采取类似的思路解决。以上是关于深度学习这块我们目前的一些工作。</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fdlmfth4z7j20hs0amjrx.jpg" alt="img"></p>
<p>其次，是关于空间资源利用率的。目前我们有一千多台机器，存储是很大的成本。之前也提到了，我们是属于花钱的部门，所以压力非常大。那怎么节省成本是一个很重要的问题。除了传统压缩之外，还能做什么？HDFS RAID是一个比较好的解决方案。HDFS RAID采用是RC编码，类似RAID6，比如一个文件有m个块，根据m个块生成k个校验块，然后能保证k个块丢失的情况下数据还能找回来，举个例子来说，比如文件2.5G大小，256M一个块，可以分成10个块，根据RC算法再生成4个校验块，可以保证丢了4个块情况下，数据都能找回来。在这个例子中，3副本情况下，一共需要30个块，而采用HDFS RAID，仅需要14个块。但他们的可靠性一样，空间占用情况却差了57%。</p>
<p>具体实施时，第一步对集群数据进行冷热分析，RAID毕竟有些性能问题，一旦数据有问题，你要通过计算才能恢复，势必会造成性能低下，所以针对冷数据做肯定是风险最低的。第二步就是压缩+archive+RAID，通过三方面技术结合把文件数和空间全部节省出来。归档实际上是会变换目录的，为了做适配，我们通过软连接功能，做到对用户透明。最后在数据读取时，如果是RAID数据，就要具备实时RAID修复功能才能保证在数据缺失的情况下不影响数据的访问。</p>
<p>后续我们会对计算资源利用率再做进一步提升。另外也会考虑Storm和YARN扩展性。还有Kubernetes调度优化，比如针对GPU资源管理功能。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是我今天想介绍的全部内容。在结束之前请允许我再做一下总结。</p>
<p>首先我介绍了58目前的大数据平台架构是怎么样的，简单来说就是“342”，三个层次、细分为四个子层、旁边两列。所以大家要做大数据平台建设工作，这几个方面是必备的。</p>
<p>第二个方面我重点的介绍了58在一年半的时间内的技术改进。第一点是关于稳定性，主要从Flume和HDFS扩展性方面重点介绍了我们的解决方案，举了三个案例来说明突发问题，不是说有了可用性和扩展性就万事OK了，还要解决突发问题。针对平台治理首先介绍了一下数据和资源的治理方法，接着又介绍了关于易用性方面的改进，我们提供了一系列平台来提高开发人员的开发效率。</p>
<p>第三方面从性能上介绍了我们这边做的优化工作以及优化的结果是怎么样的；</p>
<p>第四方面介绍了在异构环境下如何支持不同特征的作业进行合理调度。</p>
<p>最后我介绍了58深度学习平台建设方面以及存储资源空间利用率优化方面的内容。以上就是我今天的全部内容，希望对大家有帮助。</p>
<h5 id="作者介绍"><a href="#作者介绍" class="headerlink" title="作者介绍"></a>作者介绍</h5><p>赵健博，58集团高级架构师，技术委员会委员。大数据领域专家，2009年毕业于中国科学院计算所，先后就职于百度、奇虎360、58集团，主要研究领域包括分布式计算与存储系统等。58集团大数据平台负责人，负责大数据平台在集团的研发，应用与发展。</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop集群动态添加删除节点]]></title>
      <url>https://stanxia.github.io/2017/03/12/hadoop%E9%9B%86%E7%BE%A4%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="动态添加节点"><a href="#动态添加节点" class="headerlink" title="动态添加节点"></a>动态添加节点</h2><h3 id="准备工作："><a href="#准备工作：" class="headerlink" title="准备工作："></a>准备工作：</h3><ol>
<li><p>准备新节点的操作系统，安装好需要的软件</p>
</li>
<li><p>将hadoop的配置文件scp到新的节点上(复制hadoop目录的时候在新节点上清理下hadoop目录下的日志文件或者数据文件)</p>
</li>
<li><p>实现ssh无密码登录（ssh-copy-id命令实现，可以免去cp *.pub文件后的权限修改）</p>
</li>
<li><p>修改系统hostname（通过hostname和/etc/sysconfig/network进行修改）</p>
</li>
<li><p>修改hosts文件，将集群所有节点hosts配置进去（集群所有节点保持hosts文件统一）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi /etc/hosts <span class="comment">#追加新添加的节点</span></div></pre></td></tr></table></figure>
</li>
<li><p>修改主节点slave文件，添加新增节点的ip信息（集群重启时使用）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi <span class="variable">$HADOOP_HOME</span>/etc/hadoop/slaves <span class="comment">#追加新添加的节点</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="添加DataNode"><a href="#添加DataNode" class="headerlink" title="添加DataNode"></a>添加DataNode</h3><ol>
<li><p>在新增的节点上，运行sbin/hadoop-daemon.sh start datanode即可</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$HADOOP_HOME</span>/sbin/hadoop-daemon.sh start datanode</div></pre></td></tr></table></figure>
</li>
<li><p>刷新</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfsadmin -refreshNodes</div></pre></td></tr></table></figure>
</li>
<li><p>然后在namenode通过hdfs dfsadmin -report查看集群情况</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfsadmin -report</div></pre></td></tr></table></figure>
</li>
<li><p>最后还需要对hdfs负载设置均衡，因为默认的数据传输带宽比较低，可以设置为64M，即hdfs dfsadmin -setBalancerBandwidth 67108864即可</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfsadmin -setBalancerBandwidth 67108864 <span class="comment">#设置带宽为 64M/S</span></div></pre></td></tr></table></figure>
</li>
<li><p>默认balancer的threshold为10%，即各个节点与集群总的存储使用率相差不超过10%，我们可将其设置为5%</p>
</li>
<li><p>然后启动Balancer，sbin/start-balancer.sh -threshold 5，等待集群自均衡完成即可</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$HADOOP_HOME</span>/sbin/start-balancer.sh -threshold 5</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="添加NodeManager"><a href="#添加NodeManager" class="headerlink" title="添加NodeManager"></a>添加NodeManager</h3><ol>
<li><p>在新增节点，运行sbin/yarn-daemon.sh start nodemanager即可</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$HADOOP_HOME</span>/sbin/yarn-daemon.sh start nodemanager</div></pre></td></tr></table></figure>
</li>
<li><p>刷新</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -refreshNodes</div></pre></td></tr></table></figure>
</li>
<li><p>在ResourceManager，通过yarn node -list查看集群情况</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn node -list</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>随时时间推移，各个datanode上的块分布来越来越不均衡，这将降低MR的本地性，导致部分datanode相对更加繁忙。<br>balancer是一个hadoop守护进程，它将块从忙碌的datanode移动相对空闲的datanode，同时坚持块复本放置策略，将复本分散到不同的机器、机架。<br>balancer会促使每个datanode的使用率与整个集群的使用率接近，这个“接近”是通过-threashold参数指定的，默认是10%。（本案例改为5%）<br>不同节点之间复制数据的带宽是受限的，默认是1MB/s，可以通过hdfs-site.xml文件中的dfs.balance.bandwithPerSec属性指定（单位是字节）。（本案例改为64MB/S)</p>
<p><font color="red"><em>建议定期执行均衡器，如每天或者每周。</em></font></p>

<h2 id="动态删除节点"><a href="#动态删除节点" class="headerlink" title="动态删除节点"></a>动态删除节点</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li><p>修改Master节点的hdfs-site.xml，增加dfs.hosts.exclude(排除,文本文件)参数</p>
</li>
<li><p>修改Master节点的yarn-site.xml，增加yarn.resourcemanager.nodes.exclude-path参数</p>
</li>
<li><p>修改Master节点的mapred-site.xml，增加mapreduce.jobtracker.hosts.exclude.filename</p>
</li>
<li><p>新建excludes文件，添加需删除的主机名</p>
</li>
<li><p>修改Master节点slaves文件，删除该节点，复制因子等..</p>
</li>
<li><p>刷新:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin  -refreshNodes</div><div class="line">hdfs dfsadmin -refreshNodes</div></pre></td></tr></table></figure>
</li>
<li><p>查看状态</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfsadmin -report</div></pre></td></tr></table></figure>
<p>​</p>
</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[几种常见的加密方式]]></title>
      <url>https://stanxia.github.io/2017/03/08/%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E5%8A%A0%E5%AF%86%E6%96%B9%E5%BC%8F/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="数据加密-Data-encryption"><a href="#数据加密-Data-encryption" class="headerlink" title="数据加密(Data encryption)"></a>数据加密(Data encryption)</h2><p>数据加密，是一门历史悠久的技术，指通过<a href="http://baike.baidu.com/view/155969.htm" target="_blank" rel="external">加密算法</a>和加密<a href="http://baike.baidu.com/view/934.htm" target="_blank" rel="external">密钥</a>将明文转变为密文，而解密则是通过解密算法和解密密钥将密文恢复为明文。它的核心是密码学。</p>
<p>数据加密目前仍是<a href="http://baike.baidu.com/view/1130583.htm" target="_blank" rel="external">计算机系统</a>对信息进行保护的一种最可靠的办法。它利用<a href="http://baike.baidu.com/view/391036.htm" target="_blank" rel="external">密码技术</a>对信息进行加密，实现<a href="http://baike.baidu.com/view/431307.htm" target="_blank" rel="external">信息隐蔽</a>，从而起到保护信息的安全的作用。 </p>
<h2 id="Base64加密方式-可逆"><a href="#Base64加密方式-可逆" class="headerlink" title="Base64加密方式(可逆)"></a>Base64加密方式(可逆)</h2><h4 id="什么是Base64"><a href="#什么是Base64" class="headerlink" title="什么是Base64"></a><strong>什么是Base64</strong></h4><p>Base64编码可以成为密码学的基石。可以将任意的二进制数据进行Base64编码。所有的数据都能被编码为并只用65个字符就能表示的文本文件。（ 65字符：A~Z a~z 0~9 + / = ）等号“=”用来作为后缀用途。编码后的数据~=编码前数据的4/3，会大1/3左右。</p>
<h4 id="在bash中使用Base64"><a href="#在bash中使用Base64" class="headerlink" title="在bash中使用Base64:"></a><strong>在bash中使用Base64:</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">base64 需要加密的文件 -o 加密后的文件 <span class="comment">#加密过程</span></div><div class="line">base64 加密后的文件 -o 解密后的文件 -D <span class="comment">#解密过程</span></div></pre></td></tr></table></figure>
<h4 id="Base64编码原理"><a href="#Base64编码原理" class="headerlink" title="Base64编码原理"></a><strong>Base64编码原理</strong></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">a.将所有字符转化为ASCII码； </div><div class="line"></div><div class="line">b.将ASCII码转化为8位二进制； </div><div class="line"></div><div class="line">c.将二进制3个归成一组(不足3个在后边补0)共24位，再拆分成4组，每组6位； </div><div class="line"></div><div class="line">d.统一在6位二进制前补两个0凑足8位； </div><div class="line"></div><div class="line">e.将补0后的二进制转为十进制； </div><div class="line"></div><div class="line">f.从Base64编码表获取十进制对应的Base64编码；</div></pre></td></tr></table></figure>
<h4 id="Base64编码的说明"><a href="#Base64编码的说明" class="headerlink" title="Base64编码的说明"></a><strong>Base64编码的说明</strong></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">a.转换的时候，将三个byte的数据，先后放入一个24bit的缓冲区中，先来的byte占高位。 </div><div class="line"></div><div class="line">b.数据不足3byte的话，于缓冲区中剩下的bit用0补足。然后，每次取出6个bit，按照其值选择查表选择对应的字符作为编码后的输出。 </div><div class="line"></div><div class="line">c.不断进行，直到全部输入数据转换完成。 </div><div class="line"></div><div class="line">d.如果最后剩下两个输入数据，在编码结果后加1个“=”； </div><div class="line"></div><div class="line">e.如果最后剩下一个输入数据，编码结果后加2个“=”； </div><div class="line"></div><div class="line">f.如果没有剩下任何数据，就什么都不要加，这样才可以保证资料还原的正确性。</div></pre></td></tr></table></figure>
<h2 id="散列函数加密（不可逆）"><a href="#散列函数加密（不可逆）" class="headerlink" title="散列函数加密（不可逆）"></a>散列函数加密（不可逆）</h2><h4 id="散列函数："><a href="#散列函数：" class="headerlink" title="散列函数："></a>散列函数：</h4><p><strong>散列函数</strong>（或<strong>散列算法</strong>，又称<strong>哈希函数</strong>，英语：Hash Function）是一种从任何一种数据中创建小的数字“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该<a href="https://zh.wikipedia.org/wiki/%E5%87%BD%E6%95%B0" target="_blank" rel="external">函数</a>将数据打乱混合，重新创建一个叫做<strong>散列值</strong>（hash values，hash codes，hash sums，或hashes）的指纹。散列值通常用一个短的随机字母和数字组成的字符串来代表。好的散列函数在输入域中很少出现<a href="https://zh.wikipedia.org/w/index.php?title=%E6%95%A3%E5%88%97%E5%86%B2%E7%AA%81&amp;action=edit&amp;redlink=1" target="_blank" rel="external">散列冲突</a>。在<a href="https://zh.wikipedia.org/wiki/%E6%95%A3%E5%88%97%E8%A1%A8" target="_blank" rel="external">散列表</a>和<a href="https://zh.wikipedia.org/w/index.php?title=%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86&amp;action=edit&amp;redlink=1" target="_blank" rel="external">数据处理</a>中，不抑制冲突来区别数据，会使得<a href="https://zh.wikipedia.org/w/index.php?title=%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%B0%E5%BD%95&amp;action=edit&amp;redlink=1" target="_blank" rel="external">数据库记录</a>更难找到。</p>
<h4 id="单向散列函数："><a href="#单向散列函数：" class="headerlink" title="单向散列函数："></a>单向散列函数：</h4><p>如果两个散列值是不相同的（根据同一函数），那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有<a href="https://zh.wikipedia.org/wiki/%E7%A1%AE%E5%AE%9A%E6%80%A7" target="_blank" rel="external">确定性</a>的结果，具有这种性质的散列函数称为单向散列函数。</p>
<h4 id="哈希碰撞："><a href="#哈希碰撞：" class="headerlink" title="哈希碰撞："></a>哈希碰撞：</h4><p>另一方面，散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“哈希碰撞”，这通常是两个不同长度的输入值，刻意计算出相同的输出值。</p>
<h4 id="密码散列函数："><a href="#密码散列函数：" class="headerlink" title="密码散列函数："></a>密码散列函数：</h4><p><strong>密码散列函数</strong>（英语：Cryptographic hash function），又译为<strong>加密散列函数</strong>、<strong>密码散列函数</strong>、<strong>加密散列函数</strong>，是<a href="https://zh.wikipedia.org/wiki/%E6%95%A3%E5%88%97%E5%87%BD%E6%95%B8" target="_blank" rel="external">散列函数</a>的一种。它被认为是一种<a href="https://zh.wikipedia.org/wiki/%E5%96%AE%E5%90%91%E5%87%BD%E6%95%B8" target="_blank" rel="external">单向函数</a>，也就是说极其难以由散列函数输出的结果，回推输入的数据是什么。这样的单向函数被称为“现代密码学的驮马”。<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A2%BC%E9%9B%9C%E6%B9%8A%E5%87%BD%E6%95%B8#cite_note-1" target="_blank" rel="external">[1]</a>这种散列函数的输入数据，通常被称为<strong>消息</strong>（message），而它的输出结果，经常被称为<strong>消息摘要</strong>（message digest）或<strong>摘要</strong>（digest）。</p>
<p>一个理想的密码散列函数应该有四个主要的特性：</p>
<ul>
<li>对于任何一个给定的消息，它都很容易就能运算出散列数值</li>
<li><a href="https://zh.wikipedia.org/wiki/%E8%A8%88%E7%AE%97%E8%A4%87%E9%9B%9C%E6%80%A7%E7%90%86%E8%AB%96" target="_blank" rel="external">难以</a>由一个已知的散列数值，去推算出原始的消息</li>
<li>在不更动散列数值的前提下，修改消息内容是不可行的</li>
<li>对于两个不同的消息，它不能给与相同的散列数值</li>
</ul>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fdfvfa72vwj20hs0cwq4m.jpg" alt=""></p>
<p>一个工作中的密码散列函数 (特定的, <a href="https://zh.wikipedia.org/wiki/SHA-1" target="_blank" rel="external">SHA-1</a>)。注意，源输入再微小的变化（“over”这个词）也会使所产生的输出发生急剧变化，通过所谓的<a href="https://zh.wikipedia.org/wiki/%E9%9B%AA%E5%B4%A9%E6%95%88%E5%BA%94_(%E5%AF%86%E7%A0%81%E5%AD%A6" target="_blank" rel="external">雪崩效应</a>)的原理。</p>
<h3 id="碰撞（计算机科学）"><a href="#碰撞（计算机科学）" class="headerlink" title="碰撞（计算机科学）"></a>碰撞（计算机科学）</h3><p>在计算机科学中，碰撞或冲突是指两个不同的元素具有相同的<a href="https://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E5%80%BC" target="_blank" rel="external">哈希值</a>，<a href="https://zh.wikipedia.org/wiki/%E6%A0%A1%E9%AA%8C%E5%92%8C" target="_blank" rel="external">校验和</a>，数字指纹时发生的情况。当数据量足够多（例如将所有可能的人名和计算机文件名映射到一段字符上）时，碰撞是不可避免的。这仅仅是<a href="https://zh.wikipedia.org/wiki/%E9%B4%BF%E5%B7%A2%E5%8E%9F%E7%90%86" target="_blank" rel="external">鸽巢原理</a>的一个实例。</p>
<h3 id="消息认证码"><a href="#消息认证码" class="headerlink" title="消息认证码"></a>消息认证码</h3><p>在<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A2%BC%E5%AD%B8" target="_blank" rel="external">密码学</a>中，<strong>消息认证码</strong>（英语：Message authentication code，缩写为MAC），又译为<strong>消息鉴别码</strong>、<strong>文件消息认证码</strong>、<strong>讯息鉴别码</strong>、<strong>信息认证码</strong>，是经过特定算法后产生的一小段信息，检查某段消息的<a href="https://zh.wikipedia.org/wiki/%E5%AE%8C%E6%95%B4%E6%80%A7" target="_blank" rel="external">完整性</a>，以及作<a href="https://zh.wikipedia.org/wiki/%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81" target="_blank" rel="external">身份验证</a>。它可以用来检查在消息传递过程中，其内容是否被更改过，不管更改的原因是来自意外或是蓄意攻击。同时可以作为消息来源的<a href="https://zh.wikipedia.org/wiki/%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81" target="_blank" rel="external">身份验证</a>，确认消息的来源。</p>
<p>消息认证码的算法中，通常会使用<a href="https://zh.wikipedia.org/wiki/%E9%87%91%E9%91%B0%E9%9B%9C%E6%B9%8A%E8%A8%8A%E6%81%AF%E9%91%91%E5%88%A5%E7%A2%BC" target="_blank" rel="external">带密钥的散列函数（HMAC）</a>，或者块密码的带认证工作模式（如CBC-MAC）。</p>
<p>信息鉴别码不能提供对信息的保密，若要同时实现保密认证，同时需要对信息进行加密。</p>
<h3 id="彩虹表"><a href="#彩虹表" class="headerlink" title="彩虹表"></a>彩虹表</h3><p><strong>彩虹表</strong>是一个用于<a href="https://zh.wikipedia.org/wiki/%E5%8A%A0%E5%AF%86%E6%95%A3%E5%88%97%E5%87%BD%E6%95%B0" target="_blank" rel="external">加密散列函数</a>逆运算的<a href="https://zh.wikipedia.org/w/index.php?title=%E9%A2%84%E5%85%88%E8%AE%A1%E7%AE%97&amp;action=edit&amp;redlink=1" target="_blank" rel="external">预先计算</a>好的<a href="https://zh.wikipedia.org/wiki/%E6%9F%A5%E6%89%BE%E8%A1%A8" target="_blank" rel="external">表</a>，常用于破解加密过的密码散列。 查找表常常用于包含有限字符固定长度<a href="https://zh.wikipedia.org/w/index.php?title=%E7%BA%AF%E6%96%87%E6%9C%AC&amp;action=edit&amp;redlink=1" target="_blank" rel="external">纯文本</a><a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A0%81" target="_blank" rel="external">密码</a>的加密。这是<a href="https://zh.wikipedia.org/wiki/%E4%BB%A5%E7%A9%BA%E9%96%93%E6%8F%9B%E6%99%82%E9%96%93" target="_blank" rel="external">以空间换时间</a>的典型实践，在每一次尝试都计算的暴力破解中使用更少的计算能力和更多的储存空间，但却比简单的每个输入一条散列的翻查表使用更少的储存空间和更多的计算性能。使用<a href="https://zh.wikipedia.org/wiki/%E7%9B%90_(%E5%AF%86%E7%A0%81%E5%AD%A6" target="_blank" rel="external">加盐</a>)的<a href="https://zh.wikipedia.org/w/index.php?title=KDF%E5%87%BD%E6%95%B0&amp;action=edit&amp;redlink=1" target="_blank" rel="external">KDF函数</a>可以使这种攻击难以实现。</p>
<h3 id="暴力破解法"><a href="#暴力破解法" class="headerlink" title="暴力破解法"></a>暴力破解法</h3><h4 id="1-暴力破解法"><a href="#1-暴力破解法" class="headerlink" title="1. 暴力破解法"></a>1. 暴力破解法</h4><p><strong>暴力破解法</strong>，或称为<strong>穷举法</strong>，是一种<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A0%81%E5%88%86%E6%9E%90" target="_blank" rel="external">密码分析</a>的方法，即将密码进行逐个推算直到找出真正的密码为止。例如一个已知是四位并且全部由<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%97" target="_blank" rel="external">数字</a>组成的密码，其可能共有10000种组合，因此最多尝试9999次就能找到正确的密码。理论上除了具有<a href="https://zh.wikipedia.org/wiki/%E5%AE%8C%E5%96%84%E4%BF%9D%E5%AF%86%E6%80%A7" target="_blank" rel="external">完善保密性</a>的密码以外，利用这种方法可以破解任何一种密码，问题只在于如何缩短试误时间。有些人运用<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA" target="_blank" rel="external">计算机</a>来增加效率，有些人辅以<a href="https://zh.wikipedia.org/wiki/%E5%AD%97%E5%85%B8" target="_blank" rel="external">字典</a>来缩小密码组合的范围。</p>
<h4 id="2-防护手段"><a href="#2-防护手段" class="headerlink" title="2. 防护手段"></a>2. 防护手段</h4><p>最重要的手段是在构建系统时要将系统设计目标定为即便受到暴力破解的攻击也难以被攻破。以下列举了一些常用的防护手段：</p>
<ul>
<li>增加密码的长度与复杂度</li>
<li>在系统中限制密码试错的次数</li>
<li>密码验证时，将验证结果不是立即返回而是延时若干秒后返回。</li>
<li>限制允许发起请求的客户端的范围</li>
<li>禁止密码输入频率过高的请求</li>
<li>将密码设置为类似<a href="https://zh.wikipedia.org/wiki/%E5%AE%89%E5%85%A8%E4%BB%A4%E7%89%8C" target="_blank" rel="external">安全令牌</a>那样每隔一定时间就发生变化的形式</li>
<li>当同一来源的密码输入出错次数超过一定阈值，立即通过邮件/短信等方式通知系统管理员</li>
<li>人为监视系统，确认有无异常的密码试错。</li>
</ul>
<h3 id="MD5加密-32位散列值"><a href="#MD5加密-32位散列值" class="headerlink" title="MD5加密(32位散列值)"></a><font color="red">MD5加密(32位散列值)</font></h3><h4 id="MD5："><a href="#MD5：" class="headerlink" title="MD5："></a>MD5：</h4><p><strong>MD5消息摘要算法</strong>（英语：MD5 Message-Digest Algorithm），一种被广泛使用的<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A2%BC%E9%9B%9C%E6%B9%8A%E5%87%BD%E6%95%B8" target="_blank" rel="external">密码散列函数</a>，可以产生出一个128位（16<a href="https://zh.wikipedia.org/wiki/%E5%AD%97%E8%8A%82" target="_blank" rel="external">字节</a>）的散列值（hash value），用于确保信息传输完整一致。MD5由<a href="https://zh.wikipedia.org/wiki/%E7%BD%97%E7%BA%B3%E5%BE%B7%C2%B7%E6%9D%8E%E7%BB%B4%E6%96%AF%E7%89%B9" target="_blank" rel="external">罗纳德·李维斯特</a>设计，于1992年公开，用以替换<a href="https://zh.wikipedia.org/wiki/MD4" target="_blank" rel="external">MD4</a>算法。这套算法的程序在 <a href="https://tools.ietf.org/html/rfc1321" target="_blank" rel="external">RFC 1321</a> 中被加以规范。</p>
<p>1996年后被证实存在弱点，可以被加以破解，对于需要高度安全性的数据，专家一般建议改用其他算法，如<a href="https://zh.wikipedia.org/wiki/SHA-1" target="_blank" rel="external">SHA-1</a>。2004年，证实MD5算法无法防止碰撞，因此无法适用于安全性认证，如<a href="https://zh.wikipedia.org/wiki/SSL" target="_blank" rel="external">SSL</a><a href="https://zh.wikipedia.org/wiki/%E5%85%AC%E9%96%8B%E9%87%91%E9%91%B0%E8%AA%8D%E8%AD%89" target="_blank" rel="external">公开密钥认证</a>或是<a href="https://zh.wikipedia.org/wiki/%E6%95%B8%E4%BD%8D%E7%B0%BD%E7%AB%A0" target="_blank" rel="external">数字签名</a>等用途。</p>
<h4 id="应用："><a href="#应用：" class="headerlink" title="应用："></a>应用：</h4><p>MD5已经广泛使用在为文件传输提供一定的可靠性方面。例如，服务器预先提供一个MD5校验和，用户下载完文件以后，用MD5算法计算下载文件的MD5校验和，然后通过检查这两个校验和是否一致，就能判断下载的文件是否出错。如在一些<a href="https://zh.wikipedia.org/wiki/BitTorrent" target="_blank" rel="external">BitTorrent</a>下载中，软件将通过计算MD5检验下载到的文件片段的完整性。</p>
<p>MD5亦有应用于部分网上赌场以保证赌博的公平性，原理是系统先在玩家下注前已生成该局的结果，将该结果的字符串配合一组随机字符串利用MD5 加密，将该加密字符串于玩家下注前便显示给玩家，再在结果开出后将未加密的字符串显示给玩家，玩家便可利用MD5工具加密验证该字符串是否吻合。</p>
<p>例子: 在玩家下注骰宝前，赌场便先决定该局结果，假设生成的随机结果为4、5、 6大，赌场便会先利用MD5 加密“4, 5, 6”此字符串并于玩家下注前告诉玩家；由于赌场是无法预计玩家会下什么注，所以便能确保赌场不能作弊；当玩家下注完毕后，赌场便告诉玩家该原始字符串，即“4, 5, 6”，玩家便可利用MD5工具加密该字符串是否与下注前的加密字符串吻合。</p>
<p>该字符串一般会加上一组随机字符串 (Random string)，以防止玩家利用碰撞 (Collision) 解密字符串，但如使用超级电脑利用碰撞亦有可能从加上随机字符串的加密字符串中获取游戏结果。随机字符串的长度与碰撞的次数成正比关系，一般网上赌场使用的随机字符串是长于20字，有些网上赌场的随机字符串更长达500字，以增加解密难度。</p>
<h4 id="算法："><a href="#算法：" class="headerlink" title="算法："></a>算法：</h4><p>MD5是输入不定长度信息，输出固定长度128-bits的算法。经过程序流程，生成四个32位数据，最后联合起来成为一个128-bits<a href="https://zh.wikipedia.org/wiki/%E6%95%A3%E5%88%97" target="_blank" rel="external">散列</a>。基本方式为，求余、取余、调整长度、与链接变量进行循环运算。得出结果。</p>
<h4 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h4><ol>
<li>压缩性：任意长度的数据，算出的MD5值长度都是固定的(32位)。</li>
<li>容易计算：从原数据计算出MD5值很容易。</li>
<li>抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。</li>
<li>强抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的（但也会被碰撞）。</li>
</ol>
<h4 id="bash中使用MD5"><a href="#bash中使用MD5" class="headerlink" title="bash中使用MD5"></a>bash中使用MD5</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">md5 <span class="_">-s</span> <span class="string">"需要md5加密的字符串"</span> <span class="comment">#md5加密字符串</span></div><div class="line">md5 文件 <span class="comment">#md5加密文件</span></div></pre></td></tr></table></figure>
<h4 id="缺陷："><a href="#缺陷：" class="headerlink" title="缺陷："></a>缺陷：</h4><p>2009年<a href="https://zh.wikipedia.org/wiki/%E8%AC%9D%E6%BF%A4" target="_blank" rel="external">谢涛</a>和冯登国仅用了220.96的碰撞算法复杂度，破解了MD5的<a href="https://zh.wikipedia.org/w/index.php?title=%E7%A2%B0%E6%92%9E%E6%8A%B5%E6%8A%97&amp;action=edit&amp;redlink=1" target="_blank" rel="external">碰撞抵抗</a>，该攻击在普通计算机上运行只需要数秒钟。</p>
<h3 id="盐-密码学"><a href="#盐-密码学" class="headerlink" title="盐(密码学)"></a><font color="red">盐(密码学)</font></h3><h4 id="加盐："><a href="#加盐：" class="headerlink" title="加盐："></a>加盐：</h4><p><strong>盐</strong>（Salt），在<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A0%81%E5%AD%A6" target="_blank" rel="external">密码学</a>中，是指通过在密码任意固定位置插入特定的字符串，让散列后的结果和使用原始密码的散列结果不相符，这种过程称之为“加盐”。</p>
<h4 id="为什么加盐："><a href="#为什么加盐：" class="headerlink" title="为什么加盐："></a>为什么加盐：</h4><p>通常情况下，当字段经过散列处理（如<a href="https://zh.wikipedia.org/wiki/MD5" target="_blank" rel="external">MD5</a>），会生成一段散列值，而散列后的值一般是无法通过特定算法得到原始字段的。但是某些情况，比如一个大型的<a href="https://zh.wikipedia.org/wiki/%E5%BD%A9%E8%99%B9%E8%A1%A8" target="_blank" rel="external">彩虹表</a>，通过在表中搜索该MD5值，很有可能在极短的时间内找到该散列值对应的真实字段内容。</p>
<p>加盐后的散列值，可以极大的降低由于用户数据被盗而带来的密码泄漏风险，即使通过彩虹表寻找到了散列后的数值所对应的原始内容，但是由于经过了加盐，插入的字符串扰乱了真正的密码，使得获得真实密码的概率大大降低。</p>
<h4 id="实现原理："><a href="#实现原理：" class="headerlink" title="实现原理："></a>实现原理：</h4><p>加盐的实现过程通常是在需要散列的字段的特定位置增加特定的字符，打乱原始的字符串，使其生成的散列结果产生变化。比如，用户使用了一个密码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x7faqgjw</div></pre></td></tr></table></figure>
<p>经过MD5散列后，可以得出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">455e0e5c2bc109deae749e7ce0cdd397</div></pre></td></tr></table></figure>
<p>但是由于用户密码位数不足，短密码的散列结果很容易被<a href="https://zh.wikipedia.org/wiki/%E5%BD%A9%E8%99%B9%E8%A1%A8" target="_blank" rel="external">彩虹表</a>破解，因此，在用户的密码末尾添加特定字符串（括号内的字体为加盐的字段）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x7faqgjw(abcdefghijklmnopqrstuvwxyz)</div></pre></td></tr></table></figure>
<p>因此，加盐后的密码位数更长了，散列的结果也发生了变化：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">4a1690d5eb6c126ef68606dda68c2f79</div></pre></td></tr></table></figure>
<p>以上就是加盐过程的简单描述，在实际使用过程中，还需要通过特定位数插入、倒序或多种方法对原始密码进行固定的加盐处理，使得散列的结果更加不容易被破解或轻易得到原始密码，比如（括号内的字体为加盐字符串）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x7(a)fa(b)qg(c)jw</div></pre></td></tr></table></figure>
<h3 id="十六进制"><a href="#十六进制" class="headerlink" title="十六进制"></a>十六进制</h3><p><strong>十六进制</strong>（简写为<em>hex</em>或下标16）在<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%A6" target="_blank" rel="external">数学</a>中是一种逢16进1的<a href="https://zh.wikipedia.org/wiki/%E8%BF%9B%E4%BD%8D%E5%88%B6" target="_blank" rel="external">进位制</a>。一般用数字0到9和字母A到F（或a~f）表示，其中:A~F表示10~15，这些称作<strong>十六进制数字</strong>。</p>
<h3 id="SHA-1（40位散列值）"><a href="#SHA-1（40位散列值）" class="headerlink" title="SHA-1（40位散列值）"></a><font color="red">SHA-1（40位散列值）</font></h3><p><strong>SHA-1</strong>（英语：Secure Hash Algorithm 1，中文名：安全散列算法1）是一种<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A0%81%E6%95%A3%E5%88%97%E5%87%BD%E6%95%B0" target="_blank" rel="external">密码散列函数</a>，<a href="https://zh.wikipedia.org/wiki/%E7%BE%8E%E5%9B%BD%E5%9B%BD%E5%AE%B6%E5%AE%89%E5%85%A8%E5%B1%80" target="_blank" rel="external">美国国家安全局</a>设计，并由美国<a href="https://zh.wikipedia.org/wiki/%E5%9C%8B%E5%AE%B6%E6%A8%99%E6%BA%96%E6%8A%80%E8%A1%93%E7%A0%94%E7%A9%B6%E6%89%80" target="_blank" rel="external">国家标准技术研究所</a>（NIST）发布为<a href="https://zh.wikipedia.org/wiki/%E8%81%AF%E9%82%A6%E8%B3%87%E6%96%99%E8%99%95%E7%90%86%E6%A8%99%E6%BA%96" target="_blank" rel="external">联邦数据处理标准</a>（FIPS）<a href="https://zh.wikipedia.org/wiki/SHA-1#cite_note-:0-2" target="_blank" rel="external">[2]</a>。SHA-1可以生成一个被称为消息摘要的160<a href="https://zh.wikipedia.org/wiki/%E4%BD%8D" target="_blank" rel="external">位</a>（20<a href="https://zh.wikipedia.org/wiki/%E5%AD%97%E8%8A%82" target="_blank" rel="external">字节</a>）散列值，散列值通常的呈现形式为40个<a href="https://zh.wikipedia.org/wiki/%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6" target="_blank" rel="external">十六进制</a>数。(现已经被破解，可碰撞)</p>
<h3 id="SHA-2"><a href="#SHA-2" class="headerlink" title="SHA-2"></a><font color="red">SHA-2</font></h3><h4 id="特点：-1"><a href="#特点：-1" class="headerlink" title="特点："></a>特点：</h4><ol>
<li>安全，目前为止没有被成功碰撞</li>
<li>快速</li>
</ol>
<h4 id="应用：-1"><a href="#应用：-1" class="headerlink" title="应用："></a>应用：</h4><p>SHA-2 + 盐值 共同用于密码的保存。</p>
<h4 id="java实现："><a href="#java实现：" class="headerlink" title="java实现："></a>java实现：</h4><p>通过<font color="red">org.apache.commons.codec.digest.DigestUtils</font>类实现。直接调用静态加密方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.commons.codec.digest.DigestUtils; <span class="comment">//导入包</span></div><div class="line">String md5=DigestUtils.md5Hex(<span class="string">"需要加密的数据"</span>); <span class="comment">//md5加密（32位散列值）</span></div><div class="line">String sha256=DigestUtils.sha256Hex(<span class="string">"需要加密的数据"</span>); <span class="comment">//sha256加密（64位）</span></div><div class="line">String sha384=DigestUtils.sha384Hex(<span class="string">"需要加密的数据"</span>); <span class="comment">//sha384加密（96位）</span></div><div class="line">String sha512=DigestUtils.sha512Hex(<span class="string">"需要加密的数据"</span>); <span class="comment">//sha512加密（128位）</span></div></pre></td></tr></table></figure>
<h2 id="钥匙串加密方式"><a href="#钥匙串加密方式" class="headerlink" title="钥匙串加密方式"></a>钥匙串加密方式</h2><p>iCloud钥匙串,苹果给我们提供的密码保存的解决方案,iOS7之后有的</p>
<p>存沙盒：</p>
<p>1、如果手机越狱，密码容易被窃取。</p>
<p>2、当软件更新时，沙盒里的内容是不被删除的。但是，如果将软件卸载后重装，沙盒里的数据就没有了。</p>
<p>3、每个APP的沙盒是相对独立的，密码无法共用。</p>
<p>存钥匙串里：</p>
<p>1、苹果提供的安全方案，rsa加密，相对安全。</p>
<p>2、无论软件更新或删除，密码都存在，都可以自动登录。</p>
<p>3、同一公司的APP密码是可以共用的。</p>
<h2 id="对称加密算法（可逆）"><a href="#对称加密算法（可逆）" class="headerlink" title="对称加密算法（可逆）"></a>对称加密算法（可逆）</h2><p>优点：算法公开、计算量小、加密速度快、加密效率高、可逆</p>
<p>缺点：双方使用相同钥匙，安全性得不到保证</p>
<p>现状：对称加密的速度比公钥加密快很多，在很多场合都需要对称加密，</p>
<p>算法: 在对称加密算法中常用的算法有：<a href="http://baike.baidu.com/view/7510.htm" target="_blank" rel="external">DES</a>、<a href="http://baike.baidu.com/view/350958.htm" target="_blank" rel="external">3DES</a>、TDEA、<a href="http://baike.baidu.com/view/2208941.htm" target="_blank" rel="external">Blowfish</a>、RC2、RC4、<a href="http://baike.baidu.com/view/734720.htm" target="_blank" rel="external">RC5</a>、<a href="http://baike.baidu.com/view/92629.htm" target="_blank" rel="external">IDEA</a>、SKIPJACK、AES等。不同算法的实现机制不同，可参考对应算法的详细资料</p>
<p>相较于DES和3DES算法而言，AES算法有着更高的速度和资源使用效率，安全级别也较之更高了，被称为下一代加密标准</p>
<p>nECB ：电子代码本，就是说每个块都是独立加密的</p>
<p>nCBC ：密码块链，使用一个密钥和一个初始化向量 (IV)对数据执行加密转换</p>
<p>ECB和CBC区别：CBC更加复杂更加安全，里面加入了8位的向量（8个0的话结果等于ECB）。在明文里面改一个字母，ECB密文对应的那一行会改变，CBC密文从那一行往后都会改变。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3ly1fdfu3mtjaxj212i0fuaeb.jpg" alt=""></p>
<h3 id="DES-Data-Encryption-Standard-对称加密算法"><a href="#DES-Data-Encryption-Standard-对称加密算法" class="headerlink" title="DES(Data Encryption Standard) 对称加密算法"></a><font color="red">DES(Data Encryption Standard) 对称加密算法</font></h3><h4 id="DES算法的入口参数有三个：Key、Data、Mode。"><a href="#DES算法的入口参数有三个：Key、Data、Mode。" class="headerlink" title="DES算法的入口参数有三个：Key、Data、Mode。"></a>DES算法的入口参数有三个：<strong>Key、Data、Mode</strong>。</h4><ol>
<li>Key为8个字节共64位，是DES算法的工作密钥；</li>
<li>Data也为8个字节64位，是要被加密或被解密的数据；</li>
<li>Mode为DES的工作方式，有两种：加密或解密。</li>
</ol>
<h4 id="应用：-2"><a href="#应用：-2" class="headerlink" title="应用："></a>应用：</h4><p>为了网络上信息传输的安全（防止第三方窃取信息看到明文），发送发和接收方分别进行加密和解密，这样信息在<font color="red">网络上传输(比如银行卡号)</font>的时候就是相对安全的。</p>
<h4 id="java实现DES"><a href="#java实现DES" class="headerlink" title="java实现DES:"></a>java实现DES:</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.xerces.impl.dv.util.Base64;</div><div class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</div><div class="line"><span class="keyword">import</span> java.security.SecureRandom;</div><div class="line"><span class="keyword">import</span> javax.crypto.SecretKey;</div><div class="line"><span class="keyword">import</span> javax.crypto.Cipher;</div><div class="line"><span class="keyword">import</span> javax.crypto.spec.SecretKeySpec;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * DES加密介绍 DES是一种对称加密算法，所谓对称加密算法即：加密和解密使用相同密钥的算法。DES加密算法出自IBM的研究，</div><div class="line"> * 后来被美国政府正式采用，之后开始广泛流传，但是近些年使用越来越少，因为DES使用56位密钥，以现代计算能力，</div><div class="line"> * 24小时内即可被破解。虽然如此，在某些简单应用中，我们还是可以使用DES加密算法，本文简单讲解DES的JAVA实现 。</div><div class="line"> * 注意：DES加密和解密过程中，密钥长度都必须是8</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DES</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ALGORITHM=<span class="string">"DES"</span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception, NoSuchAlgorithmException </span>&#123;</div><div class="line">        <span class="comment">// data 待加密内容</span></div><div class="line">        String str = <span class="string">"3456789567890"</span>;</div><div class="line">        <span class="comment">// key 密匙，DES的密钥长度只能是8字节</span></div><div class="line">        String password = <span class="string">"12345678"</span>;</div><div class="line">        <span class="comment">// DES算法要求有一个可信任的随机数源</span></div><div class="line">        SecureRandom random = <span class="keyword">new</span> SecureRandom();</div><div class="line">        SecretKey securekey = <span class="keyword">new</span> SecretKeySpec(password.getBytes(), ALGORITHM);</div><div class="line">        <span class="comment">// Cipher对象实际完成加密操作</span></div><div class="line">        Cipher cipher = Cipher.getInstance(ALGORITHM);</div><div class="line">        <span class="comment">// 用密匙初始化Cipher对象</span></div><div class="line">        cipher.init(Cipher.ENCRYPT_MODE, securekey, random);</div><div class="line">        <span class="comment">// 现在，获取数据并加密</span></div><div class="line">        <span class="comment">// 正式执行加密操作</span></div><div class="line">        <span class="keyword">byte</span>[] result = cipher.doFinal(str.getBytes());</div><div class="line">        <span class="comment">//转换为String传输</span></div><div class="line">        String text = Base64.encode(result);</div><div class="line">        System.out.println(<span class="string">"暗文："</span> + text);</div><div class="line">        <span class="comment">//解密</span></div><div class="line">        cipher.init(Cipher.DECRYPT_MODE, securekey, random);</div><div class="line">        <span class="keyword">byte</span>[] de = cipher.doFinal(Base64.decode(text));</div><div class="line">        System.out.println(<span class="string">"明文"</span> + <span class="keyword">new</span> String(de));</div><div class="line"></div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h3 id="AES-Advanced-Encryption-Standard"><a href="#AES-Advanced-Encryption-Standard" class="headerlink" title="AES(Advanced Encryption Standard)"></a><font color="red">AES(Advanced Encryption Standard)</font></h3><h4 id="介绍："><a href="#介绍：" class="headerlink" title="介绍："></a>介绍：</h4><p>这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。</p>
<p>AES的区块长度固定为128比特，密钥长度则可以是128，192或256比特，对应的也就是16字节、24字节、32字节。</p>
<h4 id="特点：-2"><a href="#特点：-2" class="headerlink" title="特点："></a>特点：</h4><p>相对安全，推荐使用AES替代DES.</p>
<h4 id="java实现AES"><a href="#java实现AES" class="headerlink" title="java实现AES:"></a>java实现AES:</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.xerces.impl.dv.util.Base64;</div><div class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</div><div class="line"><span class="keyword">import</span> java.security.SecureRandom;</div><div class="line"><span class="keyword">import</span> javax.crypto.SecretKey;</div><div class="line"><span class="keyword">import</span> javax.crypto.Cipher;</div><div class="line"><span class="keyword">import</span> javax.crypto.spec.SecretKeySpec;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> *  这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。</div><div class="line"> *  AES的区块长度固定为128比特，密钥长度则可以是128，192或256比特，对应的也就是16字节、24字节、32字节。</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AES</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ALGORITHM=<span class="string">"AES"</span>;</div><div class="line">    <span class="comment">// 测试</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception, NoSuchAlgorithmException </span>&#123;</div><div class="line">        <span class="comment">// data 待加密内容</span></div><div class="line">        String str = <span class="string">"3456789567890"</span>;</div><div class="line">        <span class="comment">// key 密匙，AES的密钥长度只能是16字节、24字节、32字节</span></div><div class="line">        String password = <span class="string">"1234567891111111"</span>;</div><div class="line"></div><div class="line">        <span class="comment">// AES算法要求有一个可信任的随机数源</span></div><div class="line">        SecureRandom random = <span class="keyword">new</span> SecureRandom();</div><div class="line">        SecretKey securekey = <span class="keyword">new</span> SecretKeySpec(password.getBytes(), ALGORITHM);</div><div class="line">        <span class="comment">// Cipher对象实际完成加密操作</span></div><div class="line">        Cipher cipher = Cipher.getInstance(ALGORITHM);</div><div class="line">        <span class="comment">// 用密匙初始化Cipher对象</span></div><div class="line">        cipher.init(Cipher.ENCRYPT_MODE, securekey, random);</div><div class="line">        <span class="comment">// 现在，获取数据并加密</span></div><div class="line">        <span class="comment">// 正式执行加密操作</span></div><div class="line">        <span class="keyword">byte</span>[] result = cipher.doFinal(str.getBytes());</div><div class="line">        <span class="comment">//转换为String传输</span></div><div class="line">        String text = Base64.encode(result);</div><div class="line">        System.out.println(<span class="string">"暗文："</span> + text);</div><div class="line">        <span class="comment">//解密</span></div><div class="line">        cipher.init(Cipher.DECRYPT_MODE, securekey, random);</div><div class="line">        <span class="keyword">byte</span>[] de = cipher.doFinal(Base64.decode(text));</div><div class="line">        System.out.println(<span class="string">"明文"</span> + <span class="keyword">new</span> String(de));</div><div class="line"></div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h2 id="非对称加密算法-Secruty-framework系统库-（可逆）"><a href="#非对称加密算法-Secruty-framework系统库-（可逆）" class="headerlink" title="非对称加密算法(Secruty.framework系统库)（可逆）"></a>非对称加密算法(Secruty.framework系统库)（可逆）</h2><p>非对称加密算法需要两个密钥：公开密钥（publickey）和私有密钥（privatekey）</p>
<p>非对称加密中使用的主要算法有：<a href="http://baike.baidu.com/view/7520.htm" target="_blank" rel="external">RSA</a>、<a href="http://baike.baidu.com/view/2154827.htm" target="_blank" rel="external">Elgamal</a>、背包算法、Rabin、D-H、<a href="http://baike.baidu.com/view/46554.htm" target="_blank" rel="external">ECC</a>（椭圆曲线加密算法）等。</p>
<p>公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密</p>
<p>特点：</p>
<p>非对称密码体制的特点：算法强度复杂、安全性依赖于算法与密钥但是由于其算法复杂，而使得加密解密速度没有对称加密解密的速度快</p>
<p>对称密码体制中只有一种密钥，并且是非公开的，如果要解密就得让对方知道密钥。所以保证其安全性就是保证密钥的安全，而非对称密钥体制有两种密钥，其中一个是公开的，这样就可以不需要像对称密码那样传输对方的密钥了</p>
<p>但是RSA加密算法效率较差，对大型数据加密时间很长，一般用于小数据。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3ly1fdfu3n2tsgj214g0f8gqi.jpg" alt=""></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Alibaba代码规范]]></title>
      <url>https://stanxia.github.io/2017/03/07/Alibaba%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h1 id=""><a href="#" class="headerlink" title=""></a><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnlrez7aj20m10v6wid.jpg" alt="1"></h1><p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnlrozi5j20m10v60xm.jpg" alt="2"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnlrxvhzj20m10v6dmk.jpg" alt="3"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnls4woqj20m10v6wjg.jpg" alt="4"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnlsevkgj20m10v6n3c.jpg" alt="5"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnlso65nj20m10v6af9.jpg" alt="6"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnlt2v04j20m10v6wji.jpg" alt="7"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnlteijwj20m10v6jv6.jpg" alt="8"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3ly1fddnltobz1j20m10v6jxd.jpg" alt="9"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3ly1fddnmp0dsgj20m10v6n31.jpg" alt="10"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnmpcafoj20m10v60wt.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnmpkfj4j20m10v6act.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnmpsz1gj20m10v67a9.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnmq29kaj20m10v6jvc.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnmqc2z2j20m10v6tei.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnmquwirj20m10v6dme.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnmr8hefj20m10v6gr3.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnmrgurmj20m10v60xo.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnn3j1roj20m10v6grf.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnn3tks7j20m10v60zs.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnn424u1j20m10v6wgi.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnn4gxacj20m10v6gra.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnn51icgj20m10v6gsi.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnn5ccrej20m10v6jx5.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnn5o68dj20m10v6grd.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnn5wzwdj20m10v641o.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnn6fm1wj20m10v6n3f.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnnicr5kj20m10v6tbr.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnnjg99vj20m10v6q94.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnnkcow3j20m10v67av.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3ly1fddnnkzpc6j20m10v679k.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnnllrwnj20m10v6wl6.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnnm019vj20m10v6dkg.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3ly1fddnnm9rsrj20m10v6djm.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnnml164j20m10v6tdv.jpg" alt=""></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3ly1fddnnmulirj20m10v6jvt.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3ly1fddnnxpv60j20m10v6q7b.jpg" alt=""></p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop手动合并小文件]]></title>
      <url>https://stanxia.github.io/2017/03/06/hadoop%E6%89%8B%E5%8A%A8%E5%90%88%E5%B9%B6%E5%B0%8F%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>下载主要jar包：<a href="https://pan.baidu.com/s/1eSqWp9o" target="_blank" rel="external">filecrush-2.0-SNAPSHOT.jar</a>密码: x9mh</p>
<h2 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Hadoop jar filecrush-2.0-SNAPSHOT.jar crush.Crush \</div><div class="line"></div><div class="line">-Ddfs.block.size=134217728 \</div><div class="line"></div><div class="line">--input-format=text  \</div><div class="line"></div><div class="line">--output-format=text \</div><div class="line"></div><div class="line">--compress=none \</div><div class="line"></div><div class="line">/要合并的目录 /合并到哪里去 时间戳(20170221175612)</div></pre></td></tr></table></figure>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark Streaming 报错:kafka.cluster.BrokerEndPoint cannot be cast to kafka.cluster.Broker']]></title>
      <url>https://stanxia.github.io/2017/03/02/Spark-Streaming-%E6%8A%A5%E9%94%99-kafka-cluster-BrokerEndPoint-cannot-be-cast-to-kafka-cluster-Broker/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>Spark Streaming 连接kafka报错：kafka.cluster.BrokerEndPoint cannot be cast to kafka.cluster.Broker</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>Spark Streaming默认使用的是Kafka 0.8.2.1，将kafka的版本改为0.8.2.1</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[spark stream无法收取到kafka生产者的消息]]></title>
      <url>https://stanxia.github.io/2017/03/02/spark-stream-and/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>spark stream无法收取到kafka发过来的消息</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>找到集群中 kafka的server.properties，修改如下：</p>
<p><code>vi server.properties</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">listeners=PLAINTEXT://slave2xls:9092    #改为本主机的ip：port</div><div class="line">port=9092</div></pre></td></tr></table></figure>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fd8jhc2u2dj21fi09ct9t.jpg" alt="1"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JVM理解]]></title>
      <url>https://stanxia.github.io/2017/03/01/JVM%E7%90%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="什么是jvm"><a href="#什么是jvm" class="headerlink" title="什么是jvm"></a>什么是jvm</h2><p>jvm（java virtual machine）,java虚拟机，就是在计算机的内存中再虚拟出个计算机。<br>为什么java一次编译，随处运行？<br>都归功于jvm的命令集，jvm翻译之后，根据不同的cpu，翻译成不同的机器语言。</p>
<h2 id="jvm的组成部分"><a href="#jvm的组成部分" class="headerlink" title="jvm的组成部分"></a>jvm的组成部分</h2><ol>
<li><h5 id="Class-Loader-类加载器"><a href="#Class-Loader-类加载器" class="headerlink" title="Class Loader 类加载器"></a>Class Loader 类加载器</h5><p>将javac 编译后的 .class文件加载到内存中。（注意：并不会加载所有的.class文件，而是只加载符合class规范的文件。可阅读<jvm specification="">中的第四章”The Class File Format”）</jvm></p>
</li>
<li><h5 id="Execution-Engine-执行引擎"><a href="#Execution-Engine-执行引擎" class="headerlink" title="Execution Engine 执行引擎"></a>Execution Engine 执行引擎</h5><p>也叫做解释器(Interpreter)，负责解释命令，提交操作系统执行。</p>
</li>
<li><h5 id="Native-Interface-本地接口"><a href="#Native-Interface-本地接口" class="headerlink" title="Native Interface 本地接口"></a>Native Interface 本地接口</h5><p>本地接口的作用是融合不同的语言为java所用。</p>
</li>
<li><h5 id="Runtime-Data-Area-运行数据区"><a href="#Runtime-Data-Area-运行数据区" class="headerlink" title="Runtime Data Area 运行数据区"></a>Runtime Data Area 运行数据区</h5><p>所有程序被加载到运行数据区域才能运行。</p>
</li>
</ol>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fd7kltd18vj20ye0leq7j.jpg" alt="1"></p>
<h2 id="jvm-的内存管理"><a href="#jvm-的内存管理" class="headerlink" title="jvm 的内存管理"></a>jvm 的内存管理</h2><p>所有的程序都是被加载到运行数据区域才能执行。<br>运行数据区主要包括：</p>
<ol>
<li><h5 id="Stack-栈"><a href="#Stack-栈" class="headerlink" title="Stack 栈"></a>Stack 栈</h5><p>栈也叫做栈内存，与线程同生死。线程创建时创建，线程结束时自动释放栈内存，不需要GC。<br>栈的原则：先进后出。<br>栈中存放的数据格式：栈帧(Stack Frame)<br>栈帧：方法和运行期数据的数据集<br>栈帧包括：<br>a. 本地变量(local variables)，包括输入，输出参数以及方法内的变量<br>b. 栈操作(Operand Stack)，记录进出栈的操作<br>c. 栈帧数据(Frame Data),包括类文件，方法等</p>
<p>​</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fd7kltq5vcj20f90oi0u1.jpg" alt="2"></p>
<p>java 栈结构图 </p>
<p>图示：栈中有两个栈帧，栈帧2是最先被调用的方法，先入栈。方法2又调用方法1，栈帧1入栈，且位于栈顶，栈帧2位于栈底。执行完成后，先弹出栈帧1，再弹出栈帧2.线程结束，释放栈。</p>
</li>
<li><h5 id="Heap-堆内存"><a href="#Heap-堆内存" class="headerlink" title="Heap 堆内存"></a>Heap 堆内存</h5><p>一个jvm只有一个堆内存，大小可调节。类加载器加载了类文件后，需要把类，方法，常变量放到堆内存中，以方便解释器执行。<br>堆内存结构：<br>a. Permanent Space永久存储区<br>永久存储区是一个常驻内存区域。用于存放jdk自身所携带的Class,Interface的元数据，即存储的是运行环境所必须的类信息，该区域中的数据不会被GC回收，只有关闭jvm才会释放该区域所占内存。<br>b. Young Genaration Space 新生区<br>新生区是类的诞生，成长，消亡的区域。一个类在这里产生，应用，最后被GC收回。<br>新生区分为两个区：伊甸区(Eden Space)和幸存者区(Survivor space)。所有类都在伊甸区被new出来的。<br>幸存区有两个：0区(Survivor 0 space)和1区(Survivor 1 space)。<br>当伊甸区的空间用完时，程序有需要new新的类，这是GC将对伊甸区进行回收，将伊甸区中不再被引用的对象进行销毁，然后将伊甸区中剩余的对象移动到幸存0区。若幸存0区也满了，在对该区域进行垃圾回收，然后将剩余的移动到1区。如果1区也满了，再移动到养老区。<br>c. Tenure Generation Space 养老区<br>养老区用于保存被新生区筛选出来的对象。一般池对象都保存在这个区。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fd7klu48owj20ci09mgo7.jpg" alt="3"></p>
</li>
<li><h5 id="Method-Area-方法区"><a href="#Method-Area-方法区" class="headerlink" title="Method Area 方法区"></a>Method Area 方法区</h5><p>方法区是被所有线程共享，该区域保存所有字段和方法字节码，以及一些特殊方法如 构造函数，接口代码也在此定义。</p>
</li>
<li><h5 id="Program-Counter-Register-程序计数器"><a href="#Program-Counter-Register-程序计数器" class="headerlink" title="Program Counter Register 程序计数器"></a>Program Counter Register 程序计数器</h5><p>每个线程都有一个程序计数器，就是一个指针，指向方法区中的方法字节码，由执行引擎读取下一条指令。</p>
</li>
<li><h5 id="Native-Method-Stack-本地方法栈"><a href="#Native-Method-Stack-本地方法栈" class="headerlink" title="Native Method Stack 本地方法栈"></a>Native Method Stack 本地方法栈</h5></li>
</ol>
<h2 id="JVM相关问题"><a href="#JVM相关问题" class="headerlink" title="JVM相关问题"></a>JVM相关问题</h2><h5 id="堆和栈的区别？"><a href="#堆和栈的区别？" class="headerlink" title="堆和栈的区别？"></a>堆和栈的区别？</h5><ol>
<li>堆中存放对象，对象内的临时变量存放在栈中。</li>
<li>栈随线程同生死，堆随 jvm同生死。</li>
</ol>
<h5 id="堆内存存放什么？"><a href="#堆内存存放什么？" class="headerlink" title="堆内存存放什么？"></a>堆内存存放什么？</h5><p>对象，包括对象变量以及对象方法。</p>
<h5 id="类变量和实例变量的区别？"><a href="#类变量和实例变量的区别？" class="headerlink" title="类变量和实例变量的区别？"></a>类变量和实例变量的区别？</h5><ol>
<li><p>静态变量是类变量，非静态变量是实例变量。</p>
</li>
<li><p>静态变量存放在方法区中，实例变量存放在堆内存中。</p>
</li>
</ol>
<h5 id="为什么产生OutOfMemory"><a href="#为什么产生OutOfMemory" class="headerlink" title="为什么产生OutOfMemory?"></a>为什么产生OutOfMemory?</h5><p>Heap堆内存中没有足够的内存可用。新申请的内存大于堆中的空闲内存。</p>
<h5 id="产生的对象不多，为什么也会出现OutOfMemory"><a href="#产生的对象不多，为什么也会出现OutOfMemory" class="headerlink" title="产生的对象不多，为什么也会出现OutOfMemory?"></a>产生的对象不多，为什么也会出现OutOfMemory?</h5><p>继承的层次太多，Heap堆内存中产生对象是先产生父类，然后才产生子类。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[IDE关闭Spark执行日志]]></title>
      <url>https://stanxia.github.io/2017/02/28/IDE%E5%85%B3%E9%97%ADSpark%E6%89%A7%E8%A1%8C%E6%97%A5%E5%BF%97/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>用IDE执行spark任务会出现很多的日志信息，当我们不需要看这些日志信息的时候该怎么整，如何优雅的搞掉这些日志，看看下面的，或许对你有帮助。</p>
<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>添加以下代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"></div><div class="line"><span class="comment">//设置spark的日志级别为 warn，才会打印日志</span></div><div class="line"> <span class="type">Logger</span>.getLogger(<span class="string">"org.apache.spark"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line"><span class="comment">//直接关闭 jetty日志  </span></div><div class="line"> <span class="type">Logger</span>.getLogger(<span class="string">"org.eclipse.jetty.server"</span>).setLevel(<span class="type">Level</span>.<span class="type">OFF</span>)</div><div class="line"><span class="comment">//直接关闭 spark的运行日志</span></div><div class="line"> <span class="type">SparkContext</span>().setLogLevel(<span class="string">"OFF"</span>)</div></pre></td></tr></table></figure>
<p> Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark 包冲突error class javax.servlet.FilterRegistration]]></title>
      <url>https://stanxia.github.io/2017/02/27/Spark-%E5%8C%85%E5%86%B2%E7%AA%81error-class-javax-servlet-FilterRegistration/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在idea上运行spark程序时，出现以下信息：</p>
<p>Spark error class “javax.servlet.FilterRegistration”‘s signer information does not match signer information of other classes in the same package</p>
<p>如图：</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fd5a3imie6j21kw09oq96.jpg" alt="1"></p>
<p>看了一圈网上的答案，应该是包冲突，试过了各种方法，终于找到了一种看似很莫名其妙的答案，但却是非常有效。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>右键模块项目==&gt;Open Module Settings ==&gt; 选择Dependencies==&gt;找到javax.servlet:servlet-api:xx==&gt;移动到列表的最末端，如下图：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fd5amqp9jcj21ak0hu425.jpg" alt="2"></p>
<p>Apply==&gt;Ok==&gt;运行试试！</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这个问题的解决方案很奇怪，以后明白了再回来说明下。</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[spark集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/27/spark%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="前置环境"><a href="#前置环境" class="headerlink" title="前置环境"></a>前置环境</h2><ol>
<li><p>需要jdk</p>
</li>
<li><p>需要hadoop</p>
</li>
<li><p>下载spark</p>
<p><a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">点我下载spark</a></p>
</li>
</ol>
<h2 id="安装spark"><a href="#安装spark" class="headerlink" title="安装spark"></a>安装spark</h2><ol>
<li><p>安装spark</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf spark-1.6.0-bin-hadoop2.6.tgz -C /opt/ <span class="comment">#解压到/opt/</span></div><div class="line">mv spark-1.6.0-bin-hadoop2.6 spark <span class="comment">#重命名</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量</p>
<p><code>vi /etc/profile #配置环境变量</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> SPARK_HOME=/opt/spark</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</div></pre></td></tr></table></figure>
</li>
</ol>
<p>​      <code>source /etc/profile</code>  配置生效。</p>
<ol>
<li><p>配置spark-env.sh</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">cp spark-env.sh.template spark-env.sh </div><div class="line">vi spark-env.sh <span class="comment">#修改spark-env.sh</span></div><div class="line"><span class="comment">#添加如下配置：</span></div><div class="line"><span class="built_in">export</span> JAVA_HOME=/opt/jdk1.8/</div><div class="line"><span class="built_in">export</span> SCALA_HOME=/opt/scala</div><div class="line"><span class="built_in">export</span> SPARK_MASTER_IP=master</div><div class="line"><span class="built_in">export</span> SPARK_WORKER_MEMORY=4G <span class="comment">#worker内存 可随意设置</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置slaves文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /opt/spark/conf/ </div><div class="line">cp slaves.template slaves</div><div class="line">vi slaves</div><div class="line"><span class="comment">#修改slaves,添加集群中的worker节点</span></div><div class="line">slave1</div><div class="line">slave2</div></pre></td></tr></table></figure>
</li>
<li><p>复制spark文件夹到集群中的所有节点</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scp -r /opt/spark hadoop@slave1:/opt/ <span class="comment">#复制到其他节点</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置所有节点上的spark环境变量</p>
</li>
</ol>
<h2 id="启动运行"><a href="#启动运行" class="headerlink" title="启动运行"></a>启动运行</h2><ol>
<li><p>在启动spark之前，<strong>先开启hadoop服务</strong></p>
</li>
<li><p>启动脚本都放在${SPARK_HOME}/sbin/下面</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/opt/spark/sbin/start-all.sh <span class="comment">#开启spark服务</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><ol>
<li><p>进入spark操作界面</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">spark-shell</div></pre></td></tr></table></figure>
</li>
<li><p>跑一个spark自带任务看看</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$SPARK_HOME</span>/bin/run-example SparkPi</div></pre></td></tr></table></figure>
</li>
<li><p>检查页面：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip:8080</div><div class="line">ip:4040 <span class="comment">#需要进入到spark环境才会有这个页面</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[ IntelliJ IDEA 破解之道（尽量还是支持正版。。）]]></title>
      <url>https://stanxia.github.io/2017/02/27/IntelliJ-IDEA-%E7%A0%B4%E8%A7%A3%E4%B9%8B%E9%81%93%EF%BC%88%E5%B0%BD%E9%87%8F%E8%BF%98%E6%98%AF%E6%94%AF%E6%8C%81%E6%AD%A3%E7%89%88%E3%80%82%E3%80%82%EF%BC%89/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="话说"><a href="#话说" class="headerlink" title="话说"></a>话说</h2><p>IntelliJ IDEA这东西做的确实不错，但是对于一般人来说可能是有点不舍得花钱的，有钱还是建议买正版，这里也给出一些皮姐的方式。。。：</p>
<ol>
<li>适用于 <strong>IntelliJ IDEA (v2016.3.4)</strong></li>
<li>开始安装</li>
<li>选择<strong>License server</strong></li>
<li>将这个网址添加进去： <strong><a href="http://jetbrains.tech" target="_blank" rel="external">http://jetbrains.tech</a></strong> </li>
<li>确认</li>
<li>试试行不行</li>
<li><strong>如果是IntelliJ IDEA v15.0.2 </strong></li>
<li>使用<strong><a href="http://idea.lanyus.com" target="_blank" rel="external">http://idea.lanyus.com</a></strong>，如果不行，可换为<strong><a href="http://nfsgkyi.nrqw46lvomxgg33n.dresk.ru" target="_blank" rel="external">http://nfsgkyi.nrqw46lvomxgg33n.dresk.ru</a></strong></li>
</ol>
<p> <a href="https://www.haxotron.com/jetbrains-intellij-idea-crack-123/" target="_blank" rel="external">一手资料消息来源</a></p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop运行job时卡住在INFO mapreduce.Job: Running job:job _1456252725626_0001]]></title>
      <url>https://stanxia.github.io/2017/02/25/hadoop%E8%BF%90%E8%A1%8Cjob%E6%97%B6%E5%8D%A1%E4%BD%8F%E5%9C%A8INFO-mapreduce-Job-Running-job-job-1456252725626-0001/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题详情："><a href="#问题详情：" class="headerlink" title="问题详情："></a>问题详情：</h2><p>在运行hadoop MapReduce任务时，一直卡在INFO mapreduce.Job: Running job:job <em> 1456252725626 </em> 0001的位置。</p>
<h2 id="问题原因："><a href="#问题原因：" class="headerlink" title="问题原因："></a>问题原因：</h2><h5 id="遇到了问题，首先从哪里找？"><a href="#遇到了问题，首先从哪里找？" class="headerlink" title="遇到了问题，首先从哪里找？"></a>遇到了问题，首先从哪里找？</h5><p>当发现问题的时候，首先去查看相应的日志，查找问题产生的原因，对症下药。</p>
<p>在hadoop2.6以及以上版本中，mapreduce任务都是交给yarn资源管理器 管理的，所以首先去 查看 <strong>yarn-hadoop-nodemanager-slave01.log</strong> 日志。</p>
<p>终端输入：</p>
<p><code>cat hadoop所在目录/logs/yarn-hadoop-nodemanager-slave01.log</code></p>
<p>如果显示如下信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)</div></pre></td></tr></table></figure>
<p>字面上的意思每次尝试连接0.0.0.0/0.0.0.0:8031失败，google 百度一下 找到如下办法（<u>不能保证百分百有效果，但也是值得一试的</u>）</p>
<h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><p>从问题可以推断出，可能是 配置文件有问题，打开文件 hadoop文件目录/etc/hadoop/yarn-site.xml查看详细配置；</p>
<p>终端中输入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi hadoop目录/etc/hadoop/yarn-site.xml</div></pre></td></tr></table></figure>
<p> 添加如下 配置到 文件中：（只需要将下面的 monsterxls修改为你集群中的namenode所在的主机名即可 ）</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<p><strong>注意：</strong>集群中的每台服务器都修改一下。</p>
<h2 id="重启hadoop服务再试试mapreduce"><a href="#重启hadoop服务再试试mapreduce" class="headerlink" title="重启hadoop服务再试试mapreduce"></a>重启hadoop服务再试试mapreduce</h2><p>重启服务，执行任务试试效果。</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Hive与Impala]]></title>
      <url>https://stanxia.github.io/2017/02/23/Hive%E4%B8%8EImpala/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="HiveQl执行过程："><a href="#HiveQl执行过程：" class="headerlink" title="HiveQl执行过程："></a>HiveQl执行过程：</h2><p>==》驱动模块<br>==》编译器进行编译  Antlr<br>==》优化器进行优化<br>==》执行器执行（执行map reduce任务）   全表扫描* 不会执行 map reduce 任务</p>
<h2 id="HiveQL查询的-MapReduce-作业转化流程："><a href="#HiveQL查询的-MapReduce-作业转化流程：" class="headerlink" title="HiveQL查询的 MapReduce 作业转化流程："></a>HiveQL查询的 MapReduce 作业转化流程：</h2><p>==》用户输入sql<br>==》抽象语法树 AST Tree<br>==》查询块 QueryBlock<br>==》逻辑查询计划  OperatorTree<br>==》重写逻辑查询计划<br>==》物理计划<br>==》选择最优的优化查询策略<br>==》输出</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fd0twkpnl9j20t2104wjn.jpg" alt="1"></p>
<h2 id="Impala与Hive的区别："><a href="#Impala与Hive的区别：" class="headerlink" title="Impala与Hive的区别："></a>Impala与Hive的区别：</h2><p>1.Hive适合长时间的批处理查询分析；Impala适合实时的sql查询<br>2.Hive依赖于MapReduce，执行计划组合成管道形的MapReduce任务模式；Impala执行计划表现为一颗完整的执行计划树<br>3.Hive在查询过程中，内存不够用时会使用外存；Impala在内存不够用时，不会使用外存，所有Impala在查询的时候会存在一定的限制</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fd0twll2zoj20qc0myn04.jpg" alt="2"></p>
<h2 id="Impala与Hive的相同点："><a href="#Impala与Hive的相同点：" class="headerlink" title="Impala与Hive的相同点："></a>Impala与Hive的相同点：</h2><p>1.使用相同的存储数据池，都支持 HDFS,HBase<br>2.使用相同的元数据<br>3.对SQL的解释处理比较相似，都是通过 语法分析 生成执行计划</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HBase1.3新版本 新特性预览]]></title>
      <url>https://stanxia.github.io/2017/02/22/HBase1-3%E6%96%B0%E7%89%88%E6%9C%AC-%E6%96%B0%E7%89%B9%E6%80%A7%E9%A2%84%E8%A7%88/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="新版本特性"><a href="#新版本特性" class="headerlink" title="新版本特性"></a>新版本特性</h2><p>2017年1月中旬 发布的 HBase 1.3.0版本，新版本特性如下：</p>
<ul>
<li>支持分层数据的压缩</li>
<li>多方面的性能提升，如 多预写日志（WAL）一个新的RPC机制，避免大量IO峰值的磁盘刷新吞吐量控制器等</li>
</ul>
<h2 id="新特性解析"><a href="#新特性解析" class="headerlink" title="新特性解析"></a>新特性解析</h2><h3 id="分层压缩"><a href="#分层压缩" class="headerlink" title="分层压缩"></a>分层压缩</h3><h5 id="使用场景："><a href="#使用场景：" class="headerlink" title="使用场景："></a>使用场景：</h5><p>数据被铲除或更新的时候，通常要更频繁的扫描最新的数据，而旧数据则较少被扫描。</p>
<h5 id="解决痛点："><a href="#解决痛点：" class="headerlink" title="解决痛点："></a>解决痛点：</h5><p>使用这种分层压缩策略，可有轻松的记录文件的TTL(生存时间 time-to-live)；当将现有存储文件压缩到单个较大的存储文件中时，过期的记录将被删除。</p>
<h3 id="多预写日志"><a href="#多预写日志" class="headerlink" title="多预写日志"></a>多预写日志</h3><p>每个region server都有一个预写日志(WAL)，该区域上的所有操作都要写入这个唯一的预写日志。</p>
<h5 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h5><p>改进后的 <strong>多预写日志(WAL)</strong> 支持更高性能的写入操作，这使得复制速度更快而且同步写入的延迟更低。默认情况下，多预写日志 提供了三个区域分组策略来分配 预写日志：每个区域的 预写日志都有 一个身份 标识，轮询调度算法 保证 每个区域映射的预写日志 都有其边界，区域中 不同 命名空间 的表 被映射到 不同的 预写日志 中。</p>
<p>性能测试报告 显示：<strong>预写日志 在纯SATA 磁盘中的运行平均延时 减少了 20% ；在SATA-SSD磁盘中运行延时 减少了 40%</strong>。</p>
<h3 id="新的RPC调度器"><a href="#新的RPC调度器" class="headerlink" title="新的RPC调度器"></a>新的RPC调度器</h3><p>新的RPC调度器基于 <strong>CoDel算法</strong> ，用于阻止 可用IO无法满足过高清秋频率引起的 长连接队列。</p>
<p>CoDel算法 用可控的延迟 来管理 活动队列，他根据 定义好的 <strong>阈值</strong> 来裁决队列中的<strong>最小延迟</strong>。一旦最小延迟超过阈值，该链接便会 被丢弃以便处理其他更有力的 最小延迟。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[IntelliJ Idea编译报错：javacTask: 源发行版 1.8 需要目标发行版 1.8]]></title>
      <url>https://stanxia.github.io/2017/02/21/IntelliJ-Idea%E7%BC%96%E8%AF%91%E6%8A%A5%E9%94%99%EF%BC%9AjavacTask-%E6%BA%90%E5%8F%91%E8%A1%8C%E7%89%88-1-7-%E9%9C%80%E8%A6%81%E7%9B%AE%E6%A0%87%E5%8F%91%E8%A1%8C%E7%89%88-1-7/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题一：java-compiler-error"><a href="#问题一：java-compiler-error" class="headerlink" title="问题一：java compiler error"></a>问题一：java compiler error</h2><p>运行java程序时，编译报错：java compiler error，如下图所示：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jlezsnj214m08ytaq.jpg" alt="1"></p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>打开idea设置=&gt;&gt;Build,Execution,Deployment=&gt;&gt;Compiler=&gt;&gt;Java Compiler=&gt;&gt;左边框Pre-module bytecode version =&gt;&gt;找到程序所在的模块=&gt;&gt;Target Bytecode version 选择提示中的需要目标发行版本=&gt;&gt;Apply=&gt;&gt;ok,如下图所示：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jpf2uzj21kw0x6q9o.jpg" alt="2"></p>
<h2 id="问题二：Usage-of-API-documented-as-since-1-6-1-7-…"><a href="#问题二：Usage-of-API-documented-as-since-1-6-1-7-…" class="headerlink" title="问题二：Usage of API documented as  @since 1.6/1.7/…"></a>问题二：Usage of API documented as  @since 1.6/1.7/…</h2><p>当使用了一些api之后，idea会提示Usage of API documented as  @since 1.6/1.7/…如下图所示：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jq6pbnj20t809wwga.jpg" alt="3"></p>
<h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><p>右键项目=&gt;&gt;open module setting=&gt;&gt;Laguage Level =&gt;&gt;选择（大于或等于）提示中@since的版本，如下图所示：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jpvbxfj21kw0xzahh.jpg" alt="4"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[经典大数据架构案例：酷狗音乐的大数据平台重构]]></title>
      <url>https://stanxia.github.io/2017/02/21/%E7%BB%8F%E5%85%B8%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E6%A1%88%E4%BE%8B%EF%BC%9A%E9%85%B7%E7%8B%97%E9%9F%B3%E4%B9%90%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E9%87%8D%E6%9E%84/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>编者按：本文是酷狗音乐的架构师王劲对酷狗大数据架构重构的总结。酷狗音乐的大数据架构本身很经典，而这篇讲解了对原来的架构上进行重构的工作内容，总共分为重构的原因、新一代的大数据技术架构、踩过的坑、后续持续改进四个部分来给大家谈酷狗音乐大数据平台重构的过程。</p>
<p>眨眼就新的一年了，时间过的真快，趁这段时间一直在写总结的机会，也总结下上一年的工作经验，避免重复踩坑。酷狗音乐大数据平台重构整整经历了一年时间，大头的行为流水数据迁移到新平台稳定运行，在这过程中填过坑，挖过坑，为后续业务的实时计算需求打下了很好的基础。在此感谢酷狗团队成员的不懈努力，大部分从开始只知道大数据这个概念，到现在成为团队的技术支柱，感到很欣慰。</p>
<p>从重构原因，技术架构，踩过的坑，后续持续改进四个方面来描述酷狗音乐大数据平台重构的过程，在此抛砖引玉，这次的内容与6月份在高可用架构群分享的大数据技术实践的有点不同，技术架构做了些调整。</p>
<p>其实大数据平台是一个庞大的系统工程，整个建设周期很长，涉及的生态链很长(包括：数据采集、接入，清洗、存储计算、数据挖掘，可视化等环节，每个环节都可以当做一个复杂的系统来建设)，风险也很大。</p>
<h2 id="一、重构原因"><a href="#一、重构原因" class="headerlink" title="一、重构原因"></a>一、重构原因</h2><p>在讲重构原因前，先介绍下原有的大数据平台架构，如下图：</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2flakmj20at07j0tr.jpg" alt="1"></p>
<p>从上图可知，主要基于Hadoop1.x+hive做离线计算(T+1)，基于大数据平台的数据采集、数据接入、数据清洗、作业调度、平台监控几个环节存在的一些问题来列举下。</p>
<p>数据采集：</p>
<ol>
<li>数据收集接口众多，且数据格式混乱，基本每个业务都有自己的上报接口</li>
<li>存在较大的重复开发成本</li>
<li>不能汇总上报，消耗客户端资源，以及网络流量</li>
<li>每个接口收集数据项和格式不统一，加大后期数据统计分析难度</li>
<li>各个接口实现质量并不高，存在被刷，泄密等风险</li>
</ol>
<p>数据接入:</p>
<ol>
<li>通过rsync同步文件，很难满足实时流计算的需求</li>
<li>接入数据出现异常后，很难排查及定位问题，需要很高的人力成本排查</li>
<li>业务系统数据通过Kettle每天全量同步到数据中心，同步时间长，导致依赖的作业经常会有延时现象</li>
</ol>
<p>数据清洗：</p>
<ol>
<li>ETL集中在作业计算前进行处理</li>
<li>存在重复清洗</li>
</ol>
<p>作业调度：</p>
<ol>
<li>大部分作业通过crontab调度，作业多了后不利于管理</li>
<li>经常出现作业调度冲突</li>
</ol>
<p>平台监控：</p>
<ol>
<li>只有硬件与操作系统级监控</li>
<li>数据平台方面的监控等于空白</li>
</ol>
<p>基于以上问题，结合在大数据中，数据的时效性越高，数据越有价值(如：实时个性化推荐系统，RTB系统，实时预警系统等)的理念，因此，开始大重构数据平台架构。</p>
<h2 id="二、新一代大数据技术架构"><a href="#二、新一代大数据技术架构" class="headerlink" title="二、新一代大数据技术架构"></a>二、新一代大数据技术架构</h2><p>在讲新一代大数据技术架构前，先讲下大数据特征与大数据技术要解决的问题。</p>
<p>1.大数据特征：“大量化(Volume)、多样化(Variety)、快速化(Velocity)、价值密度低（Value）”就是“大数据”显著的4V特征，或者说，只有具备这些特点的数据，才是大数据。</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2gw02gj20jp0cxwjl.jpg" alt="2"></p>
<p>2.大数据技术要解决的问题：大数据技术被设计用于在成本可承受的条件下，通过非常快速（velocity）地采集、发现和分析，从大量（volumes）、多类别（variety）的数据中提取价值（value），将是IT领域新一代的技术与架构。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2iu0jpj20kb0d4tbj.jpg" alt="3"></p>
<p>介绍了大数据的特性及大数据技术要解决的问题，我们先看看新一代大数据技术架构的数据流架构图：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2k4hl5j20k50cldkv.jpg" alt="4"></p>
<p>从这张图中，可以了解到大数据处理过程可以分为数据源、数据接入、数据清洗、数据缓存、存储计算、数据服务、数据消费等环节，每个环节都有具有高可用性、可扩展性等特性，都为下一个节点更好的服务打下基础。整个数据流过程都被数据质量监控系统监控，数据异常自动预警、告警。</p>
<p>新一代大数据整体技术架构如图：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2lvooaj20kc0dmq6e.jpg" alt="5"></p>
<p>将大数据计算分为实时计算与离线计算，在整个集群中，奔着能实时计算的，一定走实时计算流处理，通过实时计算流来提高数据的时效性及数据价值，同时减轻集群的资源使用率集中现象。</p>
<p>整体架构从下往上解释下每层的作用：</p>
<p>数据实时采集：</p>
<p>主要用于数据源采集服务，从数据流架构图中，可以知道，数据源分为前端日志，服务端日志，业务系统数据。下面讲解数据是怎么采集接入的。</p>
<p>a.前端日志采集接入：</p>
<p>前端日志采集要求实时，可靠性，高可用性等特性。技术选型时，对开源的数据采集工具flume,scribe,chukwa测试对比，发现基本满足不了我们的业务场景需求。所以，选择基于kafka开发一套数据采集网关，来完成数据采集需求。数据采集网关的开发过程中走了一些弯路，最后采用nginx+lua开发，基于lua实现了kafka生产者协议。有兴趣同学可以<a href="https://github.com/doujiang24/lua-resty-kafka" target="_blank" rel="external">去Github上看看</a>，另一同事实现的，现在在github上比较活跃，被一些互联网公司应用于线上环境了。</p>
<p>b.后端日志采集接入：</p>
<p>FileCollect,考虑到很多线上环境的环境变量不能改动，为减少侵入式，目前是采用Go语言实现文件采集，年后也准备重构这块。</p>
<p>前端，服务端的数据采集整体架构如下图：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2ndr1vj20ku0fugo3.jpg" alt="6"></p>
<p>c.业务数据接入</p>
<p>利用<a href="http://agapple.iteye.com/blog/1796633" target="_blank" rel="external">Canal</a>通过MySQL的binlog机制实时同步业务增量数据。</p>
<p>数据统一接入：为了后面数据流环节的处理规范，所有的数据接入数据中心，必须通过数据采集网关转换统一上报给Kafka集群，避免后端多种接入方式的处理问题。</p>
<p>数据实时清洗(ETL)：为了减轻存储计算集群的资源压力及数据可重用性角度考虑，把数据解压、解密、转义，部分简单的补全，异常数据处理等工作前移到数据流中处理，为后面环节的数据重用打下扎实的基础(实时计算与离线计算)。</p>
<p>数据缓存重用：为了避免大量数据流(400+亿条/天)写入HDFS，导致HDFS客户端不稳定现象及数据实时性考虑，把经过数据实时清洗后的数据重新写入Kafka并保留一定周期，离线计算(批处理)通过KG-Camus拉到HDFS(通过作业调度系统配置相应的作业计划)，实时计算基于Storm/JStorm直接从Kafka消费，有很完美的解决方案storm-kafka组件。</p>
<p>离线计算(批处理)：通过spark，spark SQL实现，整体性能比hive提高5—10倍，hive脚本都在转换为Spark/Spark SQL；部分复杂的作业还是通过Hive/Spark的方式实现。在离线计算中大部分公司都会涉及到数据仓库的问题，酷狗音乐也不例外，也有数据仓库的概念，只是我们在做存储分层设计时弱化了数据仓库概念。数据存储分层模型如下图：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2ombcpj20ff0cl0tx.jpg" alt="7"></p>
<p>大数据平台数据存储模型分为：数据缓冲层Data Cache Layer（DCL）、数据明细层Data Detail Layer（DDL）、公共数据层（Common）、数据汇总层Data Summary Layer（DSL）、数据应用层Data Application Layer（DAL）、数据分析层（Analysis）、临时提数层（Temp）。</p>
<p>1）数据缓冲层(DCL)：存储业务系统或者客户端上报的，经过解码、清洗、转换后的原始数据，为数据过滤做准备。</p>
<p>2)数据明细层（DDL）：存储接口缓冲层数据经过过滤后的明细数据。</p>
<p>3）公共数据层（Common）：主要存储维表数据与外部业务系统数据。</p>
<p>4）数据汇总层（DSL）：存储对明细数据，按业务主题，与公共数据层数据进行管理后的用户行为主题数据、用户行为宽表数据、轻量汇总数据等。为数据应用层统计计算提供基础数据。数据汇总层的数据永久保存在集群中。</p>
<p>5）数据应用层（DAL）：存储运营分析（Operations Analysis ）、指标体系（Metrics System）、线上服务（Online Service）与用户分析（User Analysis）等。需要对外输出的数据都存储在这一层。主要基于热数据部分对外提供服务，通过一定周期的数据还需要到DSL层装载查询。</p>
<p>6）数据分析层（Analysis）：存储对数据明细层、公共数据层、数据汇总层关联后经过算法计算的、为推荐、广告、榜单等数据挖掘需求提供中间结果的数据。</p>
<p>7）临时提数层（Temp）：存储临时提数、数据质量校验等生产的临时数据。</p>
<p>实时计算：基于Storm/JStorm，<a href="http://www.drools.org/" target="_blank" rel="external">Drools</a>,<a href="http://blog.csdn.net/luonanqin/article/category/1557469" target="_blank" rel="external">Esper</a>。主要应用于实时监控系统、APM、数据实时清洗平台、实时DAU统计等。</p>
<p>HBase/MySQL：用于实时计算，离线计算结果存储服务。</p>
<p>Redis：用于中间计算结果存储或字典数据等。</p>
<p>Elasticsearch：用于明细数据实时查询及HBase的二级索引存储(这块目前在数据中心还没有大规模使用，有兴趣的同学可以加入我们一起玩ES)。</p>
<p>Druid：目前用于支持大数据集的快速即席查询(ad-hoc)。</p>
<p>数据平台监控系统：数据平台监控系统包括基础平台监控系统与数据质量监控系统，数据平台监控系统分为2大方向，宏观层面和微观层面。宏观角度的理解就是进程级别,拓扑结构级别,拿Hadoop举例，如：DataNode，NameNode，JournalNode，ResourceManager，NodeManager，主要就是这5大组件，通过分析这些节点上的监控数据，一般你能够定位到慢节点，可能某台机器的网络出问题了，或者说某台机器执行的时间总是大于正常机器等等这样类似的问题。刚刚说的另一个监控方向，就是微观层面，就是细粒度化的监控，基于user用户级别，基于单个job，单个task级别的监控，像这类监控指标就是另一大方向，这类的监控指标在实际的使用场景中特别重要，一旦你的集群资源是开放给外面的用户使用，用户本身不了解你的这套机制原理，很容易会乱申请资源，造成严重拖垮集群整体运作效率的事情，所以这类监控的指标就是为了防止这样的事情发生。目前我们主要实现了宏观层面的监控。如：数据质量监控系统实现方案如下。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2pdg7rj20k60cswh6.jpg" alt="8"></p>
<h2 id="三、大数据平台重构过程中踩过的坑"><a href="#三、大数据平台重构过程中踩过的坑" class="headerlink" title="三、大数据平台重构过程中踩过的坑"></a>三、大数据平台重构过程中踩过的坑</h2><p>我们在大数据平台重构过程中踩过的坑，大致可以分为操作系统、架构设计、开源组件三类，下面主要列举些比较典型的，花时间比较长的问题。</p>
<p>1、操作系统级的坑</p>
<p>Hadoop的I/O性能很大程度上依赖于Linux本地文件系统的读写性能。Linux中有多种文件系统可供选择，比如ext3和ext4，不同的文件系统性能有一定的差别。我们主要想利用ext4文件系统的特性，由于之前的操作系统都是CentOS5.9不支持ext4文件格式，所以考虑操作系统升级为CentOS6.3版本，部署Hadoop集群后，作业一启动，就出现CPU内核过高的问题。如下图</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2t4lrhj20hq09yaj2.jpg" alt="9"></p>
<p>经过很长时间的测试验证，发现CentOS6优化了内存申请的效率，引入了THP的特性，而Hadoop是高密集型内存运算系统，这个改动给hadoop带来了副作用。通过以下内核参数优化关闭系统THP特性，CPU内核使用率马上下降，如下图:</p>
<p>echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/enabled</p>
<p>echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/defrag</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe39po0yj20ip0anwlr.jpg" alt="10"></p>
<p>2、架构设计的坑</p>
<p>最初的数据流架构是数据采集网关把数据上报给Kafka，再由数据实时清洗平台(ETL)做预处理后直接实时写入HDFS，如下图：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcxe3ao3htj20eb03474f.jpg" alt="11"></p>
<p>此架构，需要维持HDFS Client的长连接，由于网络等各种原因导致Storm实时写入HDFS经常不稳定，隔三差五的出现数据异常，使后面的计算结果异常不断，当时尝试过很多种手段去优化，如：保证长连接、连接断后重试机制、调整HDFS服务端参数等，都解决的不是彻底。</p>
<p>每天异常不断，旧异常没解决，新异常又来了，在压力山大的情况下，考虑从架构角度调整，不能只从具体的技术点去优化了，在做架构调整时，考虑到我们架构重构的初衷，提高数据的实时性，尽量让计算任务实时化，但重构过程中要考虑现有业务的过渡，所以架构必须支持实时与离线的需求，结合这些需求，在数据实时清洗平台(ETL)后加了一层数据缓存重用层(kafka)，也就是经过数据实时清洗平台后的数据还是写入kafka集群，由于kafka支持重复消费，所以同一份数据可以既满足实时计算也满足离线计算，从上面的整体技术架构也可以看出，如下图：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcxe3bzx3ij20j904c3z3.jpg" alt="12"></p>
<p>KG-Camus组件也是基于架构调整后，重新实现了一套离线消费Kafka集群数据的组件，此组件是参考LinkedIn的Camus实现的。此方式，使数据消费模式由原来的推方式改为拉模式了，不用维持HDFS Client的长连接等功能了，直接由作业调度系统每隔时间去拉一次数据，不同的业务可以设置不同的时间间隔，从此架构调整上线后，基本没有类似的异常出现了。</p>
<p>这个坑，是我自己给自己挖的，导致我们的重构计划延期2个月，主要原因是由最初技术预研究测试不充分所导致。</p>
<p>3、开源组件的坑</p>
<p>由于整个数据平台涉及到的开源组件很多，踩过的坑也是十个手指数不过来。</p>
<p>1）、当我们的行为数据全量接入到Kafka集群(几百亿/天)，数据采集网卡出现大量连接超时现象，但万兆网卡进出流量使用率并不是很高，只有几百Mbit/s，经过大量的测试排查后，调整以下参数，就是顺利解决了此问题。调整参数后网卡流量如下图：</p>
<p>a)、num.network.threads(网络处理线程数)值应该比cpu数略大</p>
<p>b)、num.io.threads(接收网络线程请求并处理线程数)值提高为cpu数两倍</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe3dps6xj20de06u3zc.jpg" alt="13"></p>
<p>2）、在hive0.14 版本中，利用函数ROW_NUMBER() OVER对数据进行数据处理后，导致大量的作业出现延时很大的现象，经异常排查后，发现在数据记录数没变的情况，数据的存储容量扩大到原来的5倍左右，导致MapReduce执行很慢造成的。改为自己实现类似的函数后，解决了容量扩大为原来几倍的现象。说到这里，也在此请教读到此处的读者一个问题，在海量数据去重中采用什么算法或组件进行比较合适，既能高性能又能高准确性，有好的建议或解决方案可以加happyjim2010微信私我。</p>
<p>3）、在业务实时监控系统中，用OpenTSDB与实时计算系统（storm）结合，用于聚合并存储实时metric数据。在这种实现中，通常需要在实时计算部分使用一个时间窗口（window），用于聚合实时数据，然后将聚合结果写入tsdb。但是，由于在实际情况中，实时数据在采集、上报阶段可能会存在延时，而导致tsdb写入的数据不准确。针对这个问题，我们做了一个改进，在原有tsdb写入api的基础上，增加了一个原子加api。这样，延迟到来的数据会被叠加到之前写入的数据之上，实时的准确性由于不可避免的原因（采集、上报阶段）产生了延迟，到最终的准确性也可以得到保证。另外，添加了这个改进之后，实时计算端的时间窗口就不需要因为考虑延迟问题设置得比较大，这样既节省了内存的消耗，也提高了实时性。</p>
<h2 id="四、后续持续改进"><a href="#四、后续持续改进" class="headerlink" title="四、后续持续改进"></a>四、后续持续改进</h2><p>数据存储(分布式内存文件系统(Tachyon)、数据多介质分层存储、数据列式存储)、即席查询(OLAP)、资源隔离、数据安全、平台微观层面监控、数据对外服务等。</p>
<h2 id="作者介绍"><a href="#作者介绍" class="headerlink" title="作者介绍"></a>作者介绍</h2><p><strong>王劲</strong>，目前就职酷狗音乐，大数据架构师，负责酷狗大数据技术规划、建设、应用。 11年的IT从业经验，2年分布式应用开发，3年大数据技术实践经验，主要研究方向流式计算、大数据存储计算、分布式存储系统、NoSQL、搜索引擎等。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[flume1.7结合kafka0.9.0.1相关配置]]></title>
      <url>https://stanxia.github.io/2017/02/20/flume1-7%E7%BB%93%E5%90%88kafka0-9-0-1%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>利用flume1.7抓取数据，传入到kafka</p>
<h2 id="配置文件设置"><a href="#配置文件设置" class="headerlink" title="配置文件设置"></a>配置文件设置</h2><p>在flume/conf/新建一个 kafka.conf,修改该文件,相关配置如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">vi flume/conf/kafka.conf</div><div class="line">#agent1表示代理名称</div><div class="line">agent1.sources=source1</div><div class="line">agent1.channels=channel1</div><div class="line">agent1.sinks=sink1</div><div class="line">#Spooling Directory是监控指定文件夹中新文件的变化，一旦新文件出现，就解析该文件内容，然后</div><div class="line">写入到channle。写入完成后，标记该文件已完成或者删除该文件。</div><div class="line">#配置source</div><div class="line">#数据来源类型 spooldir表示 文件夹 ，command</div><div class="line">agent1.sources.source1.type=spooldir</div><div class="line">#指定监控的目录</div><div class="line">agent1.sources.source1.spoolDir=/home/hadoop/logs</div><div class="line">agent1.sources.source1.channels=channel1</div><div class="line">agent1.sources.source1.fileHeader=false</div><div class="line">agent1.sources.source1.interceptors=i1</div><div class="line">agent1.sources.source1.interceptors.i1.type=timestamp</div><div class="line">#配置channel1</div><div class="line">agent1.channels.channel1.type=file</div><div class="line">#channel数据存放的备份目录</div><div class="line">agent1.channels.channel1.checkpointDir=/home/hadoop/channel_data.backup</div><div class="line">#channel数据存放目录</div><div class="line">agent1.channels.channel1.dataDir=/home/hadoop/channel_data</div><div class="line">#配置sink1</div><div class="line">agent1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink</div><div class="line">#新版本开始使用如下配置：</div><div class="line">agent1.sinks.sink1.kafka.bootstrap.servers=monsterxls:9092,slave1xls:9092,slave2xls:9092</div><div class="line">#agent1.sinks.sink1.partition.key=0</div><div class="line">#agent1.sinks.sink1.partitioner.class=org.apache.flume.plugins.SinglePartition</div><div class="line">agent1.sinks.sink1.serializer.class=kafka.serializer.StringEncoder</div><div class="line">agent1.sinks.sink1.max.message.size=1000000</div><div class="line">agent1.sinks.sink1.producer.type=sync</div><div class="line">agent1.sinks.sink1.custom.encoding=UTF-8</div><div class="line">#新版本使用如下配置：</div><div class="line">agent1.sinks.sink1.topic=stanxls</div><div class="line">agent1.sinks.sink1.channel=channel1</div></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>注意版本的问题。新版本改动了很多，在配置之前多看下帮助文档，了解下各种属性。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[yarn三种调度规则]]></title>
      <url>https://stanxia.github.io/2017/02/16/yarn%E4%B8%89%E7%A7%8D%E8%B0%83%E5%BA%A6%E8%A7%84%E5%88%99/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="yarn三种调度机制"><a href="#yarn三种调度机制" class="headerlink" title="yarn三种调度机制"></a>yarn三种调度机制</h2><ol>
<li><p>FIFO Scheduler先进先出调度机制</p>
</li>
<li><p>Fair Scheduler公平调度机制</p>
</li>
<li><p>Capacity Scheduler容量机制</p>
</li>
</ol>
<h2 id="FIFO-Scheduler"><a href="#FIFO-Scheduler" class="headerlink" title="FIFO Scheduler"></a>FIFO Scheduler</h2><p>按照先进先出的调度机制，所有的application将按照提交的顺序来执行，这些application都放在一个队列里面，顺序执行，执行完一个之后，才会执行下一个。</p>
<h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><p>如果任务耗时长，后面提交的任务会一直处于等待状态，影响效率。所以只适合单人跑任务。</p>
<p>面对以上缺点，yarn提出了另两种策略，更加适合共享集群。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcsouzgzg1j20q80eqabe.jpg" alt="3"></p>
<h2 id="Capacity-Scheduler"><a href="#Capacity-Scheduler" class="headerlink" title="Capacity Scheduler"></a>Capacity Scheduler</h2><p>定位：多人共享调度器。</p>
<p>机制：为每人分配一个队列，每个队列占用集群固定的资源，每个队列占用的资源可以不同，每个队列内部还是按照FIFO的策略。</p>
<p>特性：queue elasticity （弹性队列）根据实际情况分配资源</p>
<p>Capacity Scheduler 的队列时支持层级关系的：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcsoa7b1tkj216m068mxf.jpg" alt="capacity1"></p>
<p>相关配置如下：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcsoa7u5psj20vy13m44h.jpg" alt="capacity2"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcsouw6wsej20p60g8401.jpg" alt="1"></p>
<h5 id="队列设置"><a href="#队列设置" class="headerlink" title="队列设置"></a>队列设置</h5><p>如果是mapreduce任务，通过 <code>mapreduce.job.queuename</code>来设置执行队列。</p>
<h2 id="Fair-Scheduler"><a href="#Fair-Scheduler" class="headerlink" title="Fair Scheduler"></a>Fair Scheduler</h2><p>机制：为每一个任务均匀分配资源，一个任务就可以用整个集群资源，两个任务就平分集群资源，依次类推。</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcsouwra8hj20og0ekjsr.jpg" alt="2"></p>
<h5 id="开启Fair-Scheduler"><a href="#开启Fair-Scheduler" class="headerlink" title="开启Fair Scheduler"></a>开启Fair Scheduler</h5><p>在<strong>yarn-site.xml</strong>中设置 <code>yarn.resourcemanager.scheduler.class</code>为<code>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</code> 。NOTE:CDH默认的就是Faire Scheduler ，CDH并不支持 Capacity Scheduler.</p>
<h5 id="队列设置-1"><a href="#队列设置-1" class="headerlink" title="队列设置"></a>队列设置</h5><p>设置fair-scheduler.xml文件，可参考下图：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcsortg5yjj215c0litcz.jpg" alt="fair"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka文件存储机制及partition和offset]]></title>
      <url>https://stanxia.github.io/2017/02/15/Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%E5%8F%8Apartition%E5%92%8Coffset/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="初识kafka"><a href="#初识kafka" class="headerlink" title="初识kafka"></a>初识kafka</h2><p>kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作是在现代网络上的许多社会功能的一个关键因素。</p>
<p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统(也可以当做MQ系统)，常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p>
<h2 id="为什么用kafka"><a href="#为什么用kafka" class="headerlink" title="为什么用kafka"></a>为什么用kafka</h2><p>一个商业化消息队列的性能好坏，其文件存储机制设计是衡量一个消息队列服务技术水平和最关键指标之一。</p>
<p>下面将从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p>
<h2 id="kafka名词解释"><a href="#kafka名词解释" class="headerlink" title="kafka名词解释"></a>kafka名词解释</h2><table>
<thead>
<tr>
<th style="text-align:center">名词</th>
<th style="text-align:center">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">broker</td>
<td style="text-align:center">消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</td>
</tr>
<tr>
<td style="text-align:center">topic</td>
<td style="text-align:center">一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</td>
</tr>
<tr>
<td style="text-align:center">partition</td>
<td style="text-align:center">topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。</td>
</tr>
<tr>
<td style="text-align:center">segment</td>
<td style="text-align:center">partition物理上由多个segment组成，下面有详细解释</td>
</tr>
</tbody>
</table>
<h2 id="kafka分析步骤"><a href="#kafka分析步骤" class="headerlink" title="kafka分析步骤"></a>kafka分析步骤</h2><ol>
<li>topic中partition存储分布</li>
<li>partiton中文件存储方式</li>
<li>partiton中segment文件存储结构</li>
<li>在partition中如何通过offset查找message</li>
</ol>
<h2 id="topic中partition存储分布详解"><a href="#topic中partition存储分布详解" class="headerlink" title="topic中partition存储分布详解"></a>topic中partition存储分布详解</h2><p>假设实验环境中Kafka集群只有一个broker，xxx/message-folder为数据文件存储根目录，在Kafka broker中server.properties文件配置(参数log.dirs=xxx/message-folder)，例如创建2个topic名称分别为report_push、launch_info, partitions数量都为partitions=4</p>
<p>存储路径和目录规则为：</p>
<p>xxx/message-folder</p>
<p>|–report_push-0</p>
<p>|–report_push-1</p>
<p>|–report_push-2</p>
<p>|–report_push-3</p>
<p>|–launch_info-0</p>
<p>|–launch_info-1</p>
<p>|–launch_info-2</p>
<p>|–launch_info-3</p>
<p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。</p>
<h2 id="partiton中文件存储方式"><a href="#partiton中文件存储方式" class="headerlink" title="partiton中文件存储方式"></a>partiton中文件存储方式</h2><p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275349891.png" alt="img1"></p>
<p>  <del>图1</del></p>
<p>每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。</p>
<p>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。</p>
<p>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。</p>
<h2 id="partiton中segment文件存储结构"><a href="#partiton中segment文件存储结构" class="headerlink" title="partiton中segment文件存储结构"></a>partiton中segment文件存储结构</h2><p>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件.</p>
<p>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</p>
<p>下面文件列表是笔者在Kafka broker上做的一个实验，创建一个topicXXX包含1 partition，设置每个segment大小为500MB,并启动producer向Kafka broker写入大量数据,如下图2所示segment文件列表形象说明了上述2个规则：</p>
<p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275118393.png" alt="img2"></p>
<p><del>图2</del></p>
<p>上图中对segment file文件为例，说明segment中index&lt;—-&gt;data file对应关系物理结构如下：</p>
<p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275129022.png" alt="img3"></p>
<p><del>图3</del></p>
<p>上图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。</p>
<p>其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移地址为497。</p>
<p>从上图了解到segment data file由许多message组成，下面详细说明message物理结构如下：</p>
<p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275773410.png" alt="img4"></p>
<p><del>图4</del></p>
<p>参数说明：</p>
<table>
<thead>
<tr>
<th style="text-align:center">参数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">8 byte  offset</td>
<td style="text-align:center">在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息, 在parition(分区)内的位置。即offset表示partiion的第多少message</td>
</tr>
<tr>
<td style="text-align:center">4 byte   message  size</td>
<td style="text-align:center">message大小</td>
</tr>
<tr>
<td style="text-align:center">4 byte   CRC32</td>
<td style="text-align:center">用crc32校验message</td>
</tr>
<tr>
<td style="text-align:center">1 byte   “magic”</td>
<td style="text-align:center">表示本次发布Kafka服务程序协议版本号</td>
</tr>
<tr>
<td style="text-align:center">1 byte    “attributes”</td>
<td style="text-align:center">表示为独立版本、或标识压缩类型、或编码类型。</td>
</tr>
<tr>
<td style="text-align:center">4 byte key  length</td>
<td style="text-align:center">表示key的长度,当key为-1时，K byte key字段不填</td>
</tr>
<tr>
<td style="text-align:center">K byte key</td>
<td style="text-align:center">可选</td>
</tr>
<tr>
<td style="text-align:center">value bytes   payload</td>
<td style="text-align:center">表示实际消息数据。</td>
</tr>
</tbody>
</table>
<h2 id="在partition中如何通过offset查找message"><a href="#在partition中如何通过offset查找message" class="headerlink" title="在partition中如何通过offset查找message"></a>在partition中如何通过offset查找message</h2><p>例如读取offset=368776的message，需要通过下面2个步骤查找。</p>
<p>第一步查找segment file：</p>
<p>上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，就可以快速定位到具体文件。</p>
<p>当offset=368776时定位到00000000000000368769.index|log</p>
<p>第二步通过segment file查找message：</p>
<p>通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和 00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到 offset=368776为止。</p>
<p>从上述图3可知这样做的优点，segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p>
<h2 id="Kafka文件存储机制-实际运行效果"><a href="#Kafka文件存储机制-实际运行效果" class="headerlink" title="Kafka文件存储机制?实际运行效果"></a>Kafka文件存储机制?实际运行效果</h2><p>Kafka运行时很少有大量读磁盘的操作，主要是定期批量写磁盘操作，因此操作磁盘很高效。这跟Kafka文件存储中读写message的设计是息息相关的。Kafka中读写message有如下特点:</p>
<h5 id="写message"><a href="#写message" class="headerlink" title="写message"></a>写message</h5><p>消息从java堆转入page cache(即物理内存)。</p>
<p>由异步线程刷盘,消息从page cache刷入磁盘。</p>
<h5 id="读message"><a href="#读message" class="headerlink" title="读message"></a>读message</h5><p>消息直接从page cache转入socket发送出去。</p>
<p>当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁盘Load消息到page cache,然后直接从socket发出去。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h5 id="Kafka高效文件存储设计特点"><a href="#Kafka高效文件存储设计特点" class="headerlink" title="Kafka高效文件存储设计特点"></a>Kafka高效文件存储设计特点</h5><p>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</p>
<p>通过索引信息可以快速定位message和确定response的最大大小。</p>
<p>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</p>
<p>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</p>
<h5 id="kafka中的partition和offset-log机制"><a href="#kafka中的partition和offset-log机制" class="headerlink" title="kafka中的partition和offset,log机制"></a>kafka中的partition和offset,log机制</h5><p><img src="http://www.111cn.net/get_pic/2015/10/31/20151031233153426.jpg" alt="img5"></p>
<p><del>图5 分区读写日志</del></p>
<p>首先,kafka是通过log(日志)来记录消息发布的.每当产生一个消息,kafka会记录到本地的log文件中,这个log和我们平时的log有一定的区别.</p>
<p>这个log文件默认的位置在config/server.properties中指定的.默认的位置是log.dirs=/tmp/kafka-logs</p>
<h5 id="分区partition"><a href="#分区partition" class="headerlink" title="分区partition"></a>分区partition</h5><p>kafka是为分布式环境设计的,因此如果日志文件,其实也可以理解成消息<a href="http://www.111cn.net/database/database.html" target="_blank" rel="external">数据库</a>,放在同一个地方,那么必然会带来可用性的下降,一挂全挂,如果全量拷贝到所有的机器上,那么数据又存在过多的冗余,而且由于每台机器的磁盘大小是有限的,所以即使有再多的机器,可处理的消息还是被磁盘所限制,无法超越当前磁盘大小.因此有了partition的概念.</p>
<p>kafka对消息进行一定的计算,通过hash来进行分区.这样,就把一份log文件分成了多份.如上面的分区读写日志图,分成多份以后,在单台broker上,比如快速上手中,如果新建topic的时候,我们选择了–replication-factor 1 –partitions 2,那么在log目录里,我们会看到：</p>
<p>test-0目录和test-1目录.就是两个分区了.</p>
<p><img src="http://www.111cn.net/get_pic/2015/10/31/20151031233155850.jpg" alt="img6"></p>
<p><del>图6 kafka分布式分区存储</del></p>
<p>这是一个topic包含4个Partition，2 Replication(拷贝),也就是说全部的消息被放在了4个分区存储,为了高可用,将4个分区做了2份冗余,然后根据分配算法.将总共8份数据,分配到broker集群上.</p>
<p>结果就是每个broker上存储的数据比全量数据要少,但每份数据都有冗余,这样,一旦一台机器宕机,并不影响使用.比如图中的Broker1,宕机了.那么剩下的三台broker依然保留了全量的分区数据.所以还能使用,如果再宕机一台,那么数据不完整了.当然你可以设置更多的冗余,比如设置了冗余是4,那么每台机器就有了0123完整的数据,宕机几台都行.需要在存储占用和高可用之间做衡量.</p>
<p>宕机后,zookeeper会选出新的partition leader.来提供服务.</p>
<h5 id="偏移offset"><a href="#偏移offset" class="headerlink" title="偏移offset"></a>偏移offset</h5><p>上面说了分区，分区是一个有序的,不可变的消息队列.新来的commit log持续往后面加数据.这些消息被分配了一个下标(或者偏移),就是offset,用来定位这一条消息.</p>
<p>消费者消费到了哪条消息,是保持在消费者这一端的.消息者也可以控制,消费者可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.也可以重置offset.</p>
<h5 id="如何通过offset算出分区"><a href="#如何通过offset算出分区" class="headerlink" title="如何通过offset算出分区"></a>如何通过offset算出分区</h5><p>partition存储的时候,又分成了多个segment(段),然后通过一个index,索引,来标识第几段.</p>
<p>在磁盘中，每个topic目录下面会有两个文件 index和log.</p>
<p><img src="http://www.111cn.net/get_pic/2015/10/31/20151031233158914.jpg" alt="img7"></p>
<p><del>图7 index文件和log文件</del></p>
<p>对于某个指定的分区,假设每5个消息,作为一个段大小,当产生了10条消息的情况下,目前有会得到：</p>
<p>0.index (表示这里index是对0-4做的索引)</p>
<p>5.index (表示这里index是对5-9做的索引)</p>
<p>10.index (表示这里index是对10-15做的索引,目前还没满)</p>
<p>和log文件</p>
<p>0.log</p>
<p>5.log</p>
<p>10.log</p>
<p>,当消费者需要读取offset=8的时候,首先kafka对index文件列表进行<u>二分查找</u>,可以算出.应该是在5.index对应的log文件中,然后对对应的5.log文件,进行顺序查找,5-&gt;6-&gt;7-&gt;8,直到顺序找到8就好了.</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop原生集群添加hive组件]]></title>
      <url>https://stanxia.github.io/2017/02/15/Hadoop%E5%8E%9F%E7%94%9F%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0hive%E7%BB%84%E4%BB%B6/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="一：前提"><a href="#一：前提" class="headerlink" title="一：前提"></a>一：前提</h2><ol>
<li>准备MYSQL JDBC驱动</li>
<li>本机已经安装了JDK</li>
<li>基于自己已有的HADOOP集群进行操作</li>
<li>在开启HIve之前，开启HDFS + YARN+ntpd时间同步</li>
</ol>
<h2 id="二：HIVE下载"><a href="#二：HIVE下载" class="headerlink" title="二：HIVE下载"></a>二：HIVE下载</h2><ol>
<li>HIVE的安装包下载</li>
</ol>
<p><code>wget http://mirrors.cnnic.cn/apache/hive/hive-1.2.1/apache-hive-1.2.1-bin.tar.gz</code></p>
<ol>
<li>然后解压</li>
</ol>
<p><code>tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /opt/</code></p>
<p><code>cd /opt/</code></p>
<p><code>mv apache-hive-1.2.1-bin hive</code></p>
<ol>
<li>配置环境变量</li>
</ol>
<p><code>vi /etc/profile</code></p>
<p>添加以下内容：</p>
<p><code>HIVE_HOME=/opt/hive</code></p>
<p><code>export PATH=$PATH:$HIVE_HOME/bin</code></p>
<p>文件生效：</p>
<p><code>source /etc/profile</code></p>
<p>最好 ROOT用户与 <strong>HADOOP用户</strong>都执行一次</p>
<h2 id="三：安装依赖包"><a href="#三：安装依赖包" class="headerlink" title="三：安装依赖包"></a>三：安装依赖包</h2><ol>
<li>安装nettools</li>
</ol>
<p><code>yum -y install net-tools</code></p>
<ol>
<li>安装perl</li>
</ol>
<p><code>yum install -y perl-Module-Install.noarch</code></p>
<h2 id="四：MySQL安装与配置"><a href="#四：MySQL安装与配置" class="headerlink" title="四：MySQL安装与配置"></a>四：MySQL安装与配置</h2><ol>
<li><h5 id="安装MYSQL"><a href="#安装MYSQL" class="headerlink" title="安装MYSQL"></a>安装MYSQL</h5></li>
</ol>
<ul>
<li><p>查看是否已经安装MYSQL执行命令如下：</p>
<p><code>rpm -qa | grep mariadb</code></p>
</li>
<li><p>如果存在 执行卸载:</p>
<p> <code>yum remove mariadb-libs</code>  然后 <code>yum remove mariadb</code></p>
</li>
<li><p>安装MYSQL  简易版需要安装 unzip工具 </p>
<p><code>yum -y install unzip</code></p>
</li>
<li><p>下载mysql并解压，建议下载rpm包：</p>
<p>点击<a href="http://www.mysql.com/downloads" target="_blank" rel="external">MySQL 下载</a></p>
<p>解压下载的zip：</p>
<p><code>unzip **.zip</code></p>
<p>进入到解压的MYSQL目录，安装rpm包：</p>
<p><code>rpm –ivh **.rpm</code></p>
</li>
</ul>
<ol>
<li><h5 id="配置MYSQL"><a href="#配置MYSQL" class="headerlink" title="配置MYSQL"></a>配置MYSQL</h5></li>
</ol>
<ul>
<li><p>修改配置文件路径：cp /usr/share/mysql/my-default.cnf /etc/my.cnf</p>
</li>
<li><p>在配置文件中增加以下配置并保存：</p>
<p><code>vim /etc/my.cnf</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">default-storage-engine = innodb</div><div class="line"></div><div class="line">innodb_file_per_table</div><div class="line"></div><div class="line">collation-server = utf8_general_ci</div><div class="line"></div><div class="line">init-connect = 'SET NAMES utf8'</div><div class="line"></div><div class="line">character-set-server = utf8</div></pre></td></tr></table></figure>
</li>
</ul>
<ol>
<li><p>初始化数据库执行：</p>
<p><code>/usr/bin/mysql_install_db</code></p>
</li>
<li><p>开启MYSQL服务：</p>
<p><code>service mysql restart</code></p>
</li>
<li><p>查看mysql root初始化密码：</p>
<p><code>cat /root/.mysql_secret</code></p>
</li>
<li><p>登陆mysql ：</p>
<p> <code>mysql -u root –p</code> </p>
<ul>
<li>复制root的初始密码</li>
</ul>
<p>（MYSQL下执行）<code>SET PASSWORD=PASSWORD(&#39;123456&#39;);</code></p>
<ul>
<li><p>创建HIVE用户，HIVE数据库</p>
<p><code>create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;</code></p>
<p><code>use mysql;</code></p>
<p><code>grant all privileges on *.* to hive@&quot;%&quot; identified by &quot;hive&quot; with grant option;</code></p>
<p><code>flush privileges;</code></p>
<p>最好添加如下代码（否则可能会有乱码产生）：</p>
<p><code>alter database hive CHARACTER SET latin1</code></p>
</li>
</ul>
</li>
<li><p>（LINUX下执行）开启开机启动：</p>
<p><code>chkconfig mysql on</code></p>
</li>
<li><p>（LINUX下执行）拷贝mysql驱动包到 hive/lib目录下面,否则hive不能连接上mysql：</p>
<p><code>cp mysql-connector-java-5.1.34-bin.jar /opt/hive/lib</code></p>
</li>
</ol>
<h2 id="五：解决冲突包"><a href="#五：解决冲突包" class="headerlink" title="五：解决冲突包"></a>五：解决冲突包</h2><p>查看<em>hadoop目录/share/hadoop/yarn/lib</em>和<em>hive目录/lib</em>，检查jlinexxxx.jar 的版本，将低版本的替换为另一边高版本的。</p>
<p>例如：/opt/Hadoop/share/Hadoop/yarn/lib下的jline为jline 2.xx，而/opt/hive/lib/jiline为jline 0.xxx版本，则将</p>
<p>/opt/Hadoop/share/Hadoop/yarn/lib下的jline 2.xx包复制到/opt/hive/lib/下面，并且删除/opt/hive/lib/jline 0.xxx包。</p>
<p><code>ls /opt/hadoop/share/hadoop/yarn/lib</code> </p>
<p><code>ls /opt/hive/lib/</code> </p>
<h2 id="六：-修改配置文件"><a href="#六：-修改配置文件" class="headerlink" title="六： 修改配置文件"></a>六： 修改配置文件</h2><p>进入到hive的配置文件目录下，找到hive-default.xml.template，cp为hive-default.xml</p>
<p><code>cd /opt/hive/conf/</code></p>
<p><code>cp hive-default.xml.template hive-default.xml</code></p>
<p>另创建hive-site.xml并添加参数</p>
<p><code>vi hive-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line">  &lt;?xml version="1.0"?&gt;</div><div class="line"></div><div class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hivelog<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></div><div class="line"></div><div class="line">      Location of Hive run time structured log file</div><div class="line"></div><div class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive-$&#123;user.name&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Scratch space for Hive jobs<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://monsterxls:3306/hive?createDatabaseIfNotExist=true&amp; useUnicode=true&amp;characterEncoding=utf-8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>复制 hive-env.sh.template文件为 hive-env.sh</p>
<p><code>cp hive-env.sh.template hive-env.sh</code></p>
<p>主要修改以下三行</p>
<p><code>vi hive-env.sh</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">HADOOP_HOME=/opt/hadoop</div><div class="line"></div><div class="line">export HIVE_CONF_DIR=/opt/hive/conf</div><div class="line"></div><div class="line">export HIVE_AUX_JARS_PATH=/opt/hive/lib</div></pre></td></tr></table></figure>
<h2 id="七：-Hive启动"><a href="#七：-Hive启动" class="headerlink" title="七： Hive启动"></a>七： Hive启动</h2><ol>
<li><p>启动命令如下</p>
<p><code>hive --service metastore &amp;</code></p>
</li>
<li><p>查看启动后，进程是否存在</p>
<p><code>jps</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">10288 RunJar  #多了一个进程</div><div class="line"></div><div class="line">9365 NameNode</div><div class="line"></div><div class="line">9670 SecondaryNameNode</div><div class="line"></div><div class="line">11096 Jps</div><div class="line"></div><div class="line">9944 NodeManager</div><div class="line"></div><div class="line">9838 ResourceManager</div><div class="line"></div><div class="line">9471 DataNode</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="八：Hive服务器端访问"><a href="#八：Hive服务器端访问" class="headerlink" title="八：Hive服务器端访问"></a>八：Hive服务器端访问</h2><p>直接在命令控制台输入：</p>
<p><code>hive</code> </p>
<p>即可进入hive的控制台界面</p>
<p>进行一些简单的操作查看hive是否安装成功：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">hive&gt; show databases;</div><div class="line"></div><div class="line">OK</div><div class="line"></div><div class="line">default</div><div class="line"></div><div class="line">Time taken: <span class="number">1.332</span> seconds, Fetched: <span class="number">2</span> row(s)</div><div class="line"></div><div class="line">hive&gt; use default;</div><div class="line"></div><div class="line">OK</div><div class="line"></div><div class="line">Time taken: <span class="number">0.037</span> seconds</div><div class="line"></div><div class="line">hive&gt; create table test1(id int);</div><div class="line"></div><div class="line">OK</div><div class="line"></div><div class="line">Time taken: <span class="number">0.572</span> seconds</div><div class="line"></div><div class="line">hive&gt; show tables;</div><div class="line"></div><div class="line">OK</div><div class="line"></div><div class="line">test1</div><div class="line"></div><div class="line">Time taken: <span class="number">0.057</span> seconds, Fetched: <span class="number">3</span> row(s)</div><div class="line"></div><div class="line">hive&gt;</div></pre></td></tr></table></figure>
<p>创建表 testload  字段包含 id1,id2,id3，以逗号分割：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive&gt; CREATE TABLE testload (id1 STRING,id2 STRING,id3 STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos;;</div></pre></td></tr></table></figure>
<p> 使用 Hiveload进入testload:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive&gt; LOAD DATA LOCAL INPATH &apos;目标文件&apos; OVERWRITE INTO TABLE  testload;</div></pre></td></tr></table></figure>
<p>测试能否执行mapreduce任务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hive&gt; SELECT count(*) FROM testload;</div></pre></td></tr></table></figure>
<h2 id="结束语："><a href="#结束语：" class="headerlink" title="结束语："></a>结束语：</h2><ol>
<li>安装集群需要耐心以及细心，否则前面错一步后面会很难找到错误的来源。</li>
<li>出现错误请看日志，一般都会在日志中找到问题的原因。</li>
</ol>
<p>GOOD LUCK!!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[MAC应用无法打开或文件损坏的处理方法]]></title>
      <url>https://stanxia.github.io/2017/02/15/MAC%E5%BA%94%E7%94%A8%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E6%88%96%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>下载了一些程序之后，却发现无法在MAC中安装，安装时会弹出下图所示警告框：“打不开 xxx，因为它来自身份不明的开发者”</p>
<p><img src="http://img.xclient.info/attachment/cdn/large/006ehIt6jw1execfbx4xnj30nc0b6dgh.jpg" alt="img1"></p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>在MAC下安装一些软件时提示”来自身份不明开发者”，其实这是MAC新系统启用了新的安全机制。<br>默认只信任 <strong>Mac App Store</strong> 下载的软件和拥有开发者 ID 签名的应用程序。<br>换句话说就是 MAC 系统默认只能安装靠谱渠道（有苹果审核的 <strong>Mac App Store</strong>）下载的软件或被认可的人开发的软件。</p>
<p>这当然是为了用户不会稀里糊涂安装流氓软件中招，但没有开发者签名的 “老实软件” 也受影响了，安装就会弹出下图所示警告框：“打不开 xxx，因为它来自身份不明的开发者”。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol>
<li><p>最简单的方式：按住Control后，再次点击软件图标，即可。</p>
</li>
<li><p>修改系统配置：系统偏好设置… -&gt; 安全性与隐私… -&gt;通用… -&gt;选择任何来源。<img src="http://ww2.sinaimg.cn/large/006ehIt6jw1exed22xlgpj30os0m6ae7.jpg" alt="img2"></p>
<h2 id=""><a href="#" class="headerlink" title=""></a><img src="http://ww2.sinaimg.cn/large/006ehIt6jw1exed2kg4wbj30oe0jqtbd.jpg" alt="imag3"></h2><h2 id="-1"><a href="#-1" class="headerlink" title=""></a><img src="http://ww2.sinaimg.cn/large/006ehIt6jw1exed0cuqtyj30oe0js77b.jpg" alt="img4"></h2></li>
<li><p><strong><em>macOs Sierra 10.2</em></strong>以上版本，打开<u>终端</u>，执行:<code>sudo spctl --master-disable</code> 就可以啦。</p>
</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[完善ntp时间同步]]></title>
      <url>https://stanxia.github.io/2017/02/14/%E5%AE%8C%E5%96%84ntp%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h1 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h1><p>ntp同步时间过长</p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>修改 /etc/ntp.conf</p>
<p>主节点配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">server ntp7.aliyun.com iburst</div><div class="line">restrict ntp7.aliyun.com nomodify notrap noquery</div></pre></td></tr></table></figure>
<p>从节点配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">restrict hadoop1(主机名) nomodify notrap noquery</div><div class="line">server hadoop1(主机名) iburst</div></pre></td></tr></table></figure>
<h1 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h1><p>ntp时间同步之后，显示非中国时区</p>
<h1 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</div></pre></td></tr></table></figure>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[zookeeper启动时数组越界异常]]></title>
      <url>https://stanxia.github.io/2017/02/14/zookeeper%E5%90%AF%E5%8A%A8%E6%97%B6%E6%95%B0%E7%BB%84%E8%B6%8A%E7%95%8C%E5%BC%82%E5%B8%B8/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>启动zookeeper时，出现以下异常信息：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcsp95necuj21ji0jidla.jpg" alt="1"></p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>修改 ／zookeeper/conf/zoo.cfg文件<br>修改服务器id和ip映射时注意格式为：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">vi /zookeeper/conf/zoo.cfg</div><div class="line">server.1=host:port:port或者host:port或者host:port:port:type</div></pre></td></tr></table></figure></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka安装与简单的应用]]></title>
      <url>https://stanxia.github.io/2017/02/13/kafka%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="一、安装环境"><a href="#一、安装环境" class="headerlink" title="一、安装环境"></a>一、安装环境</h2><ol>
<li><p>多台Linux服务器</p>
</li>
<li><p>已经安装好zookeeper的集群（安装zookeeper的步骤可以查看前篇文章）</p>
</li>
<li><p>下载kafka</p>
<p><a href="https://kafka.apache.org/downloads.html" target="_blank" rel="external">点击选择需要下载的kafka版本</a></p>
<p>或者直接在服务器上面下载：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget  http://apache.opencas.org/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="二、安装kafka"><a href="#二、安装kafka" class="headerlink" title="二、安装kafka"></a>二、安装kafka</h2><h5 id="创建项目目录："><a href="#创建项目目录：" class="headerlink" title="创建项目目录："></a>创建项目目录：</h5><p>创建kafka项目目录，最好是将多有的集群项目都放在一个目录下面，方便管理各类项目。博主是将所有的集群项目都放在/opt下面。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir /opt/kafka <span class="comment">#创建kafka项目目录</span></div><div class="line">mkdir /opt/kafka/kafkalogs <span class="comment">#创建kafka项目的日志目录</span></div></pre></td></tr></table></figure>
<h5 id="安装kafka："><a href="#安装kafka：" class="headerlink" title="安装kafka："></a>安装kafka：</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar xzvf kafka-0.8.0-beta1-src.tgz -C /opt/kafka/  <span class="comment">#解压kafka到指定目录下</span></div><div class="line"><span class="built_in">cd</span> /opt/kafka/ <span class="comment">#到解压kafka的目录</span></div><div class="line">mv kafka-0.8.0-beta1-src kafka <span class="comment">#重命名</span></div></pre></td></tr></table></figure>
<h2 id="三、修改配置文件"><a href="#三、修改配置文件" class="headerlink" title="三、修改配置文件"></a>三、修改配置文件</h2><h5 id="配置文件目录："><a href="#配置文件目录：" class="headerlink" title="配置文件目录："></a>配置文件目录：</h5><p>kafka的配置文件都存放在/opt/kafka/kafka/config/</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /opt/kafka/kafka/config/ </div><div class="line">ll <span class="comment">#查看kafka所有的配置文件</span></div></pre></td></tr></table></figure>
<h5 id="修改配置文件："><a href="#修改配置文件：" class="headerlink" title="修改配置文件："></a>修改配置文件：</h5><p>主要修改<em>server.properties</em>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">broker.id=0  #当前机器在集群中的唯一标识，和zookeeper的myid性质一样</div><div class="line">port=19092 #当前kafka对外提供服务的端口默认是9092</div><div class="line">host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。</div><div class="line">num.network.threads=3 #这个是borker进行网络处理的线程数</div><div class="line">num.io.threads=8 #这个是borker进行I/O处理的线程数</div><div class="line">log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个</div><div class="line">socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，存储到缓冲区到达一定的大小后再发送，能提高性能</div><div class="line">socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘</div><div class="line">socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小</div><div class="line">num.partitions=1 #默认的分区数，一个topic默认1个分区数</div><div class="line">log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天</div><div class="line">message.max.byte=5242880  #消息保存的最大值5M</div><div class="line">default.replication.factor=2  #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务</div><div class="line">replica.fetch.max.bytes=5242880  #取消息的最大直接数</div><div class="line">log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新建一个文件</div><div class="line">log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除</div><div class="line">log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能</div><div class="line">zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口，与zookeeper的zoo.cfg文件中的clientPort保持一致</div></pre></td></tr></table></figure>
<h2 id="三、开启并使用kafka"><a href="#三、开启并使用kafka" class="headerlink" title="三、开启并使用kafka"></a>三、开启并使用kafka</h2><h5 id="开启kafka服务："><a href="#开启kafka服务：" class="headerlink" title="开启kafka服务："></a>开启kafka服务：</h5><ol>
<li><p>首先要确保已经开启了zookeeper服务:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/opt/zookeeper/zookeeper/bin/zkServer.sh start <span class="comment">#开启zookeeper服务</span></div></pre></td></tr></table></figure>
</li>
<li><p>后台开启kafka：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &amp; <span class="comment">#后台挂起kafka服务 nohup  &amp;</span></div><div class="line">ps -ef | grep java | grep -v grep <span class="comment">#查看当前的java进程，zookeeper与kafka都是基于java</span></div></pre></td></tr></table></figure>
</li>
<li><p>kafka基本操作：</p>
<p>创建topics</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/opt/kafka/bin/kafka-topics.sh --zookeeper 192.168.221.138:2181 --create --topic <span class="built_in">test</span> --replication-factor 1 --partition 1 <span class="comment">#新建主题 连接zookeeper --create 创建主题 --topic 主题名 --replication-factor 副本因子 --partitions 分为几个区</span></div></pre></td></tr></table></figure>
<p>发消息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="built_in">test</span> &gt;/dev/null <span class="comment">#producer发送消息  发送给broker</span></div></pre></td></tr></table></figure>
<p>收消息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic <span class="built_in">test</span> --from-beginning 2&gt;/dev/null <span class="comment">#consumer接收消息 连接zookeeper服务器  --from-beginning 接收历史消息</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><h5 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h5><ol>
<li>开启kafka之前必须要开启zookeeper</li>
<li>注意生产者连接broker 端口号默认9092；消费者连接zookeeper 端口号默认2181</li>
<li>创建主题时，设置分区为集群服务器数的两倍或多倍，可有效避免消息发送和接收的读写热点</li>
</ol>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka-server-properties参数详解]]></title>
      <url>https://stanxia.github.io/2017/02/13/kafka-server-properties%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h1 id="server-properties参数说明"><a href="#server-properties参数说明" class="headerlink" title="server.properties参数说明"></a>server.properties参数说明</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">broker.id=0</td>
<td>每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况</td>
</tr>
<tr>
<td style="text-align:right">log.dirs=/data/kafka-logs</td>
<td>kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能  /data/kafka-logs-1，/data/kafka-logs-2</td>
</tr>
<tr>
<td style="text-align:right">port =9092</td>
<td>broker server服务端口</td>
</tr>
<tr>
<td style="text-align:right">message.max.bytes =6525000</td>
<td>表示消息体的最大大小，单位是字节</td>
</tr>
<tr>
<td style="text-align:right">num.network.threads =4</td>
<td>broker处理消息的最大线程数，一般情况下数量为cpu核数</td>
</tr>
<tr>
<td style="text-align:right">num.io.threads =8</td>
<td>broker处理磁盘IO的线程数，数值为cpu核数2倍</td>
</tr>
<tr>
<td style="text-align:right">background.threads =4</td>
<td>一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改</td>
</tr>
<tr>
<td style="text-align:right">queued.max.requests =500</td>
<td>等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制。</td>
</tr>
<tr>
<td style="text-align:right">host.name</td>
<td>broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK</td>
</tr>
<tr>
<td style="text-align:right">socket.send.buffer.bytes=100*1024</td>
<td>socket的发送缓冲区，socket的调优参数SO_SNDBUFF</td>
</tr>
<tr>
<td style="text-align:right">socket.receive.buffer.bytes =100*1024</td>
<td>socket的接受缓冲区，socket的调优参数SO_RCVBUFF</td>
</tr>
<tr>
<td style="text-align:right">socket.request.max.bytes =100<em>1024</em>1024</td>
<td>socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.segment.bytes =1024<em>1024</em>1024</td>
<td>topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.roll.hours =24*7</td>
<td>这个参数会在日志segment没有达到log.segment.bytes设置的大小，也会强制新建一个segment会被 topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.cleanup.policy = delete</td>
<td>日志清理策略选择有：delete和compact主要针对过期数据的处理，或是日志文件达到限制的额度，会被 topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.retention.bytes=-1</td>
<td>topic每个分区的最大文件大小，一个topic的大小限制 = 分区数*log.retention.bytes。-1没有大小限log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.retention.check.interval.ms=5minutes</td>
<td>文件大小检查的周期时间，是否处罚 log.cleanup.policy中设置的策略</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.enable=<strong>false</strong></td>
<td>是否开启日志清理</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.threads = 2</td>
<td>日志清理运行的线程数</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.max.bytes.per.second=None</td>
<td>日志清理时候处理的最大大小</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.dedupe.buffer.size=500<em>1024</em>1024</td>
<td>日志清理去重时候的缓存空间，在空间允许的情况下，越大越好</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.buffer.size=512*1024</td>
<td>日志清理时候用到的IO块大小一般不需要修改</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.buffer.load.factor =0.9</td>
<td>日志清理中hash表的扩大因子一般不需要修改</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.backoff.ms =15000</td>
<td>检查是否处罚日志清理的间隔</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.min.cleanable.ratio=0.5</td>
<td>日志清理的频率控制，越大意味着更高效的清理，同时会存在一些空间上的浪费，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.delete.retention.ms =1day</td>
<td>对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，同log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据。会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.index.size.max.bytes =10<em>1024</em>1024</td>
<td>对于segment日志的索引文件大小限制，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.index.interval.bytes =4096</td>
<td>当执行一个fetch操作后，需要一定的空间来扫描最近的offset大小，设置越大，代表扫描速度越快，但是也更好内存，一般情况下不需要搭理这个参数</td>
</tr>
<tr>
<td style="text-align:right">log.flush.interval.messages=None</td>
<td>log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性”的必要手段,所以此参数的设置,需要在<strong>“**</strong>数据可靠性<strong>**”</strong>与”性能”之间做必要的权衡.如果此值过大,将会导致每次”fsync”的时间较长(IO阻塞),如果此值过小,将会导致<strong>“fsync”</strong>的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失.</td>
</tr>
<tr>
<td style="text-align:right">log.flush.scheduler.interval.ms =3000</td>
<td>检查是否需要固化到硬盘的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">log.flush.interval.ms = None</td>
<td>仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制<strong>“fsync”</strong>的时间间隔,如果消息量始终没有达到阀值,但是离上一次磁盘同步的时间间隔达到阀值,也将触发.</td>
</tr>
<tr>
<td style="text-align:right">log.delete.delay.ms =60000</td>
<td>文件在索引中清除后保留的时间一般不需要去修改</td>
</tr>
<tr>
<td style="text-align:right">log.flush.offset.checkpoint.interval.ms =60000</td>
<td>控制上次固化硬盘的时间点，以便于数据恢复一般不需要去修改</td>
</tr>
<tr>
<td style="text-align:right">auto.create.topics.enable =<strong>true</strong></td>
<td>是否允许自动创建topic，若是<strong>false</strong>，就需要通过命令创建topic</td>
</tr>
<tr>
<td style="text-align:right"><strong>default</strong>.replication.factor =1</td>
<td>默认副本因子</td>
</tr>
<tr>
<td style="text-align:right">num.partitions =1</td>
<td>每个topic的分区个数，若是在topic创建时候没有指定的话会被topic创建时的指定参数覆盖</td>
</tr>
</tbody>
</table>
<h1 id="以下是Leader，replicas配置"><a href="#以下是Leader，replicas配置" class="headerlink" title="以下是Leader，replicas配置"></a>以下是Leader，replicas配置</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">controller.message.queue.size=10</td>
<td>partition leader与replicas数据同步时,消息的队列尺寸</td>
</tr>
<tr>
<td style="text-align:right">controller.socket.timeout.ms =30000</td>
<td>partition leader与replicas之间通讯时,socket的超时时间</td>
</tr>
<tr>
<td style="text-align:right">replica.lag.time.max.ms =10000</td>
<td>replicas响应partition leader的最长等待时间，若是超过这个时间，就将replicas列入ISR(in-sync replicas)，并认为它是死的，不会再加入管理中</td>
</tr>
<tr>
<td style="text-align:right">replica.lag.max.messages =4000</td>
<td>如果follower落后与leader太多,将会认为此follower[或者说partition relicas]已经失效， 通常,在follower与leader通讯时,因为网络延迟或者链接断开,总会导致replicas中消息同步滞后， 如果消息之后太多,leader将认为此follower网络延迟较大或者消息吞吐能力有限,将会把此replicas迁移， 到其他follower中， 在broker数量较少,或者网络不足的环境中,建议提高此值.</td>
</tr>
<tr>
<td style="text-align:right">replica.socket.timeout.ms=30*1000</td>
<td>follower与leader之间的socket超时时间</td>
</tr>
<tr>
<td style="text-align:right">replica.socket.receive.buffer.bytes=64*1024</td>
<td>leader复制时候的socket缓存大小</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.max.bytes =1024*1024</td>
<td>replicas每次获取数据的最大大小</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.wait.max.ms =500</td>
<td>replicas同leader之间通信的最大等待时间，失败了会重试</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.min.bytes =1</td>
<td>fetch的最小数据尺寸,如果leader中尚未同步的数据不足此值,将会阻塞,直到满足条件</td>
</tr>
<tr>
<td style="text-align:right">num.replica.fetchers=1</td>
<td>leader进行复制的线程数，增大这个数值会增加follower的IO</td>
</tr>
<tr>
<td style="text-align:right">replica.high.watermark.checkpoint.interval.ms =5000</td>
<td>每个replica检查是否将最高水位进行固化的频率</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.enable =<strong>false</strong></td>
<td>是否允许控制器关闭broker ,若是设置为<strong>true</strong>,会关闭所有在这个broker上的leader，并转移到其他broker</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.max.retries =3</td>
<td>控制器关闭的尝试次数</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.retry.backoff.ms =5000</td>
<td>每次关闭尝试的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">leader.imbalance.per.broker.percentage =10</td>
<td>leader的不平衡比例，若是超过这个数值，会对分区进行重新的平衡</td>
</tr>
<tr>
<td style="text-align:right">leader.imbalance.check.interval.seconds =300</td>
<td>检查leader是否不平衡的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">offset.metadata.max.bytes</td>
<td>客户端保留offset信息的最大空间大小</td>
</tr>
</tbody>
</table>
<h1 id="kafka中zookeeper参数配置"><a href="#kafka中zookeeper参数配置" class="headerlink" title="kafka中zookeeper参数配置"></a>kafka中zookeeper参数配置</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">zookeeper.connect = localhost:2181</td>
<td>zookeeper集群的地址，可以是多个，多个之间用逗号分割hostname1:port1,hostname2:port2,hostname3:port3</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.session.timeout.ms=6000</td>
<td>ZooKeeper的最大超时时间，就是心跳的间隔，若是没有反映，那么认为已经死了，不易过大</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.connection.timeout.ms =6000</td>
<td>ZooKeeper的连接超时时间</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.sync.time.ms =2000</td>
<td>ZooKeeper集群中leader和follower之间的同步时间</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[第一阶段项目所用知识点]]></title>
      <url>https://stanxia.github.io/2017/02/12/%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E9%A1%B9%E7%9B%AE%E6%89%80%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>在hive外部执行hive语句，可多条语句一起执行<br>hive -e ‘’</p>
<p>查看表结构：<br>desc tablename;</p>
<p>查看详细表结构：<br>desc formatted tablename;</p>
<p>创建表：</p>
<p>CREATE TABLE IF NOT EXISTS   xls.bank_xls(<br>name STRING,<br>cost INT<br>)<br>PARTITIONED BY (date STRING)<br>ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘ ‘;</p>
<p>创建一张和目标表结构一样的表<br>CREATE TABLE IF NOT EXISTS xls.bank_xls LIKE wy.bank_wy;</p>
<p>删除表：<br>DROP TABLE IF EXISTS xls.bank_xls;</p>
<p>清空表数据，但不删除表：<br>TRUNCATE TABLE xls.bank_xlsx;</p>
<p>导入本地数据到hive表中：<br>LOAD DATA INPATH ‘/tmp/xls/20170103_customer_tx.txt’ OVERWRITE INTO TABLE xls.bank_xls PARTITION (date=to_date(‘20170103’));</p>
<p>查看表中的内容：<br>SLELCT * FROM xls.bank_xls;</p>
<p>SELECT name,sum(cost) FROM xls.bank_xls WHERE date=’20170105’ GROUP BY name;</p>
<p>hdfs dfs -ls /user/hive/warehouse/xls.db/bank_xls</p>
<p>hadoop jar /root/makebankrecord.jar MakeBankRecord</p>
<p>hive -e “LOAD DATA LOCAL INPATH ‘/home/xls/‘“</p>
<p>文件监听器<br>nohup hadoop jar filemonitor.jar FileChangeMain /home/xls/ &amp;</p>
<p>#获取到输出的结构<br><code>ps -ef | grep $1 | grep -v grep | awk &#39;{print $1}&#39;</code></p>
<p>指定某用户的crontab操作<br>crontab -u xls -e  编辑xls用户的crontab<br>crontab -u xls -r 删除xls用户的crontab</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[zookeeper集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/12/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><h5 id="服务器准备："><a href="#服务器准备：" class="headerlink" title="服务器准备："></a>服务器准备：</h5><p>Linxu服务器2*n+1台，最好是奇数台服务器，因为 zookeeper集群的机制是选举制度，需要超过半数才能对外提供服务。</p>
<h5 id="jdk环境："><a href="#jdk环境：" class="headerlink" title="jdk环境："></a>jdk环境：</h5><p>zookeeper底层是用java写的，所以需要jdk环境。jdk环境的安装在之前几篇文章中已经说过，这里就不赘述了。</p>
<h5 id="下载zookeeper："><a href="#下载zookeeper：" class="headerlink" title="下载zookeeper："></a>下载zookeeper：</h5><p><a href="http://www.apache.org/dyn/closer.cgi/zookeeper/" target="_blank" rel="external">点我下载zookeeper</a></p>
<p>或者直接在服务器上面下载：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz</div></pre></td></tr></table></figure>
<h2 id="二、安装zookeeper"><a href="#二、安装zookeeper" class="headerlink" title="二、安装zookeeper"></a>二、安装zookeeper</h2><p>首先确定好zookeeper的目录结构，避免在项目过多的时候找不到所需的项目。</p>
<p>在这里博主统一把所有组件都安装在/opt下的。</p>
<h5 id="创建zookeeper-项目目录："><a href="#创建zookeeper-项目目录：" class="headerlink" title="创建zookeeper 项目目录："></a>创建zookeeper 项目目录：</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir -r /opt/zookeeper  <span class="comment">#创建zookeeper项目目录</span></div><div class="line">mkdir -r /opt/zookeeper/zkdata <span class="comment">#存放快照日志</span></div><div class="line">mkdir -r /opt/zookeeper/zkdatalog <span class="comment">#存放事务日志</span></div></pre></td></tr></table></figure>
<h5 id="解压："><a href="#解压：" class="headerlink" title="解压："></a>解压：</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf zookeeper-3.4.6.tar.gz -C /opt/zookeeper  <span class="comment">#解压到/opt/zookeeper下</span></div><div class="line">mv zookeeper-3.4.6 zookeeper <span class="comment">#重命名</span></div></pre></td></tr></table></figure>
<h2 id="三、修改配置文件"><a href="#三、修改配置文件" class="headerlink" title="三、修改配置文件"></a>三、修改配置文件</h2><p>zookeeper的相关配置都在zoo.cfg文件中。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /opt/zookeeper/zookeeper/conf/ <span class="comment">#进入conf目录</span></div><div class="line">ll <span class="comment">#查看配置文件</span></div><div class="line">cp zoo_sample.cfg zoo.cfg <span class="comment">#复制并更名为zoo.cfg，zookeeper指定的命名规范为zoo.cfg</span></div></pre></td></tr></table></figure>
<h5 id="修改zoo-cfg"><a href="#修改zoo-cfg" class="headerlink" title="修改zoo.cfg:"></a>修改zoo.cfg:</h5><p><code>vi zoo.cfg #设置如下属性：</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">tickTime=2000 <span class="comment">#用于配置zookeeper中的最小时间单元的长度。默认为3000ms，很多运行时的时间间隔都是tickTime的倍数。例如：zookeeper中会话的最小超时时间默认为2*tickTime.</span></div><div class="line">initLimit=10 <span class="comment">#默认为10，表示参数tickTime的10倍。用于配置Leader服务器等待Follower启动并完成数据同步的时间。Leader允许Follower在initLimit时间内与Leader完成连接并数据同步。</span></div><div class="line">syncLimit=5 <span class="comment">#默认5，表示参数tickTime的5倍。用于配置Leader与Follower之间心跳连接的最长延时时间。如果Leader在syncLimit时间内无法获取到Follower的心跳检测相应，则会认为该Follower已经脱离了和自己的同步。</span></div><div class="line">dataDir=/opt/zookeeper/zkdata <span class="comment">#无默认值，必须配置。用于配置存放快照文件的目录。如果没有配置参数dataLogDir属性，那么会默认把日志文件存在该目录下。所以最好设置dataLogDir参数。</span></div><div class="line">dataLogDir=/opt/zookeeper/zkdatalog <span class="comment">#zookeeper存放日志的目录。</span></div><div class="line">clientPort=2181  <span class="comment">#必须配置。用于配置该服务器对外的服务端口。客户端会通过该服务端口语zookeeper服务器创建连接，一般设置为2181。每台服务器都可以随意设置该端口号，同个集群中的每个服务器也可以设置不同的端口号。</span></div><div class="line"><span class="comment">#server.id=host:port:port 无默认值。用于配置集群中的服务器列表。id为ServerID,与myid文件中的保持一致，用于辨识这是哪一台服务器，所以必须要唯一。第一个端口用于指定Follower与Leader之间通信和数据同步的端口。第二个端口专门用于Leader选举的投票端口。</span></div><div class="line">server.1=192.168.7.100:12888:13888 </div><div class="line">server.2=192.168.7.101:12888:13888</div><div class="line">server.3=192.168.7.107:12888:13888</div></pre></td></tr></table></figure>
<h5 id="创建myid文件："><a href="#创建myid文件：" class="headerlink" title="创建myid文件："></a>创建myid文件：</h5><p>myid文件用于存放当前服务器的ServerID，即当前服务器的唯一标识，必须唯一。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">echo</span> <span class="string">"ServerId"</span>&gt;&gt;/opt/zookeeper/zkdata/myid <span class="comment">#存放在zkdata下，ServerID必须与zoo.cfg中的id保持一致。</span></div></pre></td></tr></table></figure>
<h2 id="四、启动zookeeper"><a href="#四、启动zookeeper" class="headerlink" title="四、启动zookeeper"></a>四、启动zookeeper</h2><h5 id="启动服务："><a href="#启动服务：" class="headerlink" title="启动服务："></a>启动服务：</h5><p>进入到zookeeper/bin目录下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /opt/zookeeper/zookeeper/bin/ <span class="comment">#进入zookeeper/bin目录下</span></div><div class="line">./zkServer.sh start <span class="comment">#启动zookeeper服务，集群所有的服务器都需要开启</span></div></pre></td></tr></table></figure>
<h5 id="检查服务器状态："><a href="#检查服务器状态：" class="headerlink" title="检查服务器状态："></a>检查服务器状态：</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./zkServer.sh status <span class="comment">#查看zookeeper服务器状态</span></div></pre></td></tr></table></figure>
<h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><h5 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h5><ol>
<li>注意创建zkdata与zkdatalog文件夹用于存放数据与日志。如果没有设置zkdatalog，zookeeper会默认把日志都存放在zkdata中，但是这样会严重影响zookeeper的性能。作为性能调优的地方，最好将zkdatalog设置在单独的磁盘中。</li>
<li>注意各个端口的设置，如果不使用默认的端口，尽量设置大端口号，以免端口冲突。TCP能设置的最大端口号：65535</li>
<li>注意设置ServerID的时候，一定要保证唯一，否则将不能识别该服务器。</li>
</ol>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[cdh集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/11/cdh%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>1.如果存在jdk：<br>卸载方式：rpm -qa | grep jdk<br>rpm -e —nodeps 加上上面返回的结构</p>
<p>2.安装jdk：<br>rpm -ivh jdk-7u80-linux-x64.rpm </p>
<p>3.配置hostname<br>vi /etc/sysconfig/network<br>NETWORKING=yes<br>HOSTNAME=master</p>
<p>4.vi /etc/hostname</p>
<p>#删除文件内容  ,然后输入<br>master</p>
<p>5.修改host映射<br>vi /etc/hosts</p>
<p>10.211.55.9 master</p>
<p>#ipDress1为master服务器的IP地址</p>
<p>6.selinux 关闭<br>vi /etc/sysconfig/selinux<br>SELINUX=disable</p>
<p>7.重启<br>reboot</p>
<p>8.更改防火墙<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld</p>
<p>9.安装时间同步服务<br>yum -y install ntp<br>vi /etc/ntp.conf</p>
<p>#注释掉所有的server<em>.</em>.* 的指向 ，新添加一条可连接的ntp服务器<br>server ntp.sjtu.edu.cn iburst</p>
<p>#启动时间同步服务<br>service ntpd start </p>
<p>#执行命令<br>ntpdate -u 1.asia.pool.ntp.org</p>
<p>#重启时间同步服务<br>service ntpd restart</p>
<p>10.ssh无密码登陆配置<br>ssh-keygen -t rsa #一直使用默认</p>
<p>11.安装mysql</p>
<p>#查看mysql是否意境安装：<br>rpm -qa | grep mariadb </p>
<p>#如果存在：<br>cd </p>
<p>#安装mysql依赖：<br>yum install -y perl-Module-Install.noarch</p>
<p>unzip <strong>.zip<br>rpm -ivh </strong>.rpm </p>
<p>#修改配置文件目录<br>cp /usr/share/mysql/my-default.cnf /etc/my.cnf</p>
<p>#在配置文件中增加以下配置并保存：<br>vi /etc/my.cnf<br>default-storage-engine = innodb<br>innodb_file_per_table<br>collation-server = utf8_general_ci<br>init-connect = ‘SET NAMES utf8’<br>character-set-server=utf8</p>
<p>#初始化数据库执行：<br>/usr/bin/mysql_install_db</p>
<p>#开启mysql服务：<br>service mysql restart</p>
<p>#查看mysql root 初始化密码：<br>cat /root/.mysql_secret</p>
<p>T1STjiM6A1TXQB5p</p>
<p>#登陆mysql：<br>mysql -u root -p<br>SET PASSWORD=PASSWORD(‘123456’)#复制root的初始密码<br>mysql下面执行：<br>SET PASSWORDcd /=PASSWORD(‘123456’)</p>
<p>#linux开启开机启动：<br>chkconfig mysql on</p>
<p>#linux下面执行 拷贝mysql-connector-java-5.1.25-bin.jar 到/usr/share/java/mysql-connector-java.jar</p>
<p>#创建数据库：<br>mysql<br>create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database monitor DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;</p>
<p>use mysql;<br>grant all on <em>.</em> to root@‘master’ Identified by ‘123456’;<br>flush privileges;</p>
<p>12.安装cloudera-manager</p>
<p>#解压cm tar 包到指定目录<br>mkdir /opt/cloudera-manager<br>tar -zxvf cloudier-manager-centos7-cm5.6.0_x86_64.tar.gz -C<br>/opt/cloudera-manager</p>
<p>#创建cloudera-scm用户：<br>[root@master cloudera-manager]# useradd –system –home=/opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-server–no-create-home –shell=/bin/false –comment “Cloudera SCM User” cloudera-scm</p>
<p>#在注解点创建cloudera-manager-server的本地元数据保存目录<br>mkdir /var/cloudera-scm-server<br>chown cloudera-scm:cloudera-scm /var/cloudera-scm-server<br>chown cloudera-scm:cloudera-scm /opt/cloudera-manager</p>
<p>#配置从节点cloudera-manager-agent 指向注解点服务器<br>vi /opt/cloudera-manager/cm-5.6.0/etc/cloudera-scm-agent/config.ini</p>
<p>#将server host改为CMS所在的主机名即master</p>
<p>#注解点中创建parcel-repo 仓库目录：<br>mkdir -p /opt/cloudera/parcel-repo<br>chown cloudera-scm:cloudera-scm/opt/cloudera/parcel-repo<br>cp CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel  CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel.sha   manifest.json /opt/cloudera/parcel-repo</p>
<p>#所有节点创建parcel目录：<br>mkdir -p /opt/cloudera/parcels<br>chown cloudera-scm:cloudera-scm/opt/cloudera/parcels</p>
<p>13.初始化脚本配置数据库：<br>/opt/cloudera-manager/cm-5.6.0/share/cmf/schema/scm_prepare_database.sh mysql -hmaster -uroot -p123456 —sim-host master scmdbn scmdbu scmdbp</p>
<p>14.启动注解点cloudera scm server<br>cp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-server  /etc/init.d/cloudera-scm-server</p>
<p>#修改变量路径：<br>vi /etc/init.d/cloudera-scm-server</p>
<p>将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default</p>
<p>chkconfig cloudera-scm-server on</p>
<p>#启动注解点cloudera scm server</p>
<p>mkdir /opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-agent<br>cp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent</p>
<p>#修改变量路径：<br>vi /etc/init.d/cloudera-scm-agent</p>
<p>#将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default</p>
<p>chkconfig cloudera-scm-agent on</p>
<p>service cloudera-scm-server start</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop原生集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/11/hadoop%E5%8E%9F%E7%94%9F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="一：解压hadoop-tar-gz和jdk安装包"><a href="#一：解压hadoop-tar-gz和jdk安装包" class="headerlink" title="一：解压hadoop.tar.gz和jdk安装包"></a>一：解压hadoop.tar.gz和jdk安装包</h2><ol>
<li><p>将hadoop和jdk解压在/opt目录下面</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -zxvf jdk1.8.gz -C /opt/  <span class="comment">#解压jdk到/opt下</span></div><div class="line">tar -zxvf hadoop-2.6.0.tar.gz -C /opt/ <span class="comment">#解压hadoop到/opt</span></div></pre></td></tr></table></figure>
</li>
<li><p>在/opt目录下面修改 Hadoop和jdk 名字（非必需，只是为了后续的操作方便）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mv hadoop-2.6.0 hadoop <span class="comment">#hadoop文件夹重命名</span></div><div class="line">mv jdk1.8 jdk <span class="comment">#jdk文件夹重命名</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="二：设置SSH互信："><a href="#二：设置SSH互信：" class="headerlink" title="二：设置SSH互信："></a>二：设置SSH互信：</h2><ol>
<li><p>在每台服务器上面设置SSH无密码登录：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t rsa -p <span class="string">''</span> <span class="comment">#-t rsa 表示通过rsa 算法处理 ；-p '' 设置密码为‘’ 即为空</span></div></pre></td></tr></table></figure>
</li>
<li><p>拷贝每台服务器上面的 idrsa.pub ：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> ~ <span class="comment">#到当前用户目录</span></div><div class="line"><span class="built_in">cd</span> .ssh <span class="comment">#到存放idrsa.pub 的目录</span></div><div class="line">scp idrsa.pub hadoop@master:/home/hadoop/.ssh/ <span class="comment">#所有服务器上面的idrsa.pub都传给master</span></div><div class="line">touch authorized_keys <span class="comment">#matsr新建authorized_keys文件，存放所有服务器的idrsa.pub公匙</span></div><div class="line">scp authorized_keys hadoop@slave1:/home/hadoop/.ssh/ <span class="comment">#将authorized_keys复制给集群中的所有服务器</span></div></pre></td></tr></table></figure>
</li>
<li><p>试试效果：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh slave1 <span class="comment">#如果不需要输密码，则证明配置成功；若配置失败，再进行一次第二步操作</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="三：修改配置文件："><a href="#三：修改配置文件：" class="headerlink" title="三：修改配置文件："></a>三：修改配置文件：</h2><ol>
<li><p>修改/etc/profile配置java hadoop环境变量</p>
<p><code>vi /etc/profile</code></p>
<p>添加如下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/opt/jdk1.8</div><div class="line">export HADOOP_HOME=/opt/hadoop</div><div class="line">export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin</div></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/hostname（重启生效）</p>
<p><code>vi /etc/hostname</code></p>
<p>添加该机的服务器名（例如namenode所在的服务器就写 master）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">master</div></pre></td></tr></table></figure>
</li>
<li><p>配置 /etc/hosts（重启生效）</p>
<p><code>vi /etc/hosts</code></p>
<p>配置集群所有服务器的IP与hostname映射关系：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">192.168.1.121 master</div><div class="line">192.168.1.122 slave1</div><div class="line">192.168.1.123 slave2</div></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/sysconfig/network</p>
<p><code>vi /etc/sysconfig/network</code></p>
<p>添加如下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">NETWORKING=yes</div><div class="line">HOSTNAME=master</div></pre></td></tr></table></figure>
</li>
<li><p>关闭防火墙(必须关闭防火墙，否则会出现很多问题)</p>
<p>直接在命令行执行以下代码：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">systemctl stop firewalld <span class="comment">#关闭防火墙</span></div><div class="line">systemctl <span class="built_in">disable</span> firewalld <span class="comment">#防火墙下线</span></div><div class="line">systemctl status firewalld <span class="comment">#查看防火墙状态（dead为已关闭）</span></div></pre></td></tr></table></figure>
</li>
<li><p>添加hadoop用户</p>
<p>root用户执行以下代码：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">adduser hadoop <span class="comment">#添加hadoop用户</span></div><div class="line">passwd hadoop <span class="comment">#修改密码</span></div><div class="line">usermod -g root hadoop <span class="comment">#将hadoop用户放在root组</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>monsterxls:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.ipc.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:50020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:50075<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://monsterxls:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
<li><p>配置hadoop-env.sh</p>
<p><code>export JAVA_HOME=/opt/jdk1.8</code></p>
</li>
</ol>
<ol>
<li><p>配置yarn-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export HADOOP_YARN_USER=/opt/hadoop</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="三：总结"><a href="#三：总结" class="headerlink" title="三：总结"></a>三：总结</h2><p>安装集群要细心，理解着意思去安装，特别是配置文件，想想为什么要这么设置，出了问题多看看配置文件，检查是否有误设置的地方。</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[ssh互信]]></title>
      <url>https://stanxia.github.io/2017/02/11/ssh%E4%BA%92%E4%BF%A1/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>1.ssh-keygen -t rsa -P ‘’<br>-t  rsa表示通过rsa算法<br>-P表示设置密码</p>
<p>cd .ssh :包含文件  idrsa为密匙   idrsa.pub为公钥</p>
<p> 如果当前使用的用户时hadoop，当使用ssh切换时默认的是到hadoop用户 ，可以使用ssh root@hadoop </p>
<p>2.跨机器传输：<br>scp 文件 hadoop@hadoop1:/目标路径</p>
<p>scp idrsa.pub hadoop@hadoop1:/home/hadoop/<br>文件夹为：scp -r …</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[CAD破解]]></title>
      <url>https://stanxia.github.io/2017/01/26/CAD%E7%A0%B4%E8%A7%A3/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>CAD制图软件pojie方式。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p><a href="https://www.rkdot.com/autodesk-autocad-2017/" target="_blank" rel="external">点我看看原博</a></p>
<h5 id="破解"><a href="#破解" class="headerlink" title="破解"></a>破解</h5><ol>
<li><p>运行破解包中的AutoCAD_2017_English_Win_64bit_dlm_001_002.sfx.exe进行解压安装Autodesk 2017.</p>
</li>
<li><p>安装完重启</p>
</li>
<li><p>运行Autodesk 2017</p>
</li>
<li><p>提示注册，选择“Enter a Serial Number”</p>
</li>
<li><p>使用一下序列号：</p>
<pre><code>666-69696969, 667-98989898, 400-45454545或者066-66666666，产品密钥为001I1
</code></pre></li>
<li><p>断开网络，点击Next</p>
</li>
<li><p>会提示需要网络连接，选择离线激活（第二个选项）</p>
</li>
<li><p>重点步骤：</p>
<p>8.1 管理员身份运行注册机，点击Patch,此时会看到successfully patched；</p>
<p>8.2 拷贝请求码（Request cod））到注册机中，然后点击Generate，生成激活码（Activation）；</p>
<p>8.3 拷贝激活码（Activation）到软件注册窗口完成注册。</p>
</li>
</ol>
<h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><p><a href="https://pan.baidu.com/s/1c2eO9sk" target="_blank" rel="external">点我下载</a></p>
<p>密码: yuux</p>
<p>Good Luck!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[chrome离线恐龙快跑游戏]]></title>
      <url>https://stanxia.github.io/2017/01/18/chrome%E7%A6%BB%E7%BA%BF%E6%81%90%E9%BE%99%E5%BF%AB%E8%B7%91%E6%B8%B8%E6%88%8F/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="游戏介绍"><a href="#游戏介绍" class="headerlink" title="游戏介绍"></a>游戏介绍</h2><p>来源自Google chrome 浏览器没有网络状态下的小彩蛋。</p>
<h2 id="安装指南"><a href="#安装指南" class="headerlink" title="安装指南"></a>安装指南</h2><ol>
<li><p>右键<a href="https://unpkg.com/t-rex-runner/dist/runner.js" style="text-decoration:none" target="_blank" rel="external">这里</a>存储连接下载源码</p>
</li>
<li><p>将下载的js文件放置在source/js/下面</p>
</li>
<li><p>在页面上添加如下代码即可：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"/js/runner.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></div><div class="line"> initRunner('#container');</div><div class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="食用指南"><a href="#食用指南" class="headerlink" title="食用指南"></a>食用指南</h2><p>手机端：点触屏幕即可开始和操作。</p>
<p>电脑端：点击小恐龙，按空格键即可开始和操作。</p>
<p><div id="container"></div></p>
<script src="/js/runner.js"></script>
<script>
 initRunner('#container');
</script>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[这个杀手不太冷]]></title>
      <url>https://stanxia.github.io/2017/01/17/%E8%BF%99%E4%B8%AA%E6%9D%80%E6%89%8B%E4%B8%8D%E5%A4%AA%E5%86%B7/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><iframe src="https://www.bilibili.com/html/html5player.html?aid=3209983&cid=5061993" width="640" height="480" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[海贼王856“少骗人了”]]></title>
      <url>https://stanxia.github.io/2017/01/16/%E6%B5%B7%E8%B4%BC%E7%8E%8B856%E2%80%9C%E5%B0%91%E9%AA%97%E4%BA%BA%E4%BA%86%E2%80%9D/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="不定期转更！"><a href="#不定期转更！" class="headerlink" title="不定期转更！"></a>不定期转更！</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;center&gt;</div><div class="line">&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 </div><div class="line">	src=&quot;http://music.163.com/outchain/player?type=2&amp;id=25706282&amp;auto=0&amp;height=66&quot;&gt;</div><div class="line">&lt;/iframe&gt;	</div><div class="line">&lt;/center&gt;</div></pre></td></tr></table></figure>
<center><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" ​="" src="//music.163.com/outchain/player?type=2&id=4938705&auto=1&height=66"></iframe></center>

<script>



if ("xls123456"==prompt("通关密码"))

{alert("芝麻开门");

}else{alert("容我再想想");

location="https://stanxia.github.io/";

}

</script>

<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspiw6k1lj20nm10477f.jpg" alt="0"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspiwqlrgj20nm11idmk.jpg" alt="1"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspixckxcj20nm12w7d2.jpg" alt="2"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspiy4maoj20nm12w0zh.jpg" alt="3"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcspiz1vddj20nm12wqf7.jpg" alt="4"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcspj0kwx2j20nm12wdr2.jpg" alt="5"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspj1hwmuj20nm12wais.jpg" alt="6"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcspj29rp5j20nm12w4ad.jpg" alt="7"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspj361rjj20nm12wamg.jpg" alt="8"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspkakevtj20nm12wqdm.jpg" alt="9"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkawqlij20nm12wk2j.jpg" alt="10"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspkbin2pj20nm12wwob.jpg" alt="11"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspkcp79pj20nm12w12g.jpg" alt="12"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspkcuitqj20nm12w7cn.jpg" alt="13"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkdmvg9j20nm12wk2s.jpg" alt="14"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkekdunj20nm12wn72.jpg" alt="15"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkeudsbj20nm12w7eu.jpg" alt="16"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspkg862wj20nm12wtht.jpg" alt="17"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[接入bilibili视频播放]]></title>
      <url>https://stanxia.github.io/2017/01/15/%E6%B5%8B%E8%AF%95%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="测试视频播放"><a href="#测试视频播放" class="headerlink" title="测试视频播放"></a>测试视频播放</h2><p>接入bilibili的视频，只需要在md文档中添加如下代码即可：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">iframe</span> <span class="attr">src</span>=<span class="string">"https://www.bilibili.com/html/html5player.html?aid=3521416&amp;cid=6041635"</span> <span class="attr">width</span>=<span class="string">"640"</span> <span class="attr">height</span>=<span class="string">"480"</span> <span class="attr">frameborder</span>=<span class="string">"0"</span> <span class="attr">webkitallowfullscreen</span> <span class="attr">mozallowfullscreen</span> <span class="attr">allowfullscreen</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></div></pre></td></tr></table></figure>
<p>其中aid和cid在bilibili网页上都可以爬出来。</p>
<p>效果如下：</p>
<iframe src="https://www.bilibili.com/html/html5player.html?aid=3521416&cid=6041635" width="640" height="480" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[利用微博作为图床]]></title>
      <url>https://stanxia.github.io/2017/01/15/%E5%88%A9%E7%94%A8%E5%BE%AE%E5%8D%9A%E4%BD%9C%E4%B8%BA%E5%9B%BE%E5%BA%8A/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h3 id="上传图片"><a href="#上传图片" class="headerlink" title="上传图片"></a>上传图片</h3><ol>
<li><p>登陆微博，右上角点击发布微博</p>
</li>
<li><p>选择图片上传，选择需要上传的图片</p>
</li>
<li><p>右键图片，复制图片网络链接</p>
</li>
<li><p>将图片网址作为图片地址应用到网站中</p>
<p><img src="http://wx1.sinaimg.cn/mw690/6aae3cf3gy1fcr3nqql3pj20rm0rcdgj.jpg" alt="test"></p>
</li>
</ol>
]]></content>
    </entry>
    
  
  
</search>
