<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[利用微博作为图床]]></title>
      <url>https://stanxia.github.io/2017/02/15/%E5%88%A9%E7%94%A8%E5%BE%AE%E5%8D%9A%E4%BD%9C%E4%B8%BA%E5%9B%BE%E5%BA%8A/</url>
      <content type="html"><![CDATA[<h3 id="上传图片"><a href="#上传图片" class="headerlink" title="上传图片"></a>上传图片</h3><ol>
<li>登陆微博，右上角点击发布微博</li>
<li>选择图片上传，选择需要上传的图片</li>
<li>右键图片，复制图片网络链接</li>
<li><a href="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcr3nqql3pj20rm0rcdgj.jpg" target="_blank" rel="external">http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcr3nqql3pj20rm0rcdgj.jpg</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[完善ntp时间同步]]></title>
      <url>https://stanxia.github.io/2017/02/14/%E5%AE%8C%E5%96%84ntp%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/</url>
      <content type="html"><![CDATA[<h1 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h1><p>ntp同步时间过长</p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>修改 /etc/ntp.conf</p>
<p>主节点配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">server ntp7.aliyun.com iburst</div><div class="line">restrict ntp7.aliyun.com nomodify notrap noquery</div></pre></td></tr></table></figure>
<p>从节点配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">restrict hadoop1(主机名) nomodify notrap noquery</div><div class="line">server hadoop1(主机名) iburst</div></pre></td></tr></table></figure>
<h1 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h1><p>ntp时间同步之后，显示非中国时区</p>
<h1 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</div></pre></td></tr></table></figure>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[zookeeper启动时数组越界异常]]></title>
      <url>https://stanxia.github.io/2017/02/14/zookeeper%E5%90%AF%E5%8A%A8%E6%97%B6%E6%95%B0%E7%BB%84%E8%B6%8A%E7%95%8C%E5%BC%82%E5%B8%B8/</url>
      <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p><img src="zk-aoi.png" alt=""></p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>修改 ／zookeeper/conf/zoo.cfg文件<br>修改端口号<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi /zookeeper/conf/zoo.cfg</div></pre></td></tr></table></figure></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka-server-properties参数详解]]></title>
      <url>https://stanxia.github.io/2017/02/13/kafka-server-properties%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h1 id="server-properties参数说明"><a href="#server-properties参数说明" class="headerlink" title="server.properties参数说明"></a>server.properties参数说明</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">broker.id=0</td>
<td>每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况</td>
</tr>
<tr>
<td style="text-align:right">log.dirs=/data/kafka-logs</td>
<td>kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能  /data/kafka-logs-1，/data/kafka-logs-2</td>
</tr>
<tr>
<td style="text-align:right">port =9092</td>
<td>broker server服务端口</td>
</tr>
<tr>
<td style="text-align:right">message.max.bytes =6525000</td>
<td>表示消息体的最大大小，单位是字节</td>
</tr>
<tr>
<td style="text-align:right">num.network.threads =4</td>
<td>broker处理消息的最大线程数，一般情况下数量为cpu核数</td>
</tr>
<tr>
<td style="text-align:right">num.io.threads =8</td>
<td>broker处理磁盘IO的线程数，数值为cpu核数2倍</td>
</tr>
<tr>
<td style="text-align:right">background.threads =4</td>
<td>一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改</td>
</tr>
<tr>
<td style="text-align:right">queued.max.requests =500</td>
<td>等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制。</td>
</tr>
<tr>
<td style="text-align:right">host.name</td>
<td>broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK</td>
</tr>
<tr>
<td style="text-align:right">socket.send.buffer.bytes=100*1024</td>
<td>socket的发送缓冲区，socket的调优参数SO_SNDBUFF</td>
</tr>
<tr>
<td style="text-align:right">socket.receive.buffer.bytes =100*1024</td>
<td>socket的接受缓冲区，socket的调优参数SO_RCVBUFF</td>
</tr>
<tr>
<td style="text-align:right">socket.request.max.bytes =100<em>1024</em>1024</td>
<td>socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.segment.bytes =1024<em>1024</em>1024</td>
<td>topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.roll.hours =24*7</td>
<td>这个参数会在日志segment没有达到log.segment.bytes设置的大小，也会强制新建一个segment会被 topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.cleanup.policy = delete</td>
<td>日志清理策略选择有：delete和compact主要针对过期数据的处理，或是日志文件达到限制的额度，会被 topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.retention.bytes=-1</td>
<td>topic每个分区的最大文件大小，一个topic的大小限制 = 分区数*log.retention.bytes。-1没有大小限log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.retention.check.interval.ms=5minutes</td>
<td>文件大小检查的周期时间，是否处罚 log.cleanup.policy中设置的策略</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.enable=<strong>false</strong></td>
<td>是否开启日志清理</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.threads = 2</td>
<td>日志清理运行的线程数</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.max.bytes.per.second=None</td>
<td>日志清理时候处理的最大大小</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.dedupe.buffer.size=500<em>1024</em>1024</td>
<td>日志清理去重时候的缓存空间，在空间允许的情况下，越大越好</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.buffer.size=512*1024</td>
<td>日志清理时候用到的IO块大小一般不需要修改</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.buffer.load.factor =0.9</td>
<td>日志清理中hash表的扩大因子一般不需要修改</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.backoff.ms =15000</td>
<td>检查是否处罚日志清理的间隔</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.min.cleanable.ratio=0.5</td>
<td>日志清理的频率控制，越大意味着更高效的清理，同时会存在一些空间上的浪费，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.delete.retention.ms =1day</td>
<td>对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，同log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据。会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.index.size.max.bytes =10<em>1024</em>1024</td>
<td>对于segment日志的索引文件大小限制，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.index.interval.bytes =4096</td>
<td>当执行一个fetch操作后，需要一定的空间来扫描最近的offset大小，设置越大，代表扫描速度越快，但是也更好内存，一般情况下不需要搭理这个参数</td>
</tr>
<tr>
<td style="text-align:right">log.flush.interval.messages=None</td>
<td>log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性”的必要手段,所以此参数的设置,需要在<strong>“**</strong>数据可靠性<strong>**”</strong>与”性能”之间做必要的权衡.如果此值过大,将会导致每次”fsync”的时间较长(IO阻塞),如果此值过小,将会导致<strong>“fsync”</strong>的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失.</td>
</tr>
<tr>
<td style="text-align:right">log.flush.scheduler.interval.ms =3000</td>
<td>检查是否需要固化到硬盘的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">log.flush.interval.ms = None</td>
<td>仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制<strong>“fsync”</strong>的时间间隔,如果消息量始终没有达到阀值,但是离上一次磁盘同步的时间间隔达到阀值,也将触发.</td>
</tr>
<tr>
<td style="text-align:right">log.delete.delay.ms =60000</td>
<td>文件在索引中清除后保留的时间一般不需要去修改</td>
</tr>
<tr>
<td style="text-align:right">log.flush.offset.checkpoint.interval.ms =60000</td>
<td>控制上次固化硬盘的时间点，以便于数据恢复一般不需要去修改</td>
</tr>
<tr>
<td style="text-align:right">auto.create.topics.enable =<strong>true</strong></td>
<td>是否允许自动创建topic，若是<strong>false</strong>，就需要通过命令创建topic</td>
</tr>
<tr>
<td style="text-align:right"><strong>default</strong>.replication.factor =1</td>
<td>默认副本因子</td>
</tr>
<tr>
<td style="text-align:right">num.partitions =1</td>
<td>每个topic的分区个数，若是在topic创建时候没有指定的话会被topic创建时的指定参数覆盖</td>
</tr>
</tbody>
</table>
<h1 id="以下是Leader，replicas配置"><a href="#以下是Leader，replicas配置" class="headerlink" title="以下是Leader，replicas配置"></a>以下是Leader，replicas配置</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">controller.message.queue.size=10</td>
<td>partition leader与replicas数据同步时,消息的队列尺寸</td>
</tr>
<tr>
<td style="text-align:right">controller.socket.timeout.ms =30000</td>
<td>partition leader与replicas之间通讯时,socket的超时时间</td>
</tr>
<tr>
<td style="text-align:right">replica.lag.time.max.ms =10000</td>
<td>replicas响应partition leader的最长等待时间，若是超过这个时间，就将replicas列入ISR(in-sync replicas)，并认为它是死的，不会再加入管理中</td>
</tr>
<tr>
<td style="text-align:right">replica.lag.max.messages =4000</td>
<td>如果follower落后与leader太多,将会认为此follower[或者说partition relicas]已经失效， 通常,在follower与leader通讯时,因为网络延迟或者链接断开,总会导致replicas中消息同步滞后， 如果消息之后太多,leader将认为此follower网络延迟较大或者消息吞吐能力有限,将会把此replicas迁移， 到其他follower中， 在broker数量较少,或者网络不足的环境中,建议提高此值.</td>
</tr>
<tr>
<td style="text-align:right">replica.socket.timeout.ms=30*1000</td>
<td>follower与leader之间的socket超时时间</td>
</tr>
<tr>
<td style="text-align:right">replica.socket.receive.buffer.bytes=64*1024</td>
<td>leader复制时候的socket缓存大小</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.max.bytes =1024*1024</td>
<td>replicas每次获取数据的最大大小</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.wait.max.ms =500</td>
<td>replicas同leader之间通信的最大等待时间，失败了会重试</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.min.bytes =1</td>
<td>fetch的最小数据尺寸,如果leader中尚未同步的数据不足此值,将会阻塞,直到满足条件</td>
</tr>
<tr>
<td style="text-align:right">num.replica.fetchers=1</td>
<td>leader进行复制的线程数，增大这个数值会增加follower的IO</td>
</tr>
<tr>
<td style="text-align:right">replica.high.watermark.checkpoint.interval.ms =5000</td>
<td>每个replica检查是否将最高水位进行固化的频率</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.enable =<strong>false</strong></td>
<td>是否允许控制器关闭broker ,若是设置为<strong>true</strong>,会关闭所有在这个broker上的leader，并转移到其他broker</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.max.retries =3</td>
<td>控制器关闭的尝试次数</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.retry.backoff.ms =5000</td>
<td>每次关闭尝试的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">leader.imbalance.per.broker.percentage =10</td>
<td>leader的不平衡比例，若是超过这个数值，会对分区进行重新的平衡</td>
</tr>
<tr>
<td style="text-align:right">leader.imbalance.check.interval.seconds =300</td>
<td>检查leader是否不平衡的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">offset.metadata.max.bytes</td>
<td>客户端保留offset信息的最大空间大小</td>
</tr>
</tbody>
</table>
<h1 id="kafka中zookeeper参数配置"><a href="#kafka中zookeeper参数配置" class="headerlink" title="kafka中zookeeper参数配置"></a>kafka中zookeeper参数配置</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">zookeeper.connect = localhost:2181</td>
<td>zookeeper集群的地址，可以是多个，多个之间用逗号分割hostname1:port1,hostname2:port2,hostname3:port3</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.session.timeout.ms=6000</td>
<td>ZooKeeper的最大超时时间，就是心跳的间隔，若是没有反映，那么认为已经死了，不易过大</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.connection.timeout.ms =6000</td>
<td>ZooKeeper的连接超时时间</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.sync.time.ms =2000</td>
<td>ZooKeeper集群中leader和follower之间的同步时间</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka安装与简单的应用]]></title>
      <url>https://stanxia.github.io/2017/02/13/kafka%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>安装</p>
<h1 id="tar-xzvf-kafka-0-8-0-beta1-src-tgz"><a href="#tar-xzvf-kafka-0-8-0-beta1-src-tgz" class="headerlink" title="tar xzvf kafka-0.8.0-beta1-src.tgz"></a>tar xzvf kafka-0.8.0-beta1-src.tgz</h1><h1 id="cd-kafka-0-8-0-beta1-src"><a href="#cd-kafka-0-8-0-beta1-src" class="headerlink" title="cd kafka-0.8.0-beta1-src"></a>cd kafka-0.8.0-beta1-src</h1><h1 id="sbt-update"><a href="#sbt-update" class="headerlink" title="./sbt update"></a>./sbt update</h1><h1 id="sbt-package"><a href="#sbt-package" class="headerlink" title="./sbt package"></a>./sbt package</h1><h1 id="sbt-assembly-package-dependency"><a href="#sbt-assembly-package-dependency" class="headerlink" title="./sbt assembly-package-dependency"></a>./sbt assembly-package-dependency</h1><p>首先开启zookeeper服务，因为kafka是基于zookeeper<br>nohup /opt/kafka/bin/zookeeper-server-start.sh  /opt/kafka/config/zookeeper.properties &amp;</p>
<p>再开启kafka<br>nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &amp;</p>
<p>ps -ef | grep kafka | grep -v grep</p>
<p>ps -ef | grep zookeeper | grep -v grep</p>
<p>创建topics<br>/opt/kafka/bin/kafka-topics.sh –zookeeper 192.168.221.138:2181 –create –topic test –replication-factor 1 –partition 1</p>
<p>发消息<br>bin/kafka-console-producer.sh –broker-list localhost:9092 –topic test &gt;/dev/null</p>
<p>收消息<br> bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test –from-beginning 2&gt;/dev/null</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[第一阶段项目所用知识点]]></title>
      <url>https://stanxia.github.io/2017/02/12/%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E9%A1%B9%E7%9B%AE%E6%89%80%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      <content type="html"><![CDATA[<p>在hive外部执行hive语句，可多条语句一起执行<br>hive -e ‘’</p>
<p>查看表结构：<br>desc tablename;</p>
<p>查看详细表结构：<br>desc formatted tablename;</p>
<p>创建表：</p>
<p>CREATE TABLE IF NOT EXISTS   xls.bank_xls(<br>name STRING,<br>cost INT<br>)<br>PARTITIONED BY (date STRING)<br>ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘ ‘;</p>
<p>创建一张和目标表结构一样的表<br>CREATE TABLE IF NOT EXISTS xls.bank_xls LIKE wy.bank_wy;</p>
<p>删除表：<br>DROP TABLE IF EXISTS xls.bank_xls;</p>
<p>清空表数据，但不删除表：<br>TRUNCATE TABLE xls.bank_xlsx;</p>
<p>导入本地数据到hive表中：<br>LOAD DATA INPATH ‘/tmp/xls/20170103_customer_tx.txt’ OVERWRITE INTO TABLE xls.bank_xls PARTITION (date=to_date(‘20170103’));</p>
<p>查看表中的内容：<br>SLELCT * FROM xls.bank_xls;</p>
<p>SELECT name,sum(cost) FROM xls.bank_xls WHERE date=’20170105’ GROUP BY name;</p>
<p>hdfs dfs -ls /user/hive/warehouse/xls.db/bank_xls</p>
<p>hadoop jar /root/makebankrecord.jar MakeBankRecord</p>
<p>hive -e “LOAD DATA LOCAL INPATH ‘/home/xls/‘“</p>
<p>文件监听器<br>nohup hadoop jar filemonitor.jar FileChangeMain /home/xls/ &amp;</p>
<p>#获取到输出的结构<br><code>ps -ef | grep $1 | grep -v grep | awk &#39;{print $1}&#39;</code></p>
<p>指定某用户的crontab操作<br>crontab -u xls -e  编辑xls用户的crontab<br>crontab -u xls -r 删除xls用户的crontab</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[cdh集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/11/cdh%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>1.如果存在jdk：<br>卸载方式：rpm -qa | grep jdk<br>rpm -e —nodeps 加上上面返回的结构</p>
<p>2.安装jdk：<br>rpm -ivh jdk-7u80-linux-x64.rpm </p>
<p>3.配置hostname<br>vi /etc/sysconfig/network<br>NETWORKING=yes<br>HOSTNAME=master</p>
<p>4.vi /etc/hostname</p>
<p>#删除文件内容  ,然后输入<br>master</p>
<p>5.修改host映射<br>vi /etc/hosts</p>
<p>10.211.55.9 master</p>
<p>#ipDress1为master服务器的IP地址</p>
<p>6.selinux 关闭<br>vi /etc/sysconfig/selinux<br>SELINUX=disable</p>
<p>7.重启<br>reboot</p>
<p>8.更改防火墙<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld</p>
<p>9.安装时间同步服务<br>yum -y install ntp<br>vi /etc/ntp.conf</p>
<p>#注释掉所有的server<em>.</em>.* 的指向 ，新添加一条可连接的ntp服务器<br>server ntp.sjtu.edu.cn iburst</p>
<p>#启动时间同步服务<br>service ntpd start </p>
<p>#执行命令<br>ntpdate -u 1.asia.pool.ntp.org</p>
<p>#重启时间同步服务<br>service ntpd restart</p>
<p>10.ssh无密码登陆配置<br>ssh-keygen -t rsa #一直使用默认</p>
<p>11.安装mysql</p>
<p>#查看mysql是否意境安装：<br>rpm -qa | grep mariadb </p>
<p>#如果存在：<br>cd </p>
<p>#安装mysql依赖：<br>yum install -y perl-Module-Install.noarch</p>
<p>unzip <strong>.zip<br>rpm -ivh </strong>.rpm </p>
<p>#修改配置文件目录<br>cp /usr/share/mysql/my-default.cnf /etc/my.cnf</p>
<p>#在配置文件中增加以下配置并保存：<br>vi /etc/my.cnf<br>default-storage-engine = innodb<br>innodb_file_per_table<br>collation-server = utf8_general_ci<br>init-connect = ‘SET NAMES utf8’<br>character-set-server=utf8</p>
<p>#初始化数据库执行：<br>/usr/bin/mysql_install_db</p>
<p>#开启mysql服务：<br>service mysql restart</p>
<p>#查看mysql root 初始化密码：<br>cat /root/.mysql_secret</p>
<p>T1STjiM6A1TXQB5p</p>
<p>#登陆mysql：<br>mysql -u root -p<br>SET PASSWORD=PASSWORD(‘123456’)#复制root的初始密码<br>mysql下面执行：<br>SET PASSWORDcd /=PASSWORD(‘123456’)</p>
<p>#linux开启开机启动：<br>chkconfig mysql on</p>
<p>#linux下面执行 拷贝mysql-connector-java-5.1.25-bin.jar 到/usr/share/java/mysql-connector-java.jar</p>
<p>#创建数据库：<br>mysql<br>create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database monitor DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;</p>
<p>use mysql;<br>grant all on <em>.</em> to root@‘master’ Identified by ‘123456’;<br>flush privileges;</p>
<p>12.安装cloudera-manager</p>
<p>#解压cm tar 包到指定目录<br>mkdir /opt/cloudera-manager<br>tar -zxvf cloudier-manager-centos7-cm5.6.0_x86_64.tar.gz -C<br>/opt/cloudera-manager</p>
<p>#创建cloudera-scm用户：<br>[root@master cloudera-manager]# useradd –system –home=/opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-server–no-create-home –shell=/bin/false –comment “Cloudera SCM User” cloudera-scm</p>
<p>#在注解点创建cloudera-manager-server的本地元数据保存目录<br>mkdir /var/cloudera-scm-server<br>chown cloudera-scm:cloudera-scm /var/cloudera-scm-server<br>chown cloudera-scm:cloudera-scm /opt/cloudera-manager</p>
<p>#配置从节点cloudera-manager-agent 指向注解点服务器<br>vi /opt/cloudera-manager/cm-5.6.0/etc/cloudera-scm-agent/config.ini</p>
<p>#将server host改为CMS所在的主机名即master</p>
<p>#注解点中创建parcel-repo 仓库目录：<br>mkdir -p /opt/cloudera/parcel-repo<br>chown cloudera-scm:cloudera-scm/opt/cloudera/parcel-repo<br>cp CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel  CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel.sha   manifest.json /opt/cloudera/parcel-repo</p>
<p>#所有节点创建parcel目录：<br>mkdir -p /opt/cloudera/parcels<br>chown cloudera-scm:cloudera-scm/opt/cloudera/parcels</p>
<p>13.初始化脚本配置数据库：<br>/opt/cloudera-manager/cm-5.6.0/share/cmf/schema/scm_prepare_database.sh mysql -hmaster -uroot -p123456 —sim-host master scmdbn scmdbu scmdbp</p>
<p>14.启动注解点cloudera scm server<br>cp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-server  /etc/init.d/cloudera-scm-server</p>
<p>#修改变量路径：<br>vi /etc/init.d/cloudera-scm-server</p>
<p>将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default</p>
<p>chkconfig cloudera-scm-server on</p>
<p>#启动注解点cloudera scm server</p>
<p>mkdir /opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-agent<br>cp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent</p>
<p>#修改变量路径：<br>vi /etc/init.d/cloudera-scm-agent</p>
<p>#将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default</p>
<p>chkconfig cloudera-scm-agent on</p>
<p>service cloudera-scm-server start</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop原生集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/11/hadoop%E5%8E%9F%E7%94%9F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>配置yarn-site.xml</p>
<property><br>   <name>yarn.nodemanager.aux-services</name><br>   <value>mapreduce_shuffle</value><br></property>


<p>配置mapred-site.xml</p>
<property><br>   <name>mapreduce.framework.name</name><br>   <value>yarn</value><br></property><br><property><br>   <name>mapreduce.jobhistory.address</name><br>   <value>monsterxls:10020</value><br></property><br><property><br>   <name>mapreduce.jobhistory.webapp.address</name><br>   <value>monsterxls:19888</value><br></property>

<p>配置hdfs-site.xml</p>
<property><br>   <name>dfs.replication</name><br>   <value>2</value><br></property><br><property><br>   <name>dfs.datanode.ipc.address</name><br>   <value>0.0.0.0:50020</value><br></property><br><property><br>   <name>dfs.datanode.http.address</name><br>   <value>0.0.0.0:50075</value><br></property>


<p>配置core-site.xml</p>
<property><br>   <name>fs.default.name</name><br>   <value>hdfs://monsterxls:9000</value><br></property><br><property><br>   <name>hadoop.tmp.dir</name><br>   <value>/opt/tmp</value><br></property>


<p>配置hadoop-env.sh<br>export JAVA_HOME=/opt/jdk1.8</p>
<p>配置yarn-env.sh<br>export HADOOP_YARN_USER=/opt/hadoopL</p>
<p>配置/etc/profile:jdk hadoop环境变量</p>
<p>echo ‘export JAVA_HOME=/opt/jdk1.8’ &gt;&gt;/etc/profile<br>echo ‘export HADOOP_HOME=/opt/hadoop’ &gt;&gt;/etc/profile<br>echo ‘export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin’ &gt;&gt;/etc/profile<br>source /etc/profile</p>
<p>配置/etc/ntp.conf时间同步<br>yum -y install ntp<br>server ntp7.aliyun.com  iburst</p>
<p>service ntpd start<br>ntpdate -u ntp7.aliyun.com<br>service ntpd restart<br>ntpstat</p>
<p>192.168.221.136 monsterxls<br>192.168.221.135 slave1xls<br>192.168.221.137 slave2xls<br>配置/etc/hostname,/etc/hosts<br>echo ‘monsterxls’ &gt;/etc/hostname<br>echo ‘192.168.221.136 monsterxls’ &gt;&gt;/etc/hosts</p>
<p>配置/etc/sysconfig/network<br>echo ‘NETWORKING=yes’ &gt;&gt;/etc/sysconfig/network<br>echo ‘HOSTNAME=slave2xls’ &gt;&gt;/etc/sysconfig/network</p>
<p>关闭防火墙<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld</p>
<p>添加hadoop用户<br>adduser hadoop<br>passwd hadoop<br>将hadoop用户放在root组<br>usermod -g root hadoop </p>
<p>解压hadoop.tar.gz和jdk<br>tar -zxvf jdk1.8.gz -C /opt/<br>tar -zxvf hadoop-2.6.0.tar.gz -C /opt/</p>
<p>ssh相互通信<br>ssh-keygen -t rsa -P ‘’<br>scp -r id_rsa.pub root@slave1xls:/home/hadoop/.ssh/<br>authorized_keys</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[ssh互信]]></title>
      <url>https://stanxia.github.io/2017/02/11/ssh%E4%BA%92%E4%BF%A1/</url>
      <content type="html"><![CDATA[<p>1.ssh-keygen -t rsa -P ‘’<br>-t  rsa表示通过rsa算法<br>-P表示设置密码</p>
<p>cd .ssh :包含文件  idrsa为密匙   idrsa.pub为公钥</p>
<p> 如果当前使用的用户时hadoop，当使用ssh切换时默认的是到hadoop用户 ，可以使用ssh root@hadoop </p>
<p>2.跨机器传输：<br>scp 文件 hadoop@hadoop1:/目标路径</p>
<p>scp idrsa.pub hadoop@hadoop1:/home/hadoop/<br>文件夹为：scp -r …</p>
]]></content>
    </entry>
    
  
  
</search>
