<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Hive与Impala]]></title>
      <url>https://stanxia.github.io/2017/02/23/Hive%E4%B8%8EImpala/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="HiveQl执行过程："><a href="#HiveQl执行过程：" class="headerlink" title="HiveQl执行过程："></a>HiveQl执行过程：</h2><p>==》驱动模块<br>==》编译器进行编译  Antlr<br>==》优化器进行优化<br>==》执行器执行（执行map reduce任务）   全表扫描* 不会执行 map reduce 任务</p>
<h2 id="HiveQL查询的-MapReduce-作业转化流程："><a href="#HiveQL查询的-MapReduce-作业转化流程：" class="headerlink" title="HiveQL查询的 MapReduce 作业转化流程："></a>HiveQL查询的 MapReduce 作业转化流程：</h2><p>==》用户输入sql<br>==》抽象语法树 AST Tree<br>==》查询块 QueryBlock<br>==》逻辑查询计划  OperatorTree<br>==》重写逻辑查询计划<br>==》物理计划<br>==》选择最优的优化查询策略<br>==》输出</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fd0twkpnl9j20t2104wjn.jpg" alt="1"></p>
<h2 id="Impala与Hive的区别："><a href="#Impala与Hive的区别：" class="headerlink" title="Impala与Hive的区别："></a>Impala与Hive的区别：</h2><p>1.Hive适合长时间的批处理查询分析；Impala适合实时的sql查询<br>2.Hive依赖于MapReduce，执行计划组合成管道形的MapReduce任务模式；Impala执行计划表现为一颗完整的执行计划树<br>3.Hive在查询过程中，内存不够用时会使用外存；Impala在内存不够用时，不会使用外存，所有Impala在查询的时候会存在一定的限制</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fd0twll2zoj20qc0myn04.jpg" alt="2"></p>
<h2 id="Impala与Hive的相同点："><a href="#Impala与Hive的相同点：" class="headerlink" title="Impala与Hive的相同点："></a>Impala与Hive的相同点：</h2><p>1.使用相同的存储数据池，都支持 HDFS,HBase<br>2.使用相同的元数据<br>3.对SQL的解释处理比较相似，都是通过 语法分析 生成执行计划</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HBase1.3新版本 新特性预览]]></title>
      <url>https://stanxia.github.io/2017/02/22/HBase1-3%E6%96%B0%E7%89%88%E6%9C%AC-%E6%96%B0%E7%89%B9%E6%80%A7%E9%A2%84%E8%A7%88/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="新版本特性"><a href="#新版本特性" class="headerlink" title="新版本特性"></a>新版本特性</h2><p>2017年1月中旬 发布的 HBase 1.3.0版本，新版本特性如下：</p>
<ul>
<li>支持分层数据的压缩</li>
<li>多方面的性能提升，如 多预写日志（WAL）一个新的RPC机制，避免大量IO峰值的磁盘刷新吞吐量控制器等</li>
</ul>
<h2 id="新特性解析"><a href="#新特性解析" class="headerlink" title="新特性解析"></a>新特性解析</h2><h3 id="分层压缩"><a href="#分层压缩" class="headerlink" title="分层压缩"></a>分层压缩</h3><h5 id="使用场景："><a href="#使用场景：" class="headerlink" title="使用场景："></a>使用场景：</h5><p>数据被铲除或更新的时候，通常要更频繁的扫描最新的数据，而旧数据则较少被扫描。</p>
<h5 id="解决痛点："><a href="#解决痛点：" class="headerlink" title="解决痛点："></a>解决痛点：</h5><p>使用这种分层压缩策略，可有轻松的记录文件的TTL(生存时间 time-to-live)；当将现有存储文件压缩到单个较大的存储文件中时，过期的记录将被删除。</p>
<h3 id="多预写日志"><a href="#多预写日志" class="headerlink" title="多预写日志"></a>多预写日志</h3><p>每个region server都有一个预写日志(WAL)，该区域上的所有操作都要写入这个唯一的预写日志。</p>
<h5 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h5><p>改进后的 <strong>多预写日志(WAL)</strong> 支持更高性能的写入操作，这使得复制速度更快而且同步写入的延迟更低。默认情况下，多预写日志 提供了三个区域分组策略来分配 预写日志：每个区域的 预写日志都有 一个身份 标识，轮询调度算法 保证 每个区域映射的预写日志 都有其边界，区域中 不同 命名空间 的表 被映射到 不同的 预写日志 中。</p>
<p>性能测试报告 显示：<strong>预写日志 在纯SATA 磁盘中的运行平均延时 减少了 20% ；在SATA-SSD磁盘中运行延时 减少了 40%</strong>。</p>
<h3 id="新的RPC调度器"><a href="#新的RPC调度器" class="headerlink" title="新的RPC调度器"></a>新的RPC调度器</h3><p>新的RPC调度器基于 <strong>CoDel算法</strong> ，用于阻止 可用IO无法满足过高清秋频率引起的 长连接队列。</p>
<p>CoDel算法 用可控的延迟 来管理 活动队列，他根据 定义好的 <strong>阈值</strong> 来裁决队列中的<strong>最小延迟</strong>。一旦最小延迟超过阈值，该链接便会 被丢弃以便处理其他更有力的 最小延迟。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[IntelliJ Idea编译报错：javacTask: 源发行版 1.8 需要目标发行版 1.8]]></title>
      <url>https://stanxia.github.io/2017/02/21/IntelliJ-Idea%E7%BC%96%E8%AF%91%E6%8A%A5%E9%94%99%EF%BC%9AjavacTask-%E6%BA%90%E5%8F%91%E8%A1%8C%E7%89%88-1-7-%E9%9C%80%E8%A6%81%E7%9B%AE%E6%A0%87%E5%8F%91%E8%A1%8C%E7%89%88-1-7/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题一：java-compiler-error"><a href="#问题一：java-compiler-error" class="headerlink" title="问题一：java compiler error"></a>问题一：java compiler error</h2><p>运行java程序时，编译报错：java compiler error，如下图所示：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jlezsnj214m08ytaq.jpg" alt="1"></p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>打开idea设置=&gt;&gt;Build,Execution,Deployment=&gt;&gt;Compiler=&gt;&gt;Java Compiler=&gt;&gt;左边框Pre-module bytecode version =&gt;&gt;找到程序所在的模块=&gt;&gt;Target Bytecode version 选择提示中的需要目标发行版本=&gt;&gt;Apply=&gt;&gt;ok,如下图所示：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jpf2uzj21kw0x6q9o.jpg" alt="2"></p>
<h2 id="问题二：Usage-of-API-documented-as-since-1-6-1-7-…"><a href="#问题二：Usage-of-API-documented-as-since-1-6-1-7-…" class="headerlink" title="问题二：Usage of API documented as  @since 1.6/1.7/…"></a>问题二：Usage of API documented as  @since 1.6/1.7/…</h2><p>当使用了一些api之后，idea会提示Usage of API documented as  @since 1.6/1.7/…如下图所示：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jq6pbnj20t809wwga.jpg" alt="3"></p>
<h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><p>右键项目=&gt;&gt;open module setting=&gt;&gt;Laguage Level =&gt;&gt;选择（大于或等于）提示中@since的版本，如下图所示：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcy0jpvbxfj21kw0xzahh.jpg" alt="4"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[经典大数据架构案例：酷狗音乐的大数据平台重构]]></title>
      <url>https://stanxia.github.io/2017/02/21/%E7%BB%8F%E5%85%B8%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E6%A1%88%E4%BE%8B%EF%BC%9A%E9%85%B7%E7%8B%97%E9%9F%B3%E4%B9%90%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E9%87%8D%E6%9E%84/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>编者按：本文是酷狗音乐的架构师王劲对酷狗大数据架构重构的总结。酷狗音乐的大数据架构本身很经典，而这篇讲解了对原来的架构上进行重构的工作内容，总共分为重构的原因、新一代的大数据技术架构、踩过的坑、后续持续改进四个部分来给大家谈酷狗音乐大数据平台重构的过程。</p>
<p>眨眼就新的一年了，时间过的真快，趁这段时间一直在写总结的机会，也总结下上一年的工作经验，避免重复踩坑。酷狗音乐大数据平台重构整整经历了一年时间，大头的行为流水数据迁移到新平台稳定运行，在这过程中填过坑，挖过坑，为后续业务的实时计算需求打下了很好的基础。在此感谢酷狗团队成员的不懈努力，大部分从开始只知道大数据这个概念，到现在成为团队的技术支柱，感到很欣慰。</p>
<p>从重构原因，技术架构，踩过的坑，后续持续改进四个方面来描述酷狗音乐大数据平台重构的过程，在此抛砖引玉，这次的内容与6月份在高可用架构群分享的大数据技术实践的有点不同，技术架构做了些调整。</p>
<p>其实大数据平台是一个庞大的系统工程，整个建设周期很长，涉及的生态链很长(包括：数据采集、接入，清洗、存储计算、数据挖掘，可视化等环节，每个环节都可以当做一个复杂的系统来建设)，风险也很大。</p>
<h2 id="一、重构原因"><a href="#一、重构原因" class="headerlink" title="一、重构原因"></a>一、重构原因</h2><p>在讲重构原因前，先介绍下原有的大数据平台架构，如下图：</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2flakmj20at07j0tr.jpg" alt="1"></p>
<p>从上图可知，主要基于Hadoop1.x+hive做离线计算(T+1)，基于大数据平台的数据采集、数据接入、数据清洗、作业调度、平台监控几个环节存在的一些问题来列举下。</p>
<p>数据采集：</p>
<ol>
<li>数据收集接口众多，且数据格式混乱，基本每个业务都有自己的上报接口</li>
<li>存在较大的重复开发成本</li>
<li>不能汇总上报，消耗客户端资源，以及网络流量</li>
<li>每个接口收集数据项和格式不统一，加大后期数据统计分析难度</li>
<li>各个接口实现质量并不高，存在被刷，泄密等风险</li>
</ol>
<p>数据接入:</p>
<ol>
<li>通过rsync同步文件，很难满足实时流计算的需求</li>
<li>接入数据出现异常后，很难排查及定位问题，需要很高的人力成本排查</li>
<li>业务系统数据通过Kettle每天全量同步到数据中心，同步时间长，导致依赖的作业经常会有延时现象</li>
</ol>
<p>数据清洗：</p>
<ol>
<li>ETL集中在作业计算前进行处理</li>
<li>存在重复清洗</li>
</ol>
<p>作业调度：</p>
<ol>
<li>大部分作业通过crontab调度，作业多了后不利于管理</li>
<li>经常出现作业调度冲突</li>
</ol>
<p>平台监控：</p>
<ol>
<li>只有硬件与操作系统级监控</li>
<li>数据平台方面的监控等于空白</li>
</ol>
<p>基于以上问题，结合在大数据中，数据的时效性越高，数据越有价值(如：实时个性化推荐系统，RTB系统，实时预警系统等)的理念，因此，开始大重构数据平台架构。</p>
<h2 id="二、新一代大数据技术架构"><a href="#二、新一代大数据技术架构" class="headerlink" title="二、新一代大数据技术架构"></a>二、新一代大数据技术架构</h2><p>在讲新一代大数据技术架构前，先讲下大数据特征与大数据技术要解决的问题。</p>
<p>1.大数据特征：“大量化(Volume)、多样化(Variety)、快速化(Velocity)、价值密度低（Value）”就是“大数据”显著的4V特征，或者说，只有具备这些特点的数据，才是大数据。</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2gw02gj20jp0cxwjl.jpg" alt="2"></p>
<p>2.大数据技术要解决的问题：大数据技术被设计用于在成本可承受的条件下，通过非常快速（velocity）地采集、发现和分析，从大量（volumes）、多类别（variety）的数据中提取价值（value），将是IT领域新一代的技术与架构。</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2iu0jpj20kb0d4tbj.jpg" alt="3"></p>
<p>介绍了大数据的特性及大数据技术要解决的问题，我们先看看新一代大数据技术架构的数据流架构图：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2k4hl5j20k50cldkv.jpg" alt="4"></p>
<p>从这张图中，可以了解到大数据处理过程可以分为数据源、数据接入、数据清洗、数据缓存、存储计算、数据服务、数据消费等环节，每个环节都有具有高可用性、可扩展性等特性，都为下一个节点更好的服务打下基础。整个数据流过程都被数据质量监控系统监控，数据异常自动预警、告警。</p>
<p>新一代大数据整体技术架构如图：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2lvooaj20kc0dmq6e.jpg" alt="5"></p>
<p>将大数据计算分为实时计算与离线计算，在整个集群中，奔着能实时计算的，一定走实时计算流处理，通过实时计算流来提高数据的时效性及数据价值，同时减轻集群的资源使用率集中现象。</p>
<p>整体架构从下往上解释下每层的作用：</p>
<p>数据实时采集：</p>
<p>主要用于数据源采集服务，从数据流架构图中，可以知道，数据源分为前端日志，服务端日志，业务系统数据。下面讲解数据是怎么采集接入的。</p>
<p>a.前端日志采集接入：</p>
<p>前端日志采集要求实时，可靠性，高可用性等特性。技术选型时，对开源的数据采集工具flume,scribe,chukwa测试对比，发现基本满足不了我们的业务场景需求。所以，选择基于kafka开发一套数据采集网关，来完成数据采集需求。数据采集网关的开发过程中走了一些弯路，最后采用nginx+lua开发，基于lua实现了kafka生产者协议。有兴趣同学可以<a href="https://github.com/doujiang24/lua-resty-kafka" target="_blank" rel="external">去Github上看看</a>，另一同事实现的，现在在github上比较活跃，被一些互联网公司应用于线上环境了。</p>
<p>b.后端日志采集接入：</p>
<p>FileCollect,考虑到很多线上环境的环境变量不能改动，为减少侵入式，目前是采用Go语言实现文件采集，年后也准备重构这块。</p>
<p>前端，服务端的数据采集整体架构如下图：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2ndr1vj20ku0fugo3.jpg" alt="6"></p>
<p>c.业务数据接入</p>
<p>利用<a href="http://agapple.iteye.com/blog/1796633" target="_blank" rel="external">Canal</a>通过MySQL的binlog机制实时同步业务增量数据。</p>
<p>数据统一接入：为了后面数据流环节的处理规范，所有的数据接入数据中心，必须通过数据采集网关转换统一上报给Kafka集群，避免后端多种接入方式的处理问题。</p>
<p>数据实时清洗(ETL)：为了减轻存储计算集群的资源压力及数据可重用性角度考虑，把数据解压、解密、转义，部分简单的补全，异常数据处理等工作前移到数据流中处理，为后面环节的数据重用打下扎实的基础(实时计算与离线计算)。</p>
<p>数据缓存重用：为了避免大量数据流(400+亿条/天)写入HDFS，导致HDFS客户端不稳定现象及数据实时性考虑，把经过数据实时清洗后的数据重新写入Kafka并保留一定周期，离线计算(批处理)通过KG-Camus拉到HDFS(通过作业调度系统配置相应的作业计划)，实时计算基于Storm/JStorm直接从Kafka消费，有很完美的解决方案storm-kafka组件。</p>
<p>离线计算(批处理)：通过spark，spark SQL实现，整体性能比hive提高5—10倍，hive脚本都在转换为Spark/Spark SQL；部分复杂的作业还是通过Hive/Spark的方式实现。在离线计算中大部分公司都会涉及到数据仓库的问题，酷狗音乐也不例外，也有数据仓库的概念，只是我们在做存储分层设计时弱化了数据仓库概念。数据存储分层模型如下图：</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2ombcpj20ff0cl0tx.jpg" alt="7"></p>
<p>大数据平台数据存储模型分为：数据缓冲层Data Cache Layer（DCL）、数据明细层Data Detail Layer（DDL）、公共数据层（Common）、数据汇总层Data Summary Layer（DSL）、数据应用层Data Application Layer（DAL）、数据分析层（Analysis）、临时提数层（Temp）。</p>
<p>1）数据缓冲层(DCL)：存储业务系统或者客户端上报的，经过解码、清洗、转换后的原始数据，为数据过滤做准备。</p>
<p>2)数据明细层（DDL）：存储接口缓冲层数据经过过滤后的明细数据。</p>
<p>3）公共数据层（Common）：主要存储维表数据与外部业务系统数据。</p>
<p>4）数据汇总层（DSL）：存储对明细数据，按业务主题，与公共数据层数据进行管理后的用户行为主题数据、用户行为宽表数据、轻量汇总数据等。为数据应用层统计计算提供基础数据。数据汇总层的数据永久保存在集群中。</p>
<p>5）数据应用层（DAL）：存储运营分析（Operations Analysis ）、指标体系（Metrics System）、线上服务（Online Service）与用户分析（User Analysis）等。需要对外输出的数据都存储在这一层。主要基于热数据部分对外提供服务，通过一定周期的数据还需要到DSL层装载查询。</p>
<p>6）数据分析层（Analysis）：存储对数据明细层、公共数据层、数据汇总层关联后经过算法计算的、为推荐、广告、榜单等数据挖掘需求提供中间结果的数据。</p>
<p>7）临时提数层（Temp）：存储临时提数、数据质量校验等生产的临时数据。</p>
<p>实时计算：基于Storm/JStorm，<a href="http://www.drools.org/" target="_blank" rel="external">Drools</a>,<a href="http://blog.csdn.net/luonanqin/article/category/1557469" target="_blank" rel="external">Esper</a>。主要应用于实时监控系统、APM、数据实时清洗平台、实时DAU统计等。</p>
<p>HBase/MySQL：用于实时计算，离线计算结果存储服务。</p>
<p>Redis：用于中间计算结果存储或字典数据等。</p>
<p>Elasticsearch：用于明细数据实时查询及HBase的二级索引存储(这块目前在数据中心还没有大规模使用，有兴趣的同学可以加入我们一起玩ES)。</p>
<p>Druid：目前用于支持大数据集的快速即席查询(ad-hoc)。</p>
<p>数据平台监控系统：数据平台监控系统包括基础平台监控系统与数据质量监控系统，数据平台监控系统分为2大方向，宏观层面和微观层面。宏观角度的理解就是进程级别,拓扑结构级别,拿Hadoop举例，如：DataNode，NameNode，JournalNode，ResourceManager，NodeManager，主要就是这5大组件，通过分析这些节点上的监控数据，一般你能够定位到慢节点，可能某台机器的网络出问题了，或者说某台机器执行的时间总是大于正常机器等等这样类似的问题。刚刚说的另一个监控方向，就是微观层面，就是细粒度化的监控，基于user用户级别，基于单个job，单个task级别的监控，像这类监控指标就是另一大方向，这类的监控指标在实际的使用场景中特别重要，一旦你的集群资源是开放给外面的用户使用，用户本身不了解你的这套机制原理，很容易会乱申请资源，造成严重拖垮集群整体运作效率的事情，所以这类监控的指标就是为了防止这样的事情发生。目前我们主要实现了宏观层面的监控。如：数据质量监控系统实现方案如下。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2pdg7rj20k60cswh6.jpg" alt="8"></p>
<h2 id="三、大数据平台重构过程中踩过的坑"><a href="#三、大数据平台重构过程中踩过的坑" class="headerlink" title="三、大数据平台重构过程中踩过的坑"></a>三、大数据平台重构过程中踩过的坑</h2><p>我们在大数据平台重构过程中踩过的坑，大致可以分为操作系统、架构设计、开源组件三类，下面主要列举些比较典型的，花时间比较长的问题。</p>
<p>1、操作系统级的坑</p>
<p>Hadoop的I/O性能很大程度上依赖于Linux本地文件系统的读写性能。Linux中有多种文件系统可供选择，比如ext3和ext4，不同的文件系统性能有一定的差别。我们主要想利用ext4文件系统的特性，由于之前的操作系统都是CentOS5.9不支持ext4文件格式，所以考虑操作系统升级为CentOS6.3版本，部署Hadoop集群后，作业一启动，就出现CPU内核过高的问题。如下图</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe2t4lrhj20hq09yaj2.jpg" alt="9"></p>
<p>经过很长时间的测试验证，发现CentOS6优化了内存申请的效率，引入了THP的特性，而Hadoop是高密集型内存运算系统，这个改动给hadoop带来了副作用。通过以下内核参数优化关闭系统THP特性，CPU内核使用率马上下降，如下图:</p>
<p>echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/enabled</p>
<p>echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/defrag</p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcxe39po0yj20ip0anwlr.jpg" alt="10"></p>
<p>2、架构设计的坑</p>
<p>最初的数据流架构是数据采集网关把数据上报给Kafka，再由数据实时清洗平台(ETL)做预处理后直接实时写入HDFS，如下图：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcxe3ao3htj20eb03474f.jpg" alt="11"></p>
<p>此架构，需要维持HDFS Client的长连接，由于网络等各种原因导致Storm实时写入HDFS经常不稳定，隔三差五的出现数据异常，使后面的计算结果异常不断，当时尝试过很多种手段去优化，如：保证长连接、连接断后重试机制、调整HDFS服务端参数等，都解决的不是彻底。</p>
<p>每天异常不断，旧异常没解决，新异常又来了，在压力山大的情况下，考虑从架构角度调整，不能只从具体的技术点去优化了，在做架构调整时，考虑到我们架构重构的初衷，提高数据的实时性，尽量让计算任务实时化，但重构过程中要考虑现有业务的过渡，所以架构必须支持实时与离线的需求，结合这些需求，在数据实时清洗平台(ETL)后加了一层数据缓存重用层(kafka)，也就是经过数据实时清洗平台后的数据还是写入kafka集群，由于kafka支持重复消费，所以同一份数据可以既满足实时计算也满足离线计算，从上面的整体技术架构也可以看出，如下图：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcxe3bzx3ij20j904c3z3.jpg" alt="12"></p>
<p>KG-Camus组件也是基于架构调整后，重新实现了一套离线消费Kafka集群数据的组件，此组件是参考LinkedIn的Camus实现的。此方式，使数据消费模式由原来的推方式改为拉模式了，不用维持HDFS Client的长连接等功能了，直接由作业调度系统每隔时间去拉一次数据，不同的业务可以设置不同的时间间隔，从此架构调整上线后，基本没有类似的异常出现了。</p>
<p>这个坑，是我自己给自己挖的，导致我们的重构计划延期2个月，主要原因是由最初技术预研究测试不充分所导致。</p>
<p>3、开源组件的坑</p>
<p>由于整个数据平台涉及到的开源组件很多，踩过的坑也是十个手指数不过来。</p>
<p>1）、当我们的行为数据全量接入到Kafka集群(几百亿/天)，数据采集网卡出现大量连接超时现象，但万兆网卡进出流量使用率并不是很高，只有几百Mbit/s，经过大量的测试排查后，调整以下参数，就是顺利解决了此问题。调整参数后网卡流量如下图：</p>
<p>a)、num.network.threads(网络处理线程数)值应该比cpu数略大</p>
<p>b)、num.io.threads(接收网络线程请求并处理线程数)值提高为cpu数两倍</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcxe3dps6xj20de06u3zc.jpg" alt="13"></p>
<p>2）、在hive0.14 版本中，利用函数ROW_NUMBER() OVER对数据进行数据处理后，导致大量的作业出现延时很大的现象，经异常排查后，发现在数据记录数没变的情况，数据的存储容量扩大到原来的5倍左右，导致MapReduce执行很慢造成的。改为自己实现类似的函数后，解决了容量扩大为原来几倍的现象。说到这里，也在此请教读到此处的读者一个问题，在海量数据去重中采用什么算法或组件进行比较合适，既能高性能又能高准确性，有好的建议或解决方案可以加happyjim2010微信私我。</p>
<p>3）、在业务实时监控系统中，用OpenTSDB与实时计算系统（storm）结合，用于聚合并存储实时metric数据。在这种实现中，通常需要在实时计算部分使用一个时间窗口（window），用于聚合实时数据，然后将聚合结果写入tsdb。但是，由于在实际情况中，实时数据在采集、上报阶段可能会存在延时，而导致tsdb写入的数据不准确。针对这个问题，我们做了一个改进，在原有tsdb写入api的基础上，增加了一个原子加api。这样，延迟到来的数据会被叠加到之前写入的数据之上，实时的准确性由于不可避免的原因（采集、上报阶段）产生了延迟，到最终的准确性也可以得到保证。另外，添加了这个改进之后，实时计算端的时间窗口就不需要因为考虑延迟问题设置得比较大，这样既节省了内存的消耗，也提高了实时性。</p>
<h2 id="四、后续持续改进"><a href="#四、后续持续改进" class="headerlink" title="四、后续持续改进"></a>四、后续持续改进</h2><p>数据存储(分布式内存文件系统(Tachyon)、数据多介质分层存储、数据列式存储)、即席查询(OLAP)、资源隔离、数据安全、平台微观层面监控、数据对外服务等。</p>
<h2 id="作者介绍"><a href="#作者介绍" class="headerlink" title="作者介绍"></a>作者介绍</h2><p><strong>王劲</strong>，目前就职酷狗音乐，大数据架构师，负责酷狗大数据技术规划、建设、应用。 11年的IT从业经验，2年分布式应用开发，3年大数据技术实践经验，主要研究方向流式计算、大数据存储计算、分布式存储系统、NoSQL、搜索引擎等。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[flume1.7结合kafka0.9.0.1相关配置]]></title>
      <url>https://stanxia.github.io/2017/02/20/flume1-7%E7%BB%93%E5%90%88kafka0-9-0-1%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>利用flume1.7抓取数据，传入到kafka</p>
<h2 id="配置文件设置"><a href="#配置文件设置" class="headerlink" title="配置文件设置"></a>配置文件设置</h2><p>在flume/conf/新建一个 kafka.conf,修改该文件,相关配置如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">vi flume/conf/kafka.conf</div><div class="line">#agent1表示代理名称</div><div class="line">agent1.sources=source1</div><div class="line">agent1.channels=channel1</div><div class="line">agent1.sinks=sink1</div><div class="line">#Spooling Directory是监控指定文件夹中新文件的变化，一旦新文件出现，就解析该文件内容，然后</div><div class="line">写入到channle。写入完成后，标记该文件已完成或者删除该文件。</div><div class="line">#配置source</div><div class="line">#数据来源类型 spooldir表示 文件夹 ，command</div><div class="line">agent1.sources.source1.type=spooldir</div><div class="line">#指定监控的目录</div><div class="line">agent1.sources.source1.spoolDir=/home/hadoop/logs</div><div class="line">agent1.sources.source1.channels=channel1</div><div class="line">agent1.sources.source1.fileHeader=false</div><div class="line">agent1.sources.source1.interceptors=i1</div><div class="line">agent1.sources.source1.interceptors.i1.type=timestamp</div><div class="line">#配置channel1</div><div class="line">agent1.channels.channel1.type=file</div><div class="line">#channel数据存放的备份目录</div><div class="line">agent1.channels.channel1.checkpointDir=/home/hadoop/channel_data.backup</div><div class="line">#channel数据存放目录</div><div class="line">agent1.channels.channel1.dataDir=/home/hadoop/channel_data</div><div class="line">#配置sink1</div><div class="line">agent1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink</div><div class="line">#新版本开始使用如下配置：</div><div class="line">agent1.sinks.sink1.kafka.bootstrap.servers=monsterxls:9092,slave1xls:9092,slave2xls:9092</div><div class="line">#agent1.sinks.sink1.partition.key=0</div><div class="line">#agent1.sinks.sink1.partitioner.class=org.apache.flume.plugins.SinglePartition</div><div class="line">agent1.sinks.sink1.serializer.class=kafka.serializer.StringEncoder</div><div class="line">agent1.sinks.sink1.max.message.size=1000000</div><div class="line">agent1.sinks.sink1.producer.type=sync</div><div class="line">agent1.sinks.sink1.custom.encoding=UTF-8</div><div class="line">#新版本使用如下配置：</div><div class="line">agent1.sinks.sink1.topic=stanxls</div><div class="line">agent1.sinks.sink1.channel=channel1</div></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>注意版本的问题。新版本改动了很多，在配置之前多看下帮助文档，了解下各种属性。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[yarn三种调度规则]]></title>
      <url>https://stanxia.github.io/2017/02/16/yarn%E4%B8%89%E7%A7%8D%E8%B0%83%E5%BA%A6%E8%A7%84%E5%88%99/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="yarn三种调度机制"><a href="#yarn三种调度机制" class="headerlink" title="yarn三种调度机制"></a>yarn三种调度机制</h2><ol>
<li><p>FIFO Scheduler先进先出调度机制</p>
</li>
<li><p>Fair Scheduler公平调度机制</p>
</li>
<li><p>Capacity Scheduler容量机制</p>
</li>
</ol>
<h2 id="FIFO-Scheduler"><a href="#FIFO-Scheduler" class="headerlink" title="FIFO Scheduler"></a>FIFO Scheduler</h2><p>按照先进先出的调度机制，所有的application将按照提交的顺序来执行，这些application都放在一个队列里面，顺序执行，执行完一个之后，才会执行下一个。</p>
<h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><p>如果任务耗时长，后面提交的任务会一直处于等待状态，影响效率。所以只适合单人跑任务。</p>
<p>面对以上缺点，yarn提出了另两种策略，更加适合共享集群。</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcsouzgzg1j20q80eqabe.jpg" alt="3"></p>
<h2 id="Capacity-Scheduler"><a href="#Capacity-Scheduler" class="headerlink" title="Capacity Scheduler"></a>Capacity Scheduler</h2><p>定位：多人共享调度器。</p>
<p>机制：为每人分配一个队列，每个队列占用集群固定的资源，每个队列占用的资源可以不同，每个队列内部还是按照FIFO的策略。</p>
<p>特性：queue elasticity （弹性队列）根据实际情况分配资源</p>
<p>Capacity Scheduler 的队列时支持层级关系的：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcsoa7b1tkj216m068mxf.jpg" alt="capacity1"></p>
<p>相关配置如下：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcsoa7u5psj20vy13m44h.jpg" alt="capacity2"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcsouw6wsej20p60g8401.jpg" alt="1"></p>
<h5 id="队列设置"><a href="#队列设置" class="headerlink" title="队列设置"></a>队列设置</h5><p>如果是mapreduce任务，通过 <code>mapreduce.job.queuename</code>来设置执行队列。</p>
<h2 id="Fair-Scheduler"><a href="#Fair-Scheduler" class="headerlink" title="Fair Scheduler"></a>Fair Scheduler</h2><p>机制：为每一个任务均匀分配资源，一个任务就可以用整个集群资源，两个任务就平分集群资源，依次类推。</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcsouwra8hj20og0ekjsr.jpg" alt="2"></p>
<h5 id="开启Fair-Scheduler"><a href="#开启Fair-Scheduler" class="headerlink" title="开启Fair Scheduler"></a>开启Fair Scheduler</h5><p>在<strong>yarn-site.xml</strong>中设置 <code>yarn.resourcemanager.scheduler.class</code>为<code>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</code> 。NOTE:CDH默认的就是Faire Scheduler ，CDH并不支持 Capacity Scheduler.</p>
<h5 id="队列设置-1"><a href="#队列设置-1" class="headerlink" title="队列设置"></a>队列设置</h5><p>设置fair-scheduler.xml文件，可参考下图：</p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcsortg5yjj215c0litcz.jpg" alt="fair"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka文件存储机制及partition和offset]]></title>
      <url>https://stanxia.github.io/2017/02/15/Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%E5%8F%8Apartition%E5%92%8Coffset/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="初识kafka"><a href="#初识kafka" class="headerlink" title="初识kafka"></a>初识kafka</h2><p>kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作是在现代网络上的许多社会功能的一个关键因素。</p>
<p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统(也可以当做MQ系统)，常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p>
<h2 id="为什么用kafka"><a href="#为什么用kafka" class="headerlink" title="为什么用kafka"></a>为什么用kafka</h2><p>一个商业化消息队列的性能好坏，其文件存储机制设计是衡量一个消息队列服务技术水平和最关键指标之一。</p>
<p>下面将从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p>
<h2 id="kafka名词解释"><a href="#kafka名词解释" class="headerlink" title="kafka名词解释"></a>kafka名词解释</h2><table>
<thead>
<tr>
<th style="text-align:center">名词</th>
<th style="text-align:center">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">broker</td>
<td style="text-align:center">消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</td>
</tr>
<tr>
<td style="text-align:center">topic</td>
<td style="text-align:center">一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</td>
</tr>
<tr>
<td style="text-align:center">partition</td>
<td style="text-align:center">topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。</td>
</tr>
<tr>
<td style="text-align:center">segment</td>
<td style="text-align:center">partition物理上由多个segment组成，下面有详细解释</td>
</tr>
</tbody>
</table>
<h2 id="kafka分析步骤"><a href="#kafka分析步骤" class="headerlink" title="kafka分析步骤"></a>kafka分析步骤</h2><ol>
<li>topic中partition存储分布</li>
<li>partiton中文件存储方式</li>
<li>partiton中segment文件存储结构</li>
<li>在partition中如何通过offset查找message</li>
</ol>
<h2 id="topic中partition存储分布详解"><a href="#topic中partition存储分布详解" class="headerlink" title="topic中partition存储分布详解"></a>topic中partition存储分布详解</h2><p>假设实验环境中Kafka集群只有一个broker，xxx/message-folder为数据文件存储根目录，在Kafka broker中server.properties文件配置(参数log.dirs=xxx/message-folder)，例如创建2个topic名称分别为report_push、launch_info, partitions数量都为partitions=4</p>
<p>存储路径和目录规则为：</p>
<p>xxx/message-folder</p>
<p>|–report_push-0</p>
<p>|–report_push-1</p>
<p>|–report_push-2</p>
<p>|–report_push-3</p>
<p>|–launch_info-0</p>
<p>|–launch_info-1</p>
<p>|–launch_info-2</p>
<p>|–launch_info-3</p>
<p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。</p>
<h2 id="partiton中文件存储方式"><a href="#partiton中文件存储方式" class="headerlink" title="partiton中文件存储方式"></a>partiton中文件存储方式</h2><p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275349891.png" alt="img1"></p>
<p>  <del>图1</del></p>
<p>每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。</p>
<p>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。</p>
<p>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。</p>
<h2 id="partiton中segment文件存储结构"><a href="#partiton中segment文件存储结构" class="headerlink" title="partiton中segment文件存储结构"></a>partiton中segment文件存储结构</h2><p>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件.</p>
<p>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</p>
<p>下面文件列表是笔者在Kafka broker上做的一个实验，创建一个topicXXX包含1 partition，设置每个segment大小为500MB,并启动producer向Kafka broker写入大量数据,如下图2所示segment文件列表形象说明了上述2个规则：</p>
<p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275118393.png" alt="img2"></p>
<p><del>图2</del></p>
<p>上图中对segment file文件为例，说明segment中index&lt;—-&gt;data file对应关系物理结构如下：</p>
<p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275129022.png" alt="img3"></p>
<p><del>图3</del></p>
<p>上图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。</p>
<p>其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移地址为497。</p>
<p>从上图了解到segment data file由许多message组成，下面详细说明message物理结构如下：</p>
<p><img src="http://www.111cn.net/get_pic/php/upload/image/20151031/1446305275773410.png" alt="img4"></p>
<p><del>图4</del></p>
<p>参数说明：</p>
<table>
<thead>
<tr>
<th style="text-align:center">参数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">8 byte  offset</td>
<td style="text-align:center">在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息, 在parition(分区)内的位置。即offset表示partiion的第多少message</td>
</tr>
<tr>
<td style="text-align:center">4 byte   message  size</td>
<td style="text-align:center">message大小</td>
</tr>
<tr>
<td style="text-align:center">4 byte   CRC32</td>
<td style="text-align:center">用crc32校验message</td>
</tr>
<tr>
<td style="text-align:center">1 byte   “magic”</td>
<td style="text-align:center">表示本次发布Kafka服务程序协议版本号</td>
</tr>
<tr>
<td style="text-align:center">1 byte    “attributes”</td>
<td style="text-align:center">表示为独立版本、或标识压缩类型、或编码类型。</td>
</tr>
<tr>
<td style="text-align:center">4 byte key  length</td>
<td style="text-align:center">表示key的长度,当key为-1时，K byte key字段不填</td>
</tr>
<tr>
<td style="text-align:center">K byte key</td>
<td style="text-align:center">可选</td>
</tr>
<tr>
<td style="text-align:center">value bytes   payload</td>
<td style="text-align:center">表示实际消息数据。</td>
</tr>
</tbody>
</table>
<h2 id="在partition中如何通过offset查找message"><a href="#在partition中如何通过offset查找message" class="headerlink" title="在partition中如何通过offset查找message"></a>在partition中如何通过offset查找message</h2><p>例如读取offset=368776的message，需要通过下面2个步骤查找。</p>
<p>第一步查找segment file：</p>
<p>上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，就可以快速定位到具体文件。</p>
<p>当offset=368776时定位到00000000000000368769.index|log</p>
<p>第二步通过segment file查找message：</p>
<p>通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和 00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到 offset=368776为止。</p>
<p>从上述图3可知这样做的优点，segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p>
<h2 id="Kafka文件存储机制-实际运行效果"><a href="#Kafka文件存储机制-实际运行效果" class="headerlink" title="Kafka文件存储机制?实际运行效果"></a>Kafka文件存储机制?实际运行效果</h2><p>Kafka运行时很少有大量读磁盘的操作，主要是定期批量写磁盘操作，因此操作磁盘很高效。这跟Kafka文件存储中读写message的设计是息息相关的。Kafka中读写message有如下特点:</p>
<h5 id="写message"><a href="#写message" class="headerlink" title="写message"></a>写message</h5><p>消息从java堆转入page cache(即物理内存)。</p>
<p>由异步线程刷盘,消息从page cache刷入磁盘。</p>
<h5 id="读message"><a href="#读message" class="headerlink" title="读message"></a>读message</h5><p>消息直接从page cache转入socket发送出去。</p>
<p>当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁盘Load消息到page cache,然后直接从socket发出去。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h5 id="Kafka高效文件存储设计特点"><a href="#Kafka高效文件存储设计特点" class="headerlink" title="Kafka高效文件存储设计特点"></a>Kafka高效文件存储设计特点</h5><p>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</p>
<p>通过索引信息可以快速定位message和确定response的最大大小。</p>
<p>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</p>
<p>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</p>
<h5 id="kafka中的partition和offset-log机制"><a href="#kafka中的partition和offset-log机制" class="headerlink" title="kafka中的partition和offset,log机制"></a>kafka中的partition和offset,log机制</h5><p><img src="http://www.111cn.net/get_pic/2015/10/31/20151031233153426.jpg" alt="img5"></p>
<p><del>图5 分区读写日志</del></p>
<p>首先,kafka是通过log(日志)来记录消息发布的.每当产生一个消息,kafka会记录到本地的log文件中,这个log和我们平时的log有一定的区别.</p>
<p>这个log文件默认的位置在config/server.properties中指定的.默认的位置是log.dirs=/tmp/kafka-logs</p>
<h5 id="分区partition"><a href="#分区partition" class="headerlink" title="分区partition"></a>分区partition</h5><p>kafka是为分布式环境设计的,因此如果日志文件,其实也可以理解成消息<a href="http://www.111cn.net/database/database.html" target="_blank" rel="external">数据库</a>,放在同一个地方,那么必然会带来可用性的下降,一挂全挂,如果全量拷贝到所有的机器上,那么数据又存在过多的冗余,而且由于每台机器的磁盘大小是有限的,所以即使有再多的机器,可处理的消息还是被磁盘所限制,无法超越当前磁盘大小.因此有了partition的概念.</p>
<p>kafka对消息进行一定的计算,通过hash来进行分区.这样,就把一份log文件分成了多份.如上面的分区读写日志图,分成多份以后,在单台broker上,比如快速上手中,如果新建topic的时候,我们选择了–replication-factor 1 –partitions 2,那么在log目录里,我们会看到：</p>
<p>test-0目录和test-1目录.就是两个分区了.</p>
<p><img src="http://www.111cn.net/get_pic/2015/10/31/20151031233155850.jpg" alt="img6"></p>
<p><del>图6 kafka分布式分区存储</del></p>
<p>这是一个topic包含4个Partition，2 Replication(拷贝),也就是说全部的消息被放在了4个分区存储,为了高可用,将4个分区做了2份冗余,然后根据分配算法.将总共8份数据,分配到broker集群上.</p>
<p>结果就是每个broker上存储的数据比全量数据要少,但每份数据都有冗余,这样,一旦一台机器宕机,并不影响使用.比如图中的Broker1,宕机了.那么剩下的三台broker依然保留了全量的分区数据.所以还能使用,如果再宕机一台,那么数据不完整了.当然你可以设置更多的冗余,比如设置了冗余是4,那么每台机器就有了0123完整的数据,宕机几台都行.需要在存储占用和高可用之间做衡量.</p>
<p>宕机后,zookeeper会选出新的partition leader.来提供服务.</p>
<h5 id="偏移offset"><a href="#偏移offset" class="headerlink" title="偏移offset"></a>偏移offset</h5><p>上面说了分区，分区是一个有序的,不可变的消息队列.新来的commit log持续往后面加数据.这些消息被分配了一个下标(或者偏移),就是offset,用来定位这一条消息.</p>
<p>消费者消费到了哪条消息,是保持在消费者这一端的.消息者也可以控制,消费者可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.也可以重置offset.</p>
<h5 id="如何通过offset算出分区"><a href="#如何通过offset算出分区" class="headerlink" title="如何通过offset算出分区"></a>如何通过offset算出分区</h5><p>partition存储的时候,又分成了多个segment(段),然后通过一个index,索引,来标识第几段.</p>
<p>在磁盘中，每个topic目录下面会有两个文件 index和log.</p>
<p><img src="http://www.111cn.net/get_pic/2015/10/31/20151031233158914.jpg" alt="img7"></p>
<p><del>图7 index文件和log文件</del></p>
<p>对于某个指定的分区,假设每5个消息,作为一个段大小,当产生了10条消息的情况下,目前有会得到：</p>
<p>0.index (表示这里index是对0-4做的索引)</p>
<p>5.index (表示这里index是对5-9做的索引)</p>
<p>10.index (表示这里index是对10-15做的索引,目前还没满)</p>
<p>和log文件</p>
<p>0.log</p>
<p>5.log</p>
<p>10.log</p>
<p>,当消费者需要读取offset=8的时候,首先kafka对index文件列表进行<u>二分查找</u>,可以算出.应该是在5.index对应的log文件中,然后对对应的5.log文件,进行顺序查找,5-&gt;6-&gt;7-&gt;8,直到顺序找到8就好了.</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[MAC应用无法打开或文件损坏的处理方法]]></title>
      <url>https://stanxia.github.io/2017/02/15/MAC%E5%BA%94%E7%94%A8%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E6%88%96%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>下载了一些程序之后，却发现无法在MAC中安装，安装时会弹出下图所示警告框：“打不开 xxx，因为它来自身份不明的开发者”</p>
<p><img src="http://img.xclient.info/attachment/cdn/large/006ehIt6jw1execfbx4xnj30nc0b6dgh.jpg" alt="img1"></p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>在MAC下安装一些软件时提示”来自身份不明开发者”，其实这是MAC新系统启用了新的安全机制。<br>默认只信任 <strong>Mac App Store</strong> 下载的软件和拥有开发者 ID 签名的应用程序。<br>换句话说就是 MAC 系统默认只能安装靠谱渠道（有苹果审核的 <strong>Mac App Store</strong>）下载的软件或被认可的人开发的软件。</p>
<p>这当然是为了用户不会稀里糊涂安装流氓软件中招，但没有开发者签名的 “老实软件” 也受影响了，安装就会弹出下图所示警告框：“打不开 xxx，因为它来自身份不明的开发者”。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol>
<li><p>最简单的方式：按住Control后，再次点击软件图标，即可。</p>
</li>
<li><p>修改系统配置：系统偏好设置… -&gt; 安全性与隐私… -&gt;通用… -&gt;选择任何来源。<img src="http://ww2.sinaimg.cn/large/006ehIt6jw1exed22xlgpj30os0m6ae7.jpg" alt="img2"></p>
<h2 id=""><a href="#" class="headerlink" title=""></a><img src="http://ww2.sinaimg.cn/large/006ehIt6jw1exed2kg4wbj30oe0jqtbd.jpg" alt="imag3"></h2><h2 id="-1"><a href="#-1" class="headerlink" title=""></a><img src="http://ww2.sinaimg.cn/large/006ehIt6jw1exed0cuqtyj30oe0js77b.jpg" alt="img4"></h2></li>
<li><p><strong><em>macOs Sierra 10.2</em></strong>以上版本，打开<u>终端</u>，执行:<code>sudo spctl --master-disable</code> 就可以啦。</p>
</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[完善ntp时间同步]]></title>
      <url>https://stanxia.github.io/2017/02/14/%E5%AE%8C%E5%96%84ntp%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h1 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h1><p>ntp同步时间过长</p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>修改 /etc/ntp.conf</p>
<p>主节点配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">server ntp7.aliyun.com iburst</div><div class="line">restrict ntp7.aliyun.com nomodify notrap noquery</div></pre></td></tr></table></figure>
<p>从节点配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">restrict hadoop1(主机名) nomodify notrap noquery</div><div class="line">server hadoop1(主机名) iburst</div></pre></td></tr></table></figure>
<h1 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h1><p>ntp时间同步之后，显示非中国时区</p>
<h1 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</div></pre></td></tr></table></figure>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[zookeeper启动时数组越界异常]]></title>
      <url>https://stanxia.github.io/2017/02/14/zookeeper%E5%90%AF%E5%8A%A8%E6%97%B6%E6%95%B0%E7%BB%84%E8%B6%8A%E7%95%8C%E5%BC%82%E5%B8%B8/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>启动zookeeper时，出现以下异常信息：</p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcsp95necuj21ji0jidla.jpg" alt="1"></p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>修改 ／zookeeper/conf/zoo.cfg文件<br>修改服务器id和ip映射时注意格式为：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">vi /zookeeper/conf/zoo.cfg</div><div class="line">server.1=host:port:port或者host:port或者host:port:port:type</div></pre></td></tr></table></figure></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka安装与简单的应用]]></title>
      <url>https://stanxia.github.io/2017/02/13/kafka%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>安装</p>
<h1 id="tar-xzvf-kafka-0-8-0-beta1-src-tgz"><a href="#tar-xzvf-kafka-0-8-0-beta1-src-tgz" class="headerlink" title="tar xzvf kafka-0.8.0-beta1-src.tgz"></a>tar xzvf kafka-0.8.0-beta1-src.tgz</h1><h1 id="cd-kafka-0-8-0-beta1-src"><a href="#cd-kafka-0-8-0-beta1-src" class="headerlink" title="cd kafka-0.8.0-beta1-src"></a>cd kafka-0.8.0-beta1-src</h1><h1 id="sbt-update"><a href="#sbt-update" class="headerlink" title="./sbt update"></a>./sbt update</h1><h1 id="sbt-package"><a href="#sbt-package" class="headerlink" title="./sbt package"></a>./sbt package</h1><h1 id="sbt-assembly-package-dependency"><a href="#sbt-assembly-package-dependency" class="headerlink" title="./sbt assembly-package-dependency"></a>./sbt assembly-package-dependency</h1><p>首先开启zookeeper服务，因为kafka是基于zookeeper<br>nohup /opt/kafka/bin/zookeeper-server-start.sh  /opt/kafka/config/zookeeper.properties &amp;</p>
<p>再开启kafka<br>nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &amp;</p>
<p>ps -ef | grep kafka | grep -v grep</p>
<p>ps -ef | grep zookeeper | grep -v grep</p>
<p>创建topics<br>/opt/kafka/bin/kafka-topics.sh –zookeeper 192.168.221.138:2181 –create –topic test –replication-factor 1 –partition 1</p>
<p>发消息<br>bin/kafka-console-producer.sh –broker-list localhost:9092 –topic test &gt;/dev/null</p>
<p>收消息<br> bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test –from-beginning 2&gt;/dev/null</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka-server-properties参数详解]]></title>
      <url>https://stanxia.github.io/2017/02/13/kafka-server-properties%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h1 id="server-properties参数说明"><a href="#server-properties参数说明" class="headerlink" title="server.properties参数说明"></a>server.properties参数说明</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">broker.id=0</td>
<td>每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况</td>
</tr>
<tr>
<td style="text-align:right">log.dirs=/data/kafka-logs</td>
<td>kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能  /data/kafka-logs-1，/data/kafka-logs-2</td>
</tr>
<tr>
<td style="text-align:right">port =9092</td>
<td>broker server服务端口</td>
</tr>
<tr>
<td style="text-align:right">message.max.bytes =6525000</td>
<td>表示消息体的最大大小，单位是字节</td>
</tr>
<tr>
<td style="text-align:right">num.network.threads =4</td>
<td>broker处理消息的最大线程数，一般情况下数量为cpu核数</td>
</tr>
<tr>
<td style="text-align:right">num.io.threads =8</td>
<td>broker处理磁盘IO的线程数，数值为cpu核数2倍</td>
</tr>
<tr>
<td style="text-align:right">background.threads =4</td>
<td>一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改</td>
</tr>
<tr>
<td style="text-align:right">queued.max.requests =500</td>
<td>等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制。</td>
</tr>
<tr>
<td style="text-align:right">host.name</td>
<td>broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK</td>
</tr>
<tr>
<td style="text-align:right">socket.send.buffer.bytes=100*1024</td>
<td>socket的发送缓冲区，socket的调优参数SO_SNDBUFF</td>
</tr>
<tr>
<td style="text-align:right">socket.receive.buffer.bytes =100*1024</td>
<td>socket的接受缓冲区，socket的调优参数SO_RCVBUFF</td>
</tr>
<tr>
<td style="text-align:right">socket.request.max.bytes =100<em>1024</em>1024</td>
<td>socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.segment.bytes =1024<em>1024</em>1024</td>
<td>topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.roll.hours =24*7</td>
<td>这个参数会在日志segment没有达到log.segment.bytes设置的大小，也会强制新建一个segment会被 topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.cleanup.policy = delete</td>
<td>日志清理策略选择有：delete和compact主要针对过期数据的处理，或是日志文件达到限制的额度，会被 topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.retention.bytes=-1</td>
<td>topic每个分区的最大文件大小，一个topic的大小限制 = 分区数*log.retention.bytes。-1没有大小限log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.retention.check.interval.ms=5minutes</td>
<td>文件大小检查的周期时间，是否处罚 log.cleanup.policy中设置的策略</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.enable=<strong>false</strong></td>
<td>是否开启日志清理</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.threads = 2</td>
<td>日志清理运行的线程数</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.max.bytes.per.second=None</td>
<td>日志清理时候处理的最大大小</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.dedupe.buffer.size=500<em>1024</em>1024</td>
<td>日志清理去重时候的缓存空间，在空间允许的情况下，越大越好</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.buffer.size=512*1024</td>
<td>日志清理时候用到的IO块大小一般不需要修改</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.io.buffer.load.factor =0.9</td>
<td>日志清理中hash表的扩大因子一般不需要修改</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.backoff.ms =15000</td>
<td>检查是否处罚日志清理的间隔</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.min.cleanable.ratio=0.5</td>
<td>日志清理的频率控制，越大意味着更高效的清理，同时会存在一些空间上的浪费，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.cleaner.delete.retention.ms =1day</td>
<td>对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，同log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据。会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.index.size.max.bytes =10<em>1024</em>1024</td>
<td>对于segment日志的索引文件大小限制，会被topic创建时的指定参数覆盖</td>
</tr>
<tr>
<td style="text-align:right">log.index.interval.bytes =4096</td>
<td>当执行一个fetch操作后，需要一定的空间来扫描最近的offset大小，设置越大，代表扫描速度越快，但是也更好内存，一般情况下不需要搭理这个参数</td>
</tr>
<tr>
<td style="text-align:right">log.flush.interval.messages=None</td>
<td>log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性”的必要手段,所以此参数的设置,需要在<strong>“**</strong>数据可靠性<strong>**”</strong>与”性能”之间做必要的权衡.如果此值过大,将会导致每次”fsync”的时间较长(IO阻塞),如果此值过小,将会导致<strong>“fsync”</strong>的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失.</td>
</tr>
<tr>
<td style="text-align:right">log.flush.scheduler.interval.ms =3000</td>
<td>检查是否需要固化到硬盘的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">log.flush.interval.ms = None</td>
<td>仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制<strong>“fsync”</strong>的时间间隔,如果消息量始终没有达到阀值,但是离上一次磁盘同步的时间间隔达到阀值,也将触发.</td>
</tr>
<tr>
<td style="text-align:right">log.delete.delay.ms =60000</td>
<td>文件在索引中清除后保留的时间一般不需要去修改</td>
</tr>
<tr>
<td style="text-align:right">log.flush.offset.checkpoint.interval.ms =60000</td>
<td>控制上次固化硬盘的时间点，以便于数据恢复一般不需要去修改</td>
</tr>
<tr>
<td style="text-align:right">auto.create.topics.enable =<strong>true</strong></td>
<td>是否允许自动创建topic，若是<strong>false</strong>，就需要通过命令创建topic</td>
</tr>
<tr>
<td style="text-align:right"><strong>default</strong>.replication.factor =1</td>
<td>默认副本因子</td>
</tr>
<tr>
<td style="text-align:right">num.partitions =1</td>
<td>每个topic的分区个数，若是在topic创建时候没有指定的话会被topic创建时的指定参数覆盖</td>
</tr>
</tbody>
</table>
<h1 id="以下是Leader，replicas配置"><a href="#以下是Leader，replicas配置" class="headerlink" title="以下是Leader，replicas配置"></a>以下是Leader，replicas配置</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">controller.message.queue.size=10</td>
<td>partition leader与replicas数据同步时,消息的队列尺寸</td>
</tr>
<tr>
<td style="text-align:right">controller.socket.timeout.ms =30000</td>
<td>partition leader与replicas之间通讯时,socket的超时时间</td>
</tr>
<tr>
<td style="text-align:right">replica.lag.time.max.ms =10000</td>
<td>replicas响应partition leader的最长等待时间，若是超过这个时间，就将replicas列入ISR(in-sync replicas)，并认为它是死的，不会再加入管理中</td>
</tr>
<tr>
<td style="text-align:right">replica.lag.max.messages =4000</td>
<td>如果follower落后与leader太多,将会认为此follower[或者说partition relicas]已经失效， 通常,在follower与leader通讯时,因为网络延迟或者链接断开,总会导致replicas中消息同步滞后， 如果消息之后太多,leader将认为此follower网络延迟较大或者消息吞吐能力有限,将会把此replicas迁移， 到其他follower中， 在broker数量较少,或者网络不足的环境中,建议提高此值.</td>
</tr>
<tr>
<td style="text-align:right">replica.socket.timeout.ms=30*1000</td>
<td>follower与leader之间的socket超时时间</td>
</tr>
<tr>
<td style="text-align:right">replica.socket.receive.buffer.bytes=64*1024</td>
<td>leader复制时候的socket缓存大小</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.max.bytes =1024*1024</td>
<td>replicas每次获取数据的最大大小</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.wait.max.ms =500</td>
<td>replicas同leader之间通信的最大等待时间，失败了会重试</td>
</tr>
<tr>
<td style="text-align:right">replica.fetch.min.bytes =1</td>
<td>fetch的最小数据尺寸,如果leader中尚未同步的数据不足此值,将会阻塞,直到满足条件</td>
</tr>
<tr>
<td style="text-align:right">num.replica.fetchers=1</td>
<td>leader进行复制的线程数，增大这个数值会增加follower的IO</td>
</tr>
<tr>
<td style="text-align:right">replica.high.watermark.checkpoint.interval.ms =5000</td>
<td>每个replica检查是否将最高水位进行固化的频率</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.enable =<strong>false</strong></td>
<td>是否允许控制器关闭broker ,若是设置为<strong>true</strong>,会关闭所有在这个broker上的leader，并转移到其他broker</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.max.retries =3</td>
<td>控制器关闭的尝试次数</td>
</tr>
<tr>
<td style="text-align:right">controlled.shutdown.retry.backoff.ms =5000</td>
<td>每次关闭尝试的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">leader.imbalance.per.broker.percentage =10</td>
<td>leader的不平衡比例，若是超过这个数值，会对分区进行重新的平衡</td>
</tr>
<tr>
<td style="text-align:right">leader.imbalance.check.interval.seconds =300</td>
<td>检查leader是否不平衡的时间间隔</td>
</tr>
<tr>
<td style="text-align:right">offset.metadata.max.bytes</td>
<td>客户端保留offset信息的最大空间大小</td>
</tr>
</tbody>
</table>
<h1 id="kafka中zookeeper参数配置"><a href="#kafka中zookeeper参数配置" class="headerlink" title="kafka中zookeeper参数配置"></a>kafka中zookeeper参数配置</h1><table>
<thead>
<tr>
<th style="text-align:right">参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">zookeeper.connect = localhost:2181</td>
<td>zookeeper集群的地址，可以是多个，多个之间用逗号分割hostname1:port1,hostname2:port2,hostname3:port3</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.session.timeout.ms=6000</td>
<td>ZooKeeper的最大超时时间，就是心跳的间隔，若是没有反映，那么认为已经死了，不易过大</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.connection.timeout.ms =6000</td>
<td>ZooKeeper的连接超时时间</td>
</tr>
<tr>
<td style="text-align:right">zookeeper.sync.time.ms =2000</td>
<td>ZooKeeper集群中leader和follower之间的同步时间</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[第一阶段项目所用知识点]]></title>
      <url>https://stanxia.github.io/2017/02/12/%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E9%A1%B9%E7%9B%AE%E6%89%80%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>在hive外部执行hive语句，可多条语句一起执行<br>hive -e ‘’</p>
<p>查看表结构：<br>desc tablename;</p>
<p>查看详细表结构：<br>desc formatted tablename;</p>
<p>创建表：</p>
<p>CREATE TABLE IF NOT EXISTS   xls.bank_xls(<br>name STRING,<br>cost INT<br>)<br>PARTITIONED BY (date STRING)<br>ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘ ‘;</p>
<p>创建一张和目标表结构一样的表<br>CREATE TABLE IF NOT EXISTS xls.bank_xls LIKE wy.bank_wy;</p>
<p>删除表：<br>DROP TABLE IF EXISTS xls.bank_xls;</p>
<p>清空表数据，但不删除表：<br>TRUNCATE TABLE xls.bank_xlsx;</p>
<p>导入本地数据到hive表中：<br>LOAD DATA INPATH ‘/tmp/xls/20170103_customer_tx.txt’ OVERWRITE INTO TABLE xls.bank_xls PARTITION (date=to_date(‘20170103’));</p>
<p>查看表中的内容：<br>SLELCT * FROM xls.bank_xls;</p>
<p>SELECT name,sum(cost) FROM xls.bank_xls WHERE date=’20170105’ GROUP BY name;</p>
<p>hdfs dfs -ls /user/hive/warehouse/xls.db/bank_xls</p>
<p>hadoop jar /root/makebankrecord.jar MakeBankRecord</p>
<p>hive -e “LOAD DATA LOCAL INPATH ‘/home/xls/‘“</p>
<p>文件监听器<br>nohup hadoop jar filemonitor.jar FileChangeMain /home/xls/ &amp;</p>
<p>#获取到输出的结构<br><code>ps -ef | grep $1 | grep -v grep | awk &#39;{print $1}&#39;</code></p>
<p>指定某用户的crontab操作<br>crontab -u xls -e  编辑xls用户的crontab<br>crontab -u xls -r 删除xls用户的crontab</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[cdh集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/11/cdh%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>1.如果存在jdk：<br>卸载方式：rpm -qa | grep jdk<br>rpm -e —nodeps 加上上面返回的结构</p>
<p>2.安装jdk：<br>rpm -ivh jdk-7u80-linux-x64.rpm </p>
<p>3.配置hostname<br>vi /etc/sysconfig/network<br>NETWORKING=yes<br>HOSTNAME=master</p>
<p>4.vi /etc/hostname</p>
<p>#删除文件内容  ,然后输入<br>master</p>
<p>5.修改host映射<br>vi /etc/hosts</p>
<p>10.211.55.9 master</p>
<p>#ipDress1为master服务器的IP地址</p>
<p>6.selinux 关闭<br>vi /etc/sysconfig/selinux<br>SELINUX=disable</p>
<p>7.重启<br>reboot</p>
<p>8.更改防火墙<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld</p>
<p>9.安装时间同步服务<br>yum -y install ntp<br>vi /etc/ntp.conf</p>
<p>#注释掉所有的server<em>.</em>.* 的指向 ，新添加一条可连接的ntp服务器<br>server ntp.sjtu.edu.cn iburst</p>
<p>#启动时间同步服务<br>service ntpd start </p>
<p>#执行命令<br>ntpdate -u 1.asia.pool.ntp.org</p>
<p>#重启时间同步服务<br>service ntpd restart</p>
<p>10.ssh无密码登陆配置<br>ssh-keygen -t rsa #一直使用默认</p>
<p>11.安装mysql</p>
<p>#查看mysql是否意境安装：<br>rpm -qa | grep mariadb </p>
<p>#如果存在：<br>cd </p>
<p>#安装mysql依赖：<br>yum install -y perl-Module-Install.noarch</p>
<p>unzip <strong>.zip<br>rpm -ivh </strong>.rpm </p>
<p>#修改配置文件目录<br>cp /usr/share/mysql/my-default.cnf /etc/my.cnf</p>
<p>#在配置文件中增加以下配置并保存：<br>vi /etc/my.cnf<br>default-storage-engine = innodb<br>innodb_file_per_table<br>collation-server = utf8_general_ci<br>init-connect = ‘SET NAMES utf8’<br>character-set-server=utf8</p>
<p>#初始化数据库执行：<br>/usr/bin/mysql_install_db</p>
<p>#开启mysql服务：<br>service mysql restart</p>
<p>#查看mysql root 初始化密码：<br>cat /root/.mysql_secret</p>
<p>T1STjiM6A1TXQB5p</p>
<p>#登陆mysql：<br>mysql -u root -p<br>SET PASSWORD=PASSWORD(‘123456’)#复制root的初始密码<br>mysql下面执行：<br>SET PASSWORDcd /=PASSWORD(‘123456’)</p>
<p>#linux开启开机启动：<br>chkconfig mysql on</p>
<p>#linux下面执行 拷贝mysql-connector-java-5.1.25-bin.jar 到/usr/share/java/mysql-connector-java.jar</p>
<p>#创建数据库：<br>mysql<br>create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database monitor DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;</p>
<p>use mysql;<br>grant all on <em>.</em> to root@‘master’ Identified by ‘123456’;<br>flush privileges;</p>
<p>12.安装cloudera-manager</p>
<p>#解压cm tar 包到指定目录<br>mkdir /opt/cloudera-manager<br>tar -zxvf cloudier-manager-centos7-cm5.6.0_x86_64.tar.gz -C<br>/opt/cloudera-manager</p>
<p>#创建cloudera-scm用户：<br>[root@master cloudera-manager]# useradd –system –home=/opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-server–no-create-home –shell=/bin/false –comment “Cloudera SCM User” cloudera-scm</p>
<p>#在注解点创建cloudera-manager-server的本地元数据保存目录<br>mkdir /var/cloudera-scm-server<br>chown cloudera-scm:cloudera-scm /var/cloudera-scm-server<br>chown cloudera-scm:cloudera-scm /opt/cloudera-manager</p>
<p>#配置从节点cloudera-manager-agent 指向注解点服务器<br>vi /opt/cloudera-manager/cm-5.6.0/etc/cloudera-scm-agent/config.ini</p>
<p>#将server host改为CMS所在的主机名即master</p>
<p>#注解点中创建parcel-repo 仓库目录：<br>mkdir -p /opt/cloudera/parcel-repo<br>chown cloudera-scm:cloudera-scm/opt/cloudera/parcel-repo<br>cp CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel  CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel.sha   manifest.json /opt/cloudera/parcel-repo</p>
<p>#所有节点创建parcel目录：<br>mkdir -p /opt/cloudera/parcels<br>chown cloudera-scm:cloudera-scm/opt/cloudera/parcels</p>
<p>13.初始化脚本配置数据库：<br>/opt/cloudera-manager/cm-5.6.0/share/cmf/schema/scm_prepare_database.sh mysql -hmaster -uroot -p123456 —sim-host master scmdbn scmdbu scmdbp</p>
<p>14.启动注解点cloudera scm server<br>cp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-server  /etc/init.d/cloudera-scm-server</p>
<p>#修改变量路径：<br>vi /etc/init.d/cloudera-scm-server</p>
<p>将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default</p>
<p>chkconfig cloudera-scm-server on</p>
<p>#启动注解点cloudera scm server</p>
<p>mkdir /opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-agent<br>cp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent</p>
<p>#修改变量路径：<br>vi /etc/init.d/cloudera-scm-agent</p>
<p>#将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default</p>
<p>chkconfig cloudera-scm-agent on</p>
<p>service cloudera-scm-server start</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop原生集群搭建]]></title>
      <url>https://stanxia.github.io/2017/02/11/hadoop%E5%8E%9F%E7%94%9F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>配置yarn-site.xml</p>
<property><br>   <name>yarn.nodemanager.aux-services</name><br>   <value>mapreduce_shuffle</value><br></property>


<p>配置mapred-site.xml</p>
<property><br>   <name>mapreduce.framework.name</name><br>   <value>yarn</value><br></property><br><property><br>   <name>mapreduce.jobhistory.address</name><br>   <value>monsterxls:10020</value><br></property><br><property><br>   <name>mapreduce.jobhistory.webapp.address</name><br>   <value>monsterxls:19888</value><br></property>

<p>配置hdfs-site.xml</p>
<property><br>   <name>dfs.replication</name><br>   <value>2</value><br></property><br><property><br>   <name>dfs.datanode.ipc.address</name><br>   <value>0.0.0.0:50020</value><br></property><br><property><br>   <name>dfs.datanode.http.address</name><br>   <value>0.0.0.0:50075</value><br></property>


<p>配置core-site.xml</p>
<property><br>   <name>fs.default.name</name><br>   <value>hdfs://monsterxls:9000</value><br></property><br><property><br>   <name>hadoop.tmp.dir</name><br>   <value>/opt/tmp</value><br></property>


<p>配置hadoop-env.sh<br>export JAVA_HOME=/opt/jdk1.8</p>
<p>配置yarn-env.sh<br>export HADOOP_YARN_USER=/opt/hadoopL</p>
<p>配置/etc/profile:jdk hadoop环境变量</p>
<p>echo ‘export JAVA_HOME=/opt/jdk1.8’ &gt;&gt;/etc/profile<br>echo ‘export HADOOP_HOME=/opt/hadoop’ &gt;&gt;/etc/profile<br>echo ‘export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin’ &gt;&gt;/etc/profile<br>source /etc/profile</p>
<p>配置/etc/ntp.conf时间同步<br>yum -y install ntp<br>server ntp7.aliyun.com  iburst</p>
<p>service ntpd start<br>ntpdate -u ntp7.aliyun.com<br>service ntpd restart<br>ntpstat</p>
<p>192.168.221.136 monsterxls<br>192.168.221.135 slave1xls<br>192.168.221.137 slave2xls<br>配置/etc/hostname,/etc/hosts<br>echo ‘monsterxls’ &gt;/etc/hostname<br>echo ‘192.168.221.136 monsterxls’ &gt;&gt;/etc/hosts</p>
<p>配置/etc/sysconfig/network<br>echo ‘NETWORKING=yes’ &gt;&gt;/etc/sysconfig/network<br>echo ‘HOSTNAME=slave2xls’ &gt;&gt;/etc/sysconfig/network</p>
<p>关闭防火墙<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld</p>
<p>添加hadoop用户<br>adduser hadoop<br>passwd hadoop<br>将hadoop用户放在root组<br>usermod -g root hadoop </p>
<p>解压hadoop.tar.gz和jdk<br>tar -zxvf jdk1.8.gz -C /opt/<br>tar -zxvf hadoop-2.6.0.tar.gz -C /opt/</p>
<p>ssh相互通信<br>ssh-keygen -t rsa -P ‘’<br>scp -r id_rsa.pub root@slave1xls:/home/hadoop/.ssh/<br>authorized_keys</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[ssh互信]]></title>
      <url>https://stanxia.github.io/2017/02/11/ssh%E4%BA%92%E4%BF%A1/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><p>1.ssh-keygen -t rsa -P ‘’<br>-t  rsa表示通过rsa算法<br>-P表示设置密码</p>
<p>cd .ssh :包含文件  idrsa为密匙   idrsa.pub为公钥</p>
<p> 如果当前使用的用户时hadoop，当使用ssh切换时默认的是到hadoop用户 ，可以使用ssh root@hadoop </p>
<p>2.跨机器传输：<br>scp 文件 hadoop@hadoop1:/目标路径</p>
<p>scp idrsa.pub hadoop@hadoop1:/home/hadoop/<br>文件夹为：scp -r …</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[chrome离线恐龙快跑游戏]]></title>
      <url>https://stanxia.github.io/2017/01/18/chrome%E7%A6%BB%E7%BA%BF%E6%81%90%E9%BE%99%E5%BF%AB%E8%B7%91%E6%B8%B8%E6%88%8F/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="游戏介绍"><a href="#游戏介绍" class="headerlink" title="游戏介绍"></a>游戏介绍</h2><p>来源自Google chrome 浏览器没有网络状态下的小彩蛋。</p>
<h2 id="安装指南"><a href="#安装指南" class="headerlink" title="安装指南"></a>安装指南</h2><ol>
<li><p>右键<a href="https://unpkg.com/t-rex-runner/dist/runner.js" style="text-decoration:none" target="_blank" rel="external">这里</a>存储连接下载源码</p>
</li>
<li><p>将下载的js文件放置在source/js/下面</p>
</li>
<li><p>在页面上添加如下代码即可：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"/js/runner.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></div><div class="line"> initRunner('#container');</div><div class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="食用指南"><a href="#食用指南" class="headerlink" title="食用指南"></a>食用指南</h2><p>手机端：点触屏幕即可开始和操作。</p>
<p>电脑端：点击小恐龙，按空格键即可开始和操作。</p>
<p><div id="container"></div></p>
<script src="/js/runner.js"></script>
<script>
 initRunner('#container');
</script>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[这个杀手不太冷]]></title>
      <url>https://stanxia.github.io/2017/01/17/%E8%BF%99%E4%B8%AA%E6%9D%80%E6%89%8B%E4%B8%8D%E5%A4%AA%E5%86%B7/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><iframe src="https://www.bilibili.com/html/html5player.html?aid=3209983&cid=5061993" width="640" height="480" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[海贼王856“少骗人了”]]></title>
      <url>https://stanxia.github.io/2017/01/16/%E6%B5%B7%E8%B4%BC%E7%8E%8B856%E2%80%9C%E5%B0%91%E9%AA%97%E4%BA%BA%E4%BA%86%E2%80%9D/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="不定期转更！"><a href="#不定期转更！" class="headerlink" title="不定期转更！"></a>不定期转更！</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;center&gt;</div><div class="line">&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 </div><div class="line">	src=&quot;http://music.163.com/outchain/player?type=2&amp;id=25706282&amp;auto=0&amp;height=66&quot;&gt;</div><div class="line">&lt;/iframe&gt;	</div><div class="line">&lt;/center&gt;</div></pre></td></tr></table></figure>
<center><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" ​="" src="//music.163.com/outchain/player?type=2&id=4938705&auto=1&height=66"></iframe></center>

<script>



if ("xls123456"==prompt("通关密码"))

{alert("芝麻开门");

}else{alert("容我再想想");

location="https://stanxia.github.io/";

}

</script>

<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspiw6k1lj20nm10477f.jpg" alt="0"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspiwqlrgj20nm11idmk.jpg" alt="1"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspixckxcj20nm12w7d2.jpg" alt="2"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspiy4maoj20nm12w0zh.jpg" alt="3"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcspiz1vddj20nm12wqf7.jpg" alt="4"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcspj0kwx2j20nm12wdr2.jpg" alt="5"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspj1hwmuj20nm12wais.jpg" alt="6"></p>
<p><img src="http://wx4.sinaimg.cn/mw1024/6aae3cf3gy1fcspj29rp5j20nm12w4ad.jpg" alt="7"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspj361rjj20nm12wamg.jpg" alt="8"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspkakevtj20nm12wqdm.jpg" alt="9"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkawqlij20nm12wk2j.jpg" alt="10"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspkbin2pj20nm12wwob.jpg" alt="11"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspkcp79pj20nm12w12g.jpg" alt="12"></p>
<p><img src="http://wx2.sinaimg.cn/mw1024/6aae3cf3gy1fcspkcuitqj20nm12w7cn.jpg" alt="13"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkdmvg9j20nm12wk2s.jpg" alt="14"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkekdunj20nm12wn72.jpg" alt="15"></p>
<p><img src="http://wx1.sinaimg.cn/mw1024/6aae3cf3gy1fcspkeudsbj20nm12w7eu.jpg" alt="16"></p>
<p><img src="http://wx3.sinaimg.cn/mw1024/6aae3cf3gy1fcspkg862wj20nm12wtht.jpg" alt="17"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[接入bilibili视频播放]]></title>
      <url>https://stanxia.github.io/2017/01/15/%E6%B5%8B%E8%AF%95%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h2 id="测试视频播放"><a href="#测试视频播放" class="headerlink" title="测试视频播放"></a>测试视频播放</h2><p>接入bilibili的视频，只需要在md文档中添加如下代码即可：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">iframe</span> <span class="attr">src</span>=<span class="string">"https://www.bilibili.com/html/html5player.html?aid=3521416&amp;cid=6041635"</span> <span class="attr">width</span>=<span class="string">"640"</span> <span class="attr">height</span>=<span class="string">"480"</span> <span class="attr">frameborder</span>=<span class="string">"0"</span> <span class="attr">webkitallowfullscreen</span> <span class="attr">mozallowfullscreen</span> <span class="attr">allowfullscreen</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></div></pre></td></tr></table></figure>
<p>其中aid和cid在bilibili网页上都可以爬出来。</p>
<p>效果如下：</p>
<iframe src="https://www.bilibili.com/html/html5player.html?aid=3521416&cid=6041635" width="640" height="480" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen></iframe>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[利用微博作为图床]]></title>
      <url>https://stanxia.github.io/2017/01/15/%E5%88%A9%E7%94%A8%E5%BE%AE%E5%8D%9A%E4%BD%9C%E4%B8%BA%E5%9B%BE%E5%BA%8A/</url>
      <content type="html"><![CDATA[<script src="/assets/js/DPlayer.min.js"> </script><h3 id="上传图片"><a href="#上传图片" class="headerlink" title="上传图片"></a>上传图片</h3><ol>
<li><p>登陆微博，右上角点击发布微博</p>
</li>
<li><p>选择图片上传，选择需要上传的图片</p>
</li>
<li><p>右键图片，复制图片网络链接</p>
</li>
<li><p>将图片网址作为图片地址应用到网站中</p>
<p><img src="http://wx1.sinaimg.cn/mw690/6aae3cf3gy1fcr3nqql3pj20rm0rcdgj.jpg" alt="test"></p>
</li>
</ol>
]]></content>
    </entry>
    
  
  
</search>
