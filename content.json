{"meta":{"title":"小世界，大梦想","subtitle":"夏的onepiece","description":"随便说说","author":"夏","url":"https://github.com/stanxia/stanxia.github.io.git"},"posts":[{"title":"kafka安装与简单的应用","slug":"kafka安装与简单的应用","date":"2017-02-13T06:01:39.000Z","updated":"2017-02-13T06:03:04.000Z","comments":true,"path":"2017/02/13/kafka安装与简单的应用/","link":"","permalink":"https://github.com/stanxia/stanxia.github.io.git/2017/02/13/kafka安装与简单的应用/","excerpt":"","text":"安装 tar xzvf kafka-0.8.0-beta1-src.tgzcd kafka-0.8.0-beta1-src./sbt update./sbt package./sbt assembly-package-dependency首先开启zookeeper服务，因为kafka是基于zookeepernohup /opt/kafka/bin/zookeeper-server-start.sh /opt/kafka/config/zookeeper.properties &amp; 再开启kafkanohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &amp; ps -ef | grep kafka | grep -v grep ps -ef | grep zookeeper | grep -v grep 创建topics/opt/kafka/bin/kafka-topics.sh –zookeeper 192.168.221.138:2181 –create –topic test –replication-factor 1 –partition 1 发消息bin/kafka-console-producer.sh –broker-list localhost:9092 –topic test &gt;/dev/null 收消息 bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test –from-beginning 2&gt;/dev/null","raw":null,"content":null,"categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://github.com/stanxia/stanxia.github.io.git/tags/kafka/"}]},{"title":"第一阶段项目所用知识点","slug":"第一阶段项目所用知识点","date":"2017-02-12T15:08:05.000Z","updated":"2017-02-13T01:06:03.000Z","comments":true,"path":"2017/02/12/第一阶段项目所用知识点/","link":"","permalink":"https://github.com/stanxia/stanxia.github.io.git/2017/02/12/第一阶段项目所用知识点/","excerpt":"","text":"在hive外部执行hive语句，可多条语句一起执行hive -e ‘’ 查看表结构：desc tablename; 查看详细表结构：desc formatted tablename; 创建表： CREATE TABLE IF NOT EXISTS xls.bank_xls(name STRING,cost INT)PARTITIONED BY (date STRING)ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘ ‘; 创建一张和目标表结构一样的表CREATE TABLE IF NOT EXISTS xls.bank_xls LIKE wy.bank_wy; 删除表：DROP TABLE IF EXISTS xls.bank_xls; 清空表数据，但不删除表：TRUNCATE TABLE xls.bank_xlsx; 导入本地数据到hive表中：LOAD DATA INPATH ‘/tmp/xls/20170103_customer_tx.txt’ OVERWRITE INTO TABLE xls.bank_xls PARTITION (date=to_date(‘20170103’)); 查看表中的内容：SLELCT * FROM xls.bank_xls; SELECT name,sum(cost) FROM xls.bank_xls WHERE date=’20170105’ GROUP BY name; hdfs dfs -ls /user/hive/warehouse/xls.db/bank_xls hadoop jar /root/makebankrecord.jar MakeBankRecord hive -e “LOAD DATA LOCAL INPATH ‘/home/xls/‘“ 文件监听器nohup hadoop jar filemonitor.jar FileChangeMain /home/xls/ &amp; #获取到输出的结构ps -ef | grep $1 | grep -v grep | awk &#39;{print $1}&#39; 指定某用户的crontab操作crontab -u xls -e 编辑xls用户的crontabcrontab -u xls -r 删除xls用户的crontab","raw":null,"content":null,"categories":[],"tags":[{"name":"hive","slug":"hive","permalink":"https://github.com/stanxia/stanxia.github.io.git/tags/hive/"}]},{"title":"cdh集群搭建","slug":"cdh集群搭建","date":"2017-02-11T03:03:55.000Z","updated":"2017-02-11T03:04:38.000Z","comments":true,"path":"2017/02/11/cdh集群搭建/","link":"","permalink":"https://github.com/stanxia/stanxia.github.io.git/2017/02/11/cdh集群搭建/","excerpt":"","text":"1.如果存在jdk：卸载方式：rpm -qa | grep jdkrpm -e —nodeps 加上上面返回的结构 2.安装jdk：rpm -ivh jdk-7u80-linux-x64.rpm 3.配置hostnamevi /etc/sysconfig/networkNETWORKING=yesHOSTNAME=master 4.vi /etc/hostname #删除文件内容 ,然后输入master 5.修改host映射vi /etc/hosts 10.211.55.9 master #ipDress1为master服务器的IP地址 6.selinux 关闭vi /etc/sysconfig/selinuxSELINUX=disable 7.重启reboot 8.更改防火墙systemctl stop firewalldsystemctl disable firewalldsystemctl status firewalld 9.安装时间同步服务yum -y install ntpvi /etc/ntp.conf #注释掉所有的server..* 的指向 ，新添加一条可连接的ntp服务器server ntp.sjtu.edu.cn iburst #启动时间同步服务service ntpd start #执行命令ntpdate -u 1.asia.pool.ntp.org #重启时间同步服务service ntpd restart 10.ssh无密码登陆配置ssh-keygen -t rsa #一直使用默认 11.安装mysql #查看mysql是否意境安装：rpm -qa | grep mariadb #如果存在：cd #安装mysql依赖：yum install -y perl-Module-Install.noarch unzip .ziprpm -ivh .rpm #修改配置文件目录cp /usr/share/mysql/my-default.cnf /etc/my.cnf #在配置文件中增加以下配置并保存：vi /etc/my.cnfdefault-storage-engine = innodbinnodb_file_per_tablecollation-server = utf8_general_ciinit-connect = ‘SET NAMES utf8’character-set-server=utf8 #初始化数据库执行：/usr/bin/mysql_install_db #开启mysql服务：service mysql restart #查看mysql root 初始化密码：cat /root/.mysql_secret T1STjiM6A1TXQB5p #登陆mysql：mysql -u root -pSET PASSWORD=PASSWORD(‘123456’)#复制root的初始密码mysql下面执行：SET PASSWORDcd /=PASSWORD(‘123456’) #linux开启开机启动：chkconfig mysql on #linux下面执行 拷贝mysql-connector-java-5.1.25-bin.jar 到/usr/share/java/mysql-connector-java.jar #创建数据库：mysqlcreate database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database monitor DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci; use mysql;grant all on . to root@‘master’ Identified by ‘123456’;flush privileges; 12.安装cloudera-manager #解压cm tar 包到指定目录mkdir /opt/cloudera-managertar -zxvf cloudier-manager-centos7-cm5.6.0_x86_64.tar.gz -C/opt/cloudera-manager #创建cloudera-scm用户：[root@master cloudera-manager]# useradd –system –home=/opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-server–no-create-home –shell=/bin/false –comment “Cloudera SCM User” cloudera-scm #在注解点创建cloudera-manager-server的本地元数据保存目录mkdir /var/cloudera-scm-serverchown cloudera-scm:cloudera-scm /var/cloudera-scm-serverchown cloudera-scm:cloudera-scm /opt/cloudera-manager #配置从节点cloudera-manager-agent 指向注解点服务器vi /opt/cloudera-manager/cm-5.6.0/etc/cloudera-scm-agent/config.ini #将server host改为CMS所在的主机名即master #注解点中创建parcel-repo 仓库目录：mkdir -p /opt/cloudera/parcel-repochown cloudera-scm:cloudera-scm/opt/cloudera/parcel-repocp CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel.sha manifest.json /opt/cloudera/parcel-repo #所有节点创建parcel目录：mkdir -p /opt/cloudera/parcelschown cloudera-scm:cloudera-scm/opt/cloudera/parcels 13.初始化脚本配置数据库：/opt/cloudera-manager/cm-5.6.0/share/cmf/schema/scm_prepare_database.sh mysql -hmaster -uroot -p123456 —sim-host master scmdbn scmdbu scmdbp 14.启动注解点cloudera scm servercp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-server /etc/init.d/cloudera-scm-server #修改变量路径：vi /etc/init.d/cloudera-scm-server 将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default chkconfig cloudera-scm-server on #启动注解点cloudera scm server mkdir /opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-agentcp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent #修改变量路径：vi /etc/init.d/cloudera-scm-agent #将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default chkconfig cloudera-scm-agent on service cloudera-scm-server start","raw":null,"content":null,"categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://github.com/stanxia/stanxia.github.io.git/tags/hadoop/"}]},{"title":"hadoop原生集群搭建","slug":"hadoop原生集群搭建","date":"2017-02-11T02:55:39.000Z","updated":"2017-02-11T02:56:53.000Z","comments":true,"path":"2017/02/11/hadoop原生集群搭建/","link":"","permalink":"https://github.com/stanxia/stanxia.github.io.git/2017/02/11/hadoop原生集群搭建/","excerpt":"","text":"配置yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle 配置mapred-site.xml mapreduce.framework.name yarn mapreduce.jobhistory.address monsterxls:10020 mapreduce.jobhistory.webapp.address monsterxls:19888 配置hdfs-site.xml dfs.replication 2 dfs.datanode.ipc.address 0.0.0.0:50020 dfs.datanode.http.address 0.0.0.0:50075 配置core-site.xml fs.default.name hdfs://monsterxls:9000 hadoop.tmp.dir /opt/tmp 配置hadoop-env.shexport JAVA_HOME=/opt/jdk1.8 配置yarn-env.shexport HADOOP_YARN_USER=/opt/hadoopL 配置/etc/profile:jdk hadoop环境变量 echo ‘export JAVA_HOME=/opt/jdk1.8’ &gt;&gt;/etc/profileecho ‘export HADOOP_HOME=/opt/hadoop’ &gt;&gt;/etc/profileecho ‘export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin’ &gt;&gt;/etc/profilesource /etc/profile 配置/etc/ntp.conf时间同步yum -y install ntpserver ntp7.aliyun.com iburst service ntpd startntpdate -u ntp7.aliyun.comservice ntpd restartntpstat 192.168.221.136 monsterxls192.168.221.135 slave1xls192.168.221.137 slave2xls配置/etc/hostname,/etc/hostsecho ‘monsterxls’ &gt;/etc/hostnameecho ‘192.168.221.136 monsterxls’ &gt;&gt;/etc/hosts 配置/etc/sysconfig/networkecho ‘NETWORKING=yes’ &gt;&gt;/etc/sysconfig/networkecho ‘HOSTNAME=slave2xls’ &gt;&gt;/etc/sysconfig/network 关闭防火墙systemctl stop firewalldsystemctl disable firewalldsystemctl status firewalld 添加hadoop用户adduser hadooppasswd hadoop将hadoop用户放在root组usermod -g root hadoop 解压hadoop.tar.gz和jdktar -zxvf jdk1.8.gz -C /opt/tar -zxvf hadoop-2.6.0.tar.gz -C /opt/ ssh相互通信ssh-keygen -t rsa -P ‘’scp -r id_rsa.pub root@slave1xls:/home/hadoop/.ssh/authorized_keys","raw":null,"content":null,"categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://github.com/stanxia/stanxia.github.io.git/tags/hadoop/"}]},{"title":"ssh互信","slug":"ssh互信","date":"2017-02-11T01:58:28.000Z","updated":"2017-02-11T02:41:30.000Z","comments":true,"path":"2017/02/11/ssh互信/","link":"","permalink":"https://github.com/stanxia/stanxia.github.io.git/2017/02/11/ssh互信/","excerpt":"","text":"1.ssh-keygen -t rsa -P ‘’-t rsa表示通过rsa算法-P表示设置密码 cd .ssh :包含文件 idrsa为密匙 idrsa.pub为公钥 如果当前使用的用户时hadoop，当使用ssh切换时默认的是到hadoop用户 ，可以使用ssh root@hadoop 2.跨机器传输：scp 文件 hadoop@hadoop1:/目标路径 scp idrsa.pub hadoop@hadoop1:/home/hadoop/文件夹为：scp -r …","raw":null,"content":null,"categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://github.com/stanxia/stanxia.github.io.git/tags/hadoop/"}]}]}