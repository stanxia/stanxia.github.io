{"meta":{"title":"小世界，大梦想","subtitle":"夏的onepiece","description":"随便说说","author":"夏","url":"https://stanxia.github.io"},"posts":[{"title":"海贼王856“少骗人了”","slug":"海贼王856“少骗人了”","date":"2017-02-16T15:06:34.000Z","updated":"2017-02-16T15:16:05.000Z","comments":true,"path":"2017/02/16/海贼王856“少骗人了”/","link":"","permalink":"https://stanxia.github.io/2017/02/16/海贼王856“少骗人了”/","excerpt":"","text":"不定期转更！","raw":null,"content":null,"categories":[{"name":"one-piece","slug":"one-piece","permalink":"https://stanxia.github.io/categories/one-piece/"}],"tags":[{"name":"one-piece","slug":"one-piece","permalink":"https://stanxia.github.io/tags/one-piece/"}]},{"title":"yarn三种调度规则","slug":"yarn三种调度规则","date":"2017-02-16T06:23:32.000Z","updated":"2017-02-16T14:50:22.000Z","comments":true,"path":"2017/02/16/yarn三种调度规则/","link":"","permalink":"https://stanxia.github.io/2017/02/16/yarn三种调度规则/","excerpt":"","text":"yarn三种调度机制 FIFO Scheduler先进先出调度机制 Fair Scheduler公平调度机制 Capacity Scheduler容量机制 FIFO Scheduler按照先进先出的调度机制，所有的application将按照提交的顺序来执行，这些application都放在一个队列里面，顺序执行，执行完一个之后，才会执行下一个。 缺点：如果任务耗时长，后面提交的任务会一直处于等待状态，影响效率。所以只适合单人跑任务。 面对以上缺点，yarn提出了另两种策略，更加适合共享集群。 Capacity Scheduler定位：多人共享调度器。 机制：为每人分配一个队列，每个队列占用集群固定的资源，每个队列占用的资源可以不同，每个队列内部还是按照FIFO的策略。 特性：queue elasticity （弹性队列）根据实际情况分配资源 Capacity Scheduler 的队列时支持层级关系的： 相关配置如下： 队列设置如果是mapreduce任务，通过 mapreduce.job.queuename来设置执行队列。 Fair Scheduler机制：为每一个任务均匀分配资源，一个任务就可以用整个集群资源，两个任务就平分集群资源，依次类推。 开启Fair Scheduler在yarn-site.xml中设置 yarn.resourcemanager.scheduler.class为org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler 。NOTE:CDH默认的就是Faire Scheduler ，CDH并不支持 Capacity Scheduler. 队列设置设置fair-scheduler.xml文件，可参考下图：","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"https://stanxia.github.io/categories/大数据/"}],"tags":[{"name":"yarn","slug":"yarn","permalink":"https://stanxia.github.io/tags/yarn/"}]},{"title":"接入bilibili视频播放","slug":"测试视频播放","date":"2017-02-15T12:49:37.000Z","updated":"2017-02-16T14:45:11.000Z","comments":true,"path":"2017/02/15/测试视频播放/","link":"","permalink":"https://stanxia.github.io/2017/02/15/测试视频播放/","excerpt":"","text":"测试视频播放接入bilibili的视频，只需要在md文档中添加如下代码即可： 1&lt;iframe src=\"https://www.bilibili.com/html/html5player.html?aid=3521416&amp;cid=6041635\" width=\"640\" height=\"480\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt; 其中aid和cid在bilibili网页上都可以爬出来。 效果如下：","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"https://stanxia.github.io/categories/生活/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://stanxia.github.io/tags/hexo/"}]},{"title":"Kafka文件存储机制及partition和offset","slug":"Kafka文件存储机制及partition和offset","date":"2017-02-15T08:05:05.000Z","updated":"2017-02-16T14:47:46.000Z","comments":true,"path":"2017/02/15/Kafka文件存储机制及partition和offset/","link":"","permalink":"https://stanxia.github.io/2017/02/15/Kafka文件存储机制及partition和offset/","excerpt":"","text":"初识kafkakafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作是在现代网络上的许多社会功能的一个关键因素。 Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统(也可以当做MQ系统)，常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。 为什么用kafka一个商业化消息队列的性能好坏，其文件存储机制设计是衡量一个消息队列服务技术水平和最关键指标之一。 下面将从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。 kafka名词解释 名词 解释 broker 消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。 topic 一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。 partition topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。 segment partition物理上由多个segment组成，下面有详细解释 kafka分析步骤 topic中partition存储分布 partiton中文件存储方式 partiton中segment文件存储结构 在partition中如何通过offset查找message topic中partition存储分布详解假设实验环境中Kafka集群只有一个broker，xxx/message-folder为数据文件存储根目录，在Kafka broker中server.properties文件配置(参数log.dirs=xxx/message-folder)，例如创建2个topic名称分别为report_push、launch_info, partitions数量都为partitions=4 存储路径和目录规则为： xxx/message-folder |–report_push-0 |–report_push-1 |–report_push-2 |–report_push-3 |–launch_info-0 |–launch_info-1 |–launch_info-2 |–launch_info-3 在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。 partiton中文件存储方式 图1 每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。 每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。 这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。 partiton中segment文件存储结构segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件. segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。 下面文件列表是笔者在Kafka broker上做的一个实验，创建一个topicXXX包含1 partition，设置每个segment大小为500MB,并启动producer向Kafka broker写入大量数据,如下图2所示segment文件列表形象说明了上述2个规则： 图2 上图中对segment file文件为例，说明segment中index&lt;—-&gt;data file对应关系物理结构如下： 图3 上图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。 其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移地址为497。 从上图了解到segment data file由许多message组成，下面详细说明message物理结构如下： 图4 参数说明： 参数 说明 8 byte offset 在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息, 在parition(分区)内的位置。即offset表示partiion的第多少message 4 byte message size message大小 4 byte CRC32 用crc32校验message 1 byte “magic” 表示本次发布Kafka服务程序协议版本号 1 byte “attributes” 表示为独立版本、或标识压缩类型、或编码类型。 4 byte key length 表示key的长度,当key为-1时，K byte key字段不填 K byte key 可选 value bytes payload 表示实际消息数据。 在partition中如何通过offset查找message例如读取offset=368776的message，需要通过下面2个步骤查找。 第一步查找segment file： 上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset 二分查找文件列表，就可以快速定位到具体文件。 当offset=368776时定位到00000000000000368769.index|log 第二步通过segment file查找message： 通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和 00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到 offset=368776为止。 从上述图3可知这样做的优点，segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。 Kafka文件存储机制?实际运行效果Kafka运行时很少有大量读磁盘的操作，主要是定期批量写磁盘操作，因此操作磁盘很高效。这跟Kafka文件存储中读写message的设计是息息相关的。Kafka中读写message有如下特点: 写message消息从java堆转入page cache(即物理内存)。 由异步线程刷盘,消息从page cache刷入磁盘。 读message消息直接从page cache转入socket发送出去。 当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁盘Load消息到page cache,然后直接从socket发出去。 总结Kafka高效文件存储设计特点Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。 通过索引信息可以快速定位message和确定response的最大大小。 通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。 通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。 kafka中的partition和offset,log机制 图5 分区读写日志 首先,kafka是通过log(日志)来记录消息发布的.每当产生一个消息,kafka会记录到本地的log文件中,这个log和我们平时的log有一定的区别. 这个log文件默认的位置在config/server.properties中指定的.默认的位置是log.dirs=/tmp/kafka-logs 分区partitionkafka是为分布式环境设计的,因此如果日志文件,其实也可以理解成消息数据库,放在同一个地方,那么必然会带来可用性的下降,一挂全挂,如果全量拷贝到所有的机器上,那么数据又存在过多的冗余,而且由于每台机器的磁盘大小是有限的,所以即使有再多的机器,可处理的消息还是被磁盘所限制,无法超越当前磁盘大小.因此有了partition的概念. kafka对消息进行一定的计算,通过hash来进行分区.这样,就把一份log文件分成了多份.如上面的分区读写日志图,分成多份以后,在单台broker上,比如快速上手中,如果新建topic的时候,我们选择了–replication-factor 1 –partitions 2,那么在log目录里,我们会看到： test-0目录和test-1目录.就是两个分区了. 图6 kafka分布式分区存储 这是一个topic包含4个Partition，2 Replication(拷贝),也就是说全部的消息被放在了4个分区存储,为了高可用,将4个分区做了2份冗余,然后根据分配算法.将总共8份数据,分配到broker集群上. 结果就是每个broker上存储的数据比全量数据要少,但每份数据都有冗余,这样,一旦一台机器宕机,并不影响使用.比如图中的Broker1,宕机了.那么剩下的三台broker依然保留了全量的分区数据.所以还能使用,如果再宕机一台,那么数据不完整了.当然你可以设置更多的冗余,比如设置了冗余是4,那么每台机器就有了0123完整的数据,宕机几台都行.需要在存储占用和高可用之间做衡量. 宕机后,zookeeper会选出新的partition leader.来提供服务. 偏移offset上面说了分区，分区是一个有序的,不可变的消息队列.新来的commit log持续往后面加数据.这些消息被分配了一个下标(或者偏移),就是offset,用来定位这一条消息. 消费者消费到了哪条消息,是保持在消费者这一端的.消息者也可以控制,消费者可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.也可以重置offset. 如何通过offset算出分区partition存储的时候,又分成了多个segment(段),然后通过一个index,索引,来标识第几段. 在磁盘中，每个topic目录下面会有两个文件 index和log. 图7 index文件和log文件 对于某个指定的分区,假设每5个消息,作为一个段大小,当产生了10条消息的情况下,目前有会得到： 0.index (表示这里index是对0-4做的索引) 5.index (表示这里index是对5-9做的索引) 10.index (表示这里index是对10-15做的索引,目前还没满) 和log文件 0.log 5.log 10.log ,当消费者需要读取offset=8的时候,首先kafka对index文件列表进行二分查找,可以算出.应该是在5.index对应的log文件中,然后对对应的5.log文件,进行顺序查找,5-&gt;6-&gt;7-&gt;8,直到顺序找到8就好了.","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"https://stanxia.github.io/categories/大数据/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://stanxia.github.io/tags/kafka/"}]},{"title":"MAC应用无法打开或文件损坏的处理方法","slug":"MAC应用无法打开或文件损坏的处理方法","date":"2017-02-15T06:17:24.000Z","updated":"2017-02-16T14:59:21.000Z","comments":true,"path":"2017/02/15/MAC应用无法打开或文件损坏的处理方法/","link":"","permalink":"https://stanxia.github.io/2017/02/15/MAC应用无法打开或文件损坏的处理方法/","excerpt":"","text":"问题下载了一些程序之后，却发现无法在MAC中安装，安装时会弹出下图所示警告框：“打不开 xxx，因为它来自身份不明的开发者” 原因在MAC下安装一些软件时提示”来自身份不明开发者”，其实这是MAC新系统启用了新的安全机制。默认只信任 Mac App Store 下载的软件和拥有开发者 ID 签名的应用程序。换句话说就是 MAC 系统默认只能安装靠谱渠道（有苹果审核的 Mac App Store）下载的软件或被认可的人开发的软件。 这当然是为了用户不会稀里糊涂安装流氓软件中招，但没有开发者签名的 “老实软件” 也受影响了，安装就会弹出下图所示警告框：“打不开 xxx，因为它来自身份不明的开发者”。 解决方案 最简单的方式：按住Control后，再次点击软件图标，即可。 修改系统配置：系统偏好设置… -&gt; 安全性与隐私… -&gt;通用… -&gt;选择任何来源。 macOs Sierra 10.2以上版本，打开终端，执行:sudo spctl --master-disable 就可以啦。","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"https://stanxia.github.io/categories/生活/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://stanxia.github.io/tags/mac/"}]},{"title":"利用微博作为图床","slug":"利用微博作为图床","date":"2017-02-15T04:59:49.000Z","updated":"2017-02-16T14:45:50.000Z","comments":true,"path":"2017/02/15/利用微博作为图床/","link":"","permalink":"https://stanxia.github.io/2017/02/15/利用微博作为图床/","excerpt":"","text":"上传图片 登陆微博，右上角点击发布微博 选择图片上传，选择需要上传的图片 右键图片，复制图片网络链接 将图片网址作为图片地址应用到网站中","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"https://stanxia.github.io/categories/生活/"}],"tags":[{"name":"生活小知识","slug":"生活小知识","permalink":"https://stanxia.github.io/tags/生活小知识/"}]},{"title":"完善ntp时间同步","slug":"完善ntp时间同步","date":"2017-02-14T08:19:58.000Z","updated":"2017-02-16T14:46:32.000Z","comments":true,"path":"2017/02/14/完善ntp时间同步/","link":"","permalink":"https://stanxia.github.io/2017/02/14/完善ntp时间同步/","excerpt":"","text":"问题1ntp同步时间过长 解决方案修改 /etc/ntp.conf 主节点配置： 12server ntp7.aliyun.com iburstrestrict ntp7.aliyun.com nomodify notrap noquery 从节点配置： 12restrict hadoop1(主机名) nomodify notrap noqueryserver hadoop1(主机名) iburst 问题2ntp时间同步之后，显示非中国时区 解决方案1cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime","raw":null,"content":null,"categories":[{"name":"集群搭建","slug":"集群搭建","permalink":"https://stanxia.github.io/categories/集群搭建/"}],"tags":[{"name":"ntp","slug":"ntp","permalink":"https://stanxia.github.io/tags/ntp/"}]},{"title":"zookeeper启动时数组越界异常","slug":"zookeeper启动时数组越界异常","date":"2017-02-14T05:39:29.000Z","updated":"2017-02-16T14:59:19.000Z","comments":true,"path":"2017/02/14/zookeeper启动时数组越界异常/","link":"","permalink":"https://stanxia.github.io/2017/02/14/zookeeper启动时数组越界异常/","excerpt":"","text":"问题启动zookeeper时，出现以下异常信息： 解决方案修改 ／zookeeper/conf/zoo.cfg文件修改服务器id和ip映射时注意格式为：12vi /zookeeper/conf/zoo.cfgserver.1=host:port:port或者host:port或者host:port:port:type","raw":null,"content":null,"categories":[{"name":"大数据问题","slug":"大数据问题","permalink":"https://stanxia.github.io/categories/大数据问题/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://stanxia.github.io/tags/zookeeper/"}]},{"title":"kafka-server-properties参数详解","slug":"kafka-server-properties参数详解","date":"2017-02-13T06:01:39.000Z","updated":"2017-02-15T16:12:04.000Z","comments":true,"path":"2017/02/13/kafka-server-properties参数详解/","link":"","permalink":"https://stanxia.github.io/2017/02/13/kafka-server-properties参数详解/","excerpt":"","text":"server.properties参数说明 参数 说明 broker.id=0 每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况 log.dirs=/data/kafka-logs kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能 /data/kafka-logs-1，/data/kafka-logs-2 port =9092 broker server服务端口 message.max.bytes =6525000 表示消息体的最大大小，单位是字节 num.network.threads =4 broker处理消息的最大线程数，一般情况下数量为cpu核数 num.io.threads =8 broker处理磁盘IO的线程数，数值为cpu核数2倍 background.threads =4 一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改 queued.max.requests =500 等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制。 host.name broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK socket.send.buffer.bytes=100*1024 socket的发送缓冲区，socket的调优参数SO_SNDBUFF socket.receive.buffer.bytes =100*1024 socket的接受缓冲区，socket的调优参数SO_RCVBUFF socket.request.max.bytes =10010241024 socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖 log.segment.bytes =102410241024 topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖 log.roll.hours =24*7 这个参数会在日志segment没有达到log.segment.bytes设置的大小，也会强制新建一个segment会被 topic创建时的指定参数覆盖 log.cleanup.policy = delete 日志清理策略选择有：delete和compact主要针对过期数据的处理，或是日志文件达到限制的额度，会被 topic创建时的指定参数覆盖 log.retention.bytes=-1 topic每个分区的最大文件大小，一个topic的大小限制 = 分区数*log.retention.bytes。-1没有大小限log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖 log.retention.check.interval.ms=5minutes 文件大小检查的周期时间，是否处罚 log.cleanup.policy中设置的策略 log.cleaner.enable=false 是否开启日志清理 log.cleaner.threads = 2 日志清理运行的线程数 log.cleaner.io.max.bytes.per.second=None 日志清理时候处理的最大大小 log.cleaner.dedupe.buffer.size=50010241024 日志清理去重时候的缓存空间，在空间允许的情况下，越大越好 log.cleaner.io.buffer.size=512*1024 日志清理时候用到的IO块大小一般不需要修改 log.cleaner.io.buffer.load.factor =0.9 日志清理中hash表的扩大因子一般不需要修改 log.cleaner.backoff.ms =15000 检查是否处罚日志清理的间隔 log.cleaner.min.cleanable.ratio=0.5 日志清理的频率控制，越大意味着更高效的清理，同时会存在一些空间上的浪费，会被topic创建时的指定参数覆盖 log.cleaner.delete.retention.ms =1day 对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，同log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据。会被topic创建时的指定参数覆盖 log.index.size.max.bytes =1010241024 对于segment日志的索引文件大小限制，会被topic创建时的指定参数覆盖 log.index.interval.bytes =4096 当执行一个fetch操作后，需要一定的空间来扫描最近的offset大小，设置越大，代表扫描速度越快，但是也更好内存，一般情况下不需要搭理这个参数 log.flush.interval.messages=None log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性”的必要手段,所以此参数的设置,需要在“**数据可靠性**”与”性能”之间做必要的权衡.如果此值过大,将会导致每次”fsync”的时间较长(IO阻塞),如果此值过小,将会导致“fsync”的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失. log.flush.scheduler.interval.ms =3000 检查是否需要固化到硬盘的时间间隔 log.flush.interval.ms = None 仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制“fsync”的时间间隔,如果消息量始终没有达到阀值,但是离上一次磁盘同步的时间间隔达到阀值,也将触发. log.delete.delay.ms =60000 文件在索引中清除后保留的时间一般不需要去修改 log.flush.offset.checkpoint.interval.ms =60000 控制上次固化硬盘的时间点，以便于数据恢复一般不需要去修改 auto.create.topics.enable =true 是否允许自动创建topic，若是false，就需要通过命令创建topic default.replication.factor =1 默认副本因子 num.partitions =1 每个topic的分区个数，若是在topic创建时候没有指定的话会被topic创建时的指定参数覆盖 以下是Leader，replicas配置 参数 说明 controller.message.queue.size=10 partition leader与replicas数据同步时,消息的队列尺寸 controller.socket.timeout.ms =30000 partition leader与replicas之间通讯时,socket的超时时间 replica.lag.time.max.ms =10000 replicas响应partition leader的最长等待时间，若是超过这个时间，就将replicas列入ISR(in-sync replicas)，并认为它是死的，不会再加入管理中 replica.lag.max.messages =4000 如果follower落后与leader太多,将会认为此follower[或者说partition relicas]已经失效， 通常,在follower与leader通讯时,因为网络延迟或者链接断开,总会导致replicas中消息同步滞后， 如果消息之后太多,leader将认为此follower网络延迟较大或者消息吞吐能力有限,将会把此replicas迁移， 到其他follower中， 在broker数量较少,或者网络不足的环境中,建议提高此值. replica.socket.timeout.ms=30*1000 follower与leader之间的socket超时时间 replica.socket.receive.buffer.bytes=64*1024 leader复制时候的socket缓存大小 replica.fetch.max.bytes =1024*1024 replicas每次获取数据的最大大小 replica.fetch.wait.max.ms =500 replicas同leader之间通信的最大等待时间，失败了会重试 replica.fetch.min.bytes =1 fetch的最小数据尺寸,如果leader中尚未同步的数据不足此值,将会阻塞,直到满足条件 num.replica.fetchers=1 leader进行复制的线程数，增大这个数值会增加follower的IO replica.high.watermark.checkpoint.interval.ms =5000 每个replica检查是否将最高水位进行固化的频率 controlled.shutdown.enable =false 是否允许控制器关闭broker ,若是设置为true,会关闭所有在这个broker上的leader，并转移到其他broker controlled.shutdown.max.retries =3 控制器关闭的尝试次数 controlled.shutdown.retry.backoff.ms =5000 每次关闭尝试的时间间隔 leader.imbalance.per.broker.percentage =10 leader的不平衡比例，若是超过这个数值，会对分区进行重新的平衡 leader.imbalance.check.interval.seconds =300 检查leader是否不平衡的时间间隔 offset.metadata.max.bytes 客户端保留offset信息的最大空间大小 kafka中zookeeper参数配置 参数 说明 zookeeper.connect = localhost:2181 zookeeper集群的地址，可以是多个，多个之间用逗号分割hostname1:port1,hostname2:port2,hostname3:port3 zookeeper.session.timeout.ms=6000 ZooKeeper的最大超时时间，就是心跳的间隔，若是没有反映，那么认为已经死了，不易过大 zookeeper.connection.timeout.ms =6000 ZooKeeper的连接超时时间 zookeeper.sync.time.ms =2000 ZooKeeper集群中leader和follower之间的同步时间","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"https://stanxia.github.io/categories/大数据/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://stanxia.github.io/tags/kafka/"}]},{"title":"kafka安装与简单的应用","slug":"kafka安装与简单的应用","date":"2017-02-13T06:01:39.000Z","updated":"2017-02-16T14:47:28.000Z","comments":true,"path":"2017/02/13/kafka安装与简单的应用/","link":"","permalink":"https://stanxia.github.io/2017/02/13/kafka安装与简单的应用/","excerpt":"","text":"安装 tar xzvf kafka-0.8.0-beta1-src.tgzcd kafka-0.8.0-beta1-src./sbt update./sbt package./sbt assembly-package-dependency首先开启zookeeper服务，因为kafka是基于zookeepernohup /opt/kafka/bin/zookeeper-server-start.sh /opt/kafka/config/zookeeper.properties &amp; 再开启kafkanohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &amp; ps -ef | grep kafka | grep -v grep ps -ef | grep zookeeper | grep -v grep 创建topics/opt/kafka/bin/kafka-topics.sh –zookeeper 192.168.221.138:2181 –create –topic test –replication-factor 1 –partition 1 发消息bin/kafka-console-producer.sh –broker-list localhost:9092 –topic test &gt;/dev/null 收消息 bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test –from-beginning 2&gt;/dev/null","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"https://stanxia.github.io/categories/大数据/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://stanxia.github.io/tags/kafka/"}]},{"title":"第一阶段项目所用知识点","slug":"第一阶段项目所用知识点","date":"2017-02-12T15:08:05.000Z","updated":"2017-02-16T14:45:30.000Z","comments":true,"path":"2017/02/12/第一阶段项目所用知识点/","link":"","permalink":"https://stanxia.github.io/2017/02/12/第一阶段项目所用知识点/","excerpt":"","text":"在hive外部执行hive语句，可多条语句一起执行hive -e ‘’ 查看表结构：desc tablename; 查看详细表结构：desc formatted tablename; 创建表： CREATE TABLE IF NOT EXISTS xls.bank_xls(name STRING,cost INT)PARTITIONED BY (date STRING)ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘ ‘; 创建一张和目标表结构一样的表CREATE TABLE IF NOT EXISTS xls.bank_xls LIKE wy.bank_wy; 删除表：DROP TABLE IF EXISTS xls.bank_xls; 清空表数据，但不删除表：TRUNCATE TABLE xls.bank_xlsx; 导入本地数据到hive表中：LOAD DATA INPATH ‘/tmp/xls/20170103_customer_tx.txt’ OVERWRITE INTO TABLE xls.bank_xls PARTITION (date=to_date(‘20170103’)); 查看表中的内容：SLELCT * FROM xls.bank_xls; SELECT name,sum(cost) FROM xls.bank_xls WHERE date=’20170105’ GROUP BY name; hdfs dfs -ls /user/hive/warehouse/xls.db/bank_xls hadoop jar /root/makebankrecord.jar MakeBankRecord hive -e “LOAD DATA LOCAL INPATH ‘/home/xls/‘“ 文件监听器nohup hadoop jar filemonitor.jar FileChangeMain /home/xls/ &amp; #获取到输出的结构ps -ef | grep $1 | grep -v grep | awk &#39;{print $1}&#39; 指定某用户的crontab操作crontab -u xls -e 编辑xls用户的crontabcrontab -u xls -r 删除xls用户的crontab","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"https://stanxia.github.io/categories/大数据/"}],"tags":[{"name":"hive","slug":"hive","permalink":"https://stanxia.github.io/tags/hive/"}]},{"title":"cdh集群搭建","slug":"cdh集群搭建","date":"2017-02-11T03:03:55.000Z","updated":"2017-02-16T14:46:49.000Z","comments":true,"path":"2017/02/11/cdh集群搭建/","link":"","permalink":"https://stanxia.github.io/2017/02/11/cdh集群搭建/","excerpt":"","text":"1.如果存在jdk：卸载方式：rpm -qa | grep jdkrpm -e —nodeps 加上上面返回的结构 2.安装jdk：rpm -ivh jdk-7u80-linux-x64.rpm 3.配置hostnamevi /etc/sysconfig/networkNETWORKING=yesHOSTNAME=master 4.vi /etc/hostname #删除文件内容 ,然后输入master 5.修改host映射vi /etc/hosts 10.211.55.9 master #ipDress1为master服务器的IP地址 6.selinux 关闭vi /etc/sysconfig/selinuxSELINUX=disable 7.重启reboot 8.更改防火墙systemctl stop firewalldsystemctl disable firewalldsystemctl status firewalld 9.安装时间同步服务yum -y install ntpvi /etc/ntp.conf #注释掉所有的server..* 的指向 ，新添加一条可连接的ntp服务器server ntp.sjtu.edu.cn iburst #启动时间同步服务service ntpd start #执行命令ntpdate -u 1.asia.pool.ntp.org #重启时间同步服务service ntpd restart 10.ssh无密码登陆配置ssh-keygen -t rsa #一直使用默认 11.安装mysql #查看mysql是否意境安装：rpm -qa | grep mariadb #如果存在：cd #安装mysql依赖：yum install -y perl-Module-Install.noarch unzip .ziprpm -ivh .rpm #修改配置文件目录cp /usr/share/mysql/my-default.cnf /etc/my.cnf #在配置文件中增加以下配置并保存：vi /etc/my.cnfdefault-storage-engine = innodbinnodb_file_per_tablecollation-server = utf8_general_ciinit-connect = ‘SET NAMES utf8’character-set-server=utf8 #初始化数据库执行：/usr/bin/mysql_install_db #开启mysql服务：service mysql restart #查看mysql root 初始化密码：cat /root/.mysql_secret T1STjiM6A1TXQB5p #登陆mysql：mysql -u root -pSET PASSWORD=PASSWORD(‘123456’)#复制root的初始密码mysql下面执行：SET PASSWORDcd /=PASSWORD(‘123456’) #linux开启开机启动：chkconfig mysql on #linux下面执行 拷贝mysql-connector-java-5.1.25-bin.jar 到/usr/share/java/mysql-connector-java.jar #创建数据库：mysqlcreate database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database monitor DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci; use mysql;grant all on . to root@‘master’ Identified by ‘123456’;flush privileges; 12.安装cloudera-manager #解压cm tar 包到指定目录mkdir /opt/cloudera-managertar -zxvf cloudier-manager-centos7-cm5.6.0_x86_64.tar.gz -C/opt/cloudera-manager #创建cloudera-scm用户：[root@master cloudera-manager]# useradd –system –home=/opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-server–no-create-home –shell=/bin/false –comment “Cloudera SCM User” cloudera-scm #在注解点创建cloudera-manager-server的本地元数据保存目录mkdir /var/cloudera-scm-serverchown cloudera-scm:cloudera-scm /var/cloudera-scm-serverchown cloudera-scm:cloudera-scm /opt/cloudera-manager #配置从节点cloudera-manager-agent 指向注解点服务器vi /opt/cloudera-manager/cm-5.6.0/etc/cloudera-scm-agent/config.ini #将server host改为CMS所在的主机名即master #注解点中创建parcel-repo 仓库目录：mkdir -p /opt/cloudera/parcel-repochown cloudera-scm:cloudera-scm/opt/cloudera/parcel-repocp CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel CDH-5.6.0-1.cdh5.6.0.p0.18-el7.parcel.sha manifest.json /opt/cloudera/parcel-repo #所有节点创建parcel目录：mkdir -p /opt/cloudera/parcelschown cloudera-scm:cloudera-scm/opt/cloudera/parcels 13.初始化脚本配置数据库：/opt/cloudera-manager/cm-5.6.0/share/cmf/schema/scm_prepare_database.sh mysql -hmaster -uroot -p123456 —sim-host master scmdbn scmdbu scmdbp 14.启动注解点cloudera scm servercp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-server /etc/init.d/cloudera-scm-server #修改变量路径：vi /etc/init.d/cloudera-scm-server 将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default chkconfig cloudera-scm-server on #启动注解点cloudera scm server mkdir /opt/cloudera-manager/cm-5.6.0/run/cloudera-scm-agentcp /opt/cloudera-manager/cm-5.6.0/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent #修改变量路径：vi /etc/init.d/cloudera-scm-agent #将CMF_DEFAULTS=${CMF_DEFAULTS:-/etc/default}改为=/opt/cloudera-manager/cm-5.6.0/etc/default chkconfig cloudera-scm-agent on service cloudera-scm-server start","raw":null,"content":null,"categories":[{"name":"集群搭建","slug":"集群搭建","permalink":"https://stanxia.github.io/categories/集群搭建/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://stanxia.github.io/tags/hadoop/"}]},{"title":"hadoop原生集群搭建","slug":"hadoop原生集群搭建","date":"2017-02-11T02:55:39.000Z","updated":"2017-02-16T14:47:05.000Z","comments":true,"path":"2017/02/11/hadoop原生集群搭建/","link":"","permalink":"https://stanxia.github.io/2017/02/11/hadoop原生集群搭建/","excerpt":"","text":"配置yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle 配置mapred-site.xml mapreduce.framework.name yarn mapreduce.jobhistory.address monsterxls:10020 mapreduce.jobhistory.webapp.address monsterxls:19888 配置hdfs-site.xml dfs.replication 2 dfs.datanode.ipc.address 0.0.0.0:50020 dfs.datanode.http.address 0.0.0.0:50075 配置core-site.xml fs.default.name hdfs://monsterxls:9000 hadoop.tmp.dir /opt/tmp 配置hadoop-env.shexport JAVA_HOME=/opt/jdk1.8 配置yarn-env.shexport HADOOP_YARN_USER=/opt/hadoopL 配置/etc/profile:jdk hadoop环境变量 echo ‘export JAVA_HOME=/opt/jdk1.8’ &gt;&gt;/etc/profileecho ‘export HADOOP_HOME=/opt/hadoop’ &gt;&gt;/etc/profileecho ‘export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin’ &gt;&gt;/etc/profilesource /etc/profile 配置/etc/ntp.conf时间同步yum -y install ntpserver ntp7.aliyun.com iburst service ntpd startntpdate -u ntp7.aliyun.comservice ntpd restartntpstat 192.168.221.136 monsterxls192.168.221.135 slave1xls192.168.221.137 slave2xls配置/etc/hostname,/etc/hostsecho ‘monsterxls’ &gt;/etc/hostnameecho ‘192.168.221.136 monsterxls’ &gt;&gt;/etc/hosts 配置/etc/sysconfig/networkecho ‘NETWORKING=yes’ &gt;&gt;/etc/sysconfig/networkecho ‘HOSTNAME=slave2xls’ &gt;&gt;/etc/sysconfig/network 关闭防火墙systemctl stop firewalldsystemctl disable firewalldsystemctl status firewalld 添加hadoop用户adduser hadooppasswd hadoop将hadoop用户放在root组usermod -g root hadoop 解压hadoop.tar.gz和jdktar -zxvf jdk1.8.gz -C /opt/tar -zxvf hadoop-2.6.0.tar.gz -C /opt/ ssh相互通信ssh-keygen -t rsa -P ‘’scp -r id_rsa.pub root@slave1xls:/home/hadoop/.ssh/authorized_keys","raw":null,"content":null,"categories":[{"name":"集群搭建","slug":"集群搭建","permalink":"https://stanxia.github.io/categories/集群搭建/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://stanxia.github.io/tags/hadoop/"}]},{"title":"ssh互信","slug":"ssh互信","date":"2017-02-11T01:58:28.000Z","updated":"2017-02-16T14:48:17.000Z","comments":true,"path":"2017/02/11/ssh互信/","link":"","permalink":"https://stanxia.github.io/2017/02/11/ssh互信/","excerpt":"","text":"1.ssh-keygen -t rsa -P ‘’-t rsa表示通过rsa算法-P表示设置密码 cd .ssh :包含文件 idrsa为密匙 idrsa.pub为公钥 如果当前使用的用户时hadoop，当使用ssh切换时默认的是到hadoop用户 ，可以使用ssh root@hadoop 2.跨机器传输：scp 文件 hadoop@hadoop1:/目标路径 scp idrsa.pub hadoop@hadoop1:/home/hadoop/文件夹为：scp -r …","raw":null,"content":null,"categories":[{"name":"集群搭建","slug":"集群搭建","permalink":"https://stanxia.github.io/categories/集群搭建/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://stanxia.github.io/tags/hadoop/"}]}]}